---
title: ZFS å¸¸è§é—®é¢˜
tags:
  - FAQ
---

# ZFS å¸¸è§é—®é¢˜

:::tip

- renameat2/overlayfs ZFS v2.2+
  - [zfs_rename: support RENAME\_ flags](https://github.com/openzfs/zfs/commit/dbf6108b4df92341eea40d0b41792ac16eabc514)
  - feature zilsaxattr

:::

| abbr. | stand for                  | cn             |
| ----- | -------------------------- | -------------- |
| SPA   | Storage Pool Allocator     |
| vdev  | Virtual Device             | è™šæ‹Ÿè®¾å¤‡       |
| ZIL   | ZFS Intent Log             |
| TXG   | Transaction Group          |
| SLOG  | Sync Log                   |
| ARC   | Adaptive Replacement Cache | è‡ªé€‚åº”æ›¿æ¢ç¼“å­˜ |
| L2ARC | Level 2 ARC                | äºŒçº§ ARC       |

```bash
zfs get all | grep -E 'used\b|logicalused|compression|\bcompress'

zfs get all | grep -E 'sync'
```

## å¦‚ä½•é€‰æ‹© RAIDZ/mirror/dRAID

- RAIDZ - striped vdevs - RAID5/6/7
  - 66%
    - 3wide RADIZ1
    - 6wide RADIZ2
    - 9wide RADIZ3
  - `N*W RAIDZx`
    - N group
    - W wide
  - ä¸èƒ½/ä¸æ–¹ä¾¿ æ‰©å®¹
  - å›ºå®š parity
- mirror - RAID10
  - 50%
  - degraded æ€§èƒ½æ›´å¥½
  - æ¢å¤å¿«
  - æ‰©å®¹æ–¹ä¾¿
- [dRAID](./zfs-draid.md)
  - æ›´çµæ´»

**å‚è€ƒ**

- 2015 [ZFS: You should use mirror vdevs, not RAIDZ.](https://jrs-s.net/2015/02/06/zfs-you-should-use-mirror-vdevs-not-raidz/)
  - by Author of [jimsalterjrs/sanoid](https://github.com/jimsalterjrs/sanoid)

## ä¿®å¤

```bash
# -t temporary é‡å¯åŽæ¢å¤
zpool offline main scsi-0000
zpool replace main scsi-0000 scsi-1111

# -e å¦‚æžœæ–°çš„ç¡¬ç›˜æ›´å¤§
zpool online main scsi-1111
```

**resilver**

- group é‡Œå…¨éƒ¨æ‰«
- ä¼šå¾ˆæ…¢

## raidz1 to raidz2

**ä¸å¯ä»¥**

- https://serverfault.com/a/799952/190601

## æŸ¥çœ‹å®žé™…å¤§å°

```bash
# æŸ¥çœ‹åŽ‹ç¼©åŽçš„å¤§å°
du -h .
# æŸ¥çœ‹å®žé™…å¤§å°
du --apparent-size -h .
```

## ç›®å½•ä¸‹å¾ˆå¤šæ–‡ä»¶æ—¶éžå¸¸æ…¢

å°è¯•å…³é—­ atime

## cannot create '/data/db': pool must be upgraded to set this property or value

```bash
sudo zpool upgrade -a
```

## è®¡ç®—ä½¿ç”¨ç©ºé—´

- compressratio - åŽ‹ç¼©çŽ‡
  - 1/compressratio = åŽ‹ç¼©æ¯”
  - compressratio=logicalused/used
- used - å®žé™…å ç”¨ç©ºé—´
- logicalused - é€»è¾‘å ç”¨ç©ºé—´
- å ç”¨ç©ºé—´ä¹Ÿå’Œä»€ä¹ˆæ—¶å€™å¼€å¯çš„ compression æœ‰å…³
  - å¼€å¯ compression ä¹‹åŽæ–°å†™å…¥æ•°æ®ä¼šåŽ‹ç¼©
- å ç”¨ç©ºé—´ä¼šå¯¹é½ï¼Œå› æ­¤å¯èƒ½ä¼šæ¯”é€»è¾‘æ›´å¤š

```bash
zfs get all | grep -E 'used\b|logicalused|compression|\bcompress'
```

```
data                 used                  884G                  -
data                 compressratio         1.47x                 -
data                 compression           lz4                   local
data                 logicalused           1.24T                 -
```

## zfs compression vs application compression

- zfs åŽ‹ç¼©
  - å…¨é‡åŽ‹ç¼©ï¼Œç®€å•æ˜“ç”¨
  - åŽ‹ç¼©çŽ‡å— block å¤§å°å½±å“
  - æ”¯æŒ lz4ã€zstd
- åº”ç”¨ åŽ‹ç¼©
  - æ¶‰åŠåˆ°åº”ç”¨åŠŸèƒ½æ˜¯å¦æ”¯æŒ
  - åŽ‹ç¼©çš„èŒƒå›´å’Œ ZFS åŽ‹ç¼©çš„èŒƒå›´ä¸åŒ
    - ä¸€èˆ¬åº”ç”¨åªåŽ‹ç¼© æ•°æ®
  - åŽ‹ç¼©çŽ‡ ä¸ä¸€å®šå°±æ¯” ZFS åŽ‹ç¼©çŽ‡ é«˜

---

- zfs vs pg
  - PostgreSQL 14 æ”¯æŒ LZ4 TOAST
    - default_toast_compression=lz4
    - å¯ä»¥åœ¨å»ºè¡¨æ—¶è®¾ç½® `col1 text COMPRESSION lz4`
  - PostgreSQL 15 æ”¯æŒ LZ4 WAL

## ZFS ç¼“å­˜

- ZIL - ZFS Intent Log - ç¼“å†² WRITE æ“ä½œ
- SLOG - Separate Intent Log
  - `zpool add tank log`
  - ä¸éœ€è¦ç‰¹åˆ«å¤§çš„è®¾å¤‡ - ä¾‹å¦‚ 16G, 64G SSD è¶³çŸ£
- ARC - ç¼“å­˜ READ æ“ä½œ - Adaptive Replacement Cache
  - å†…å­˜
- L2ARC
  - `zpool add tank cache`
  - ä¸éœ€è¦ç‰¹åˆ«å¤§çš„è®¾å¤‡ - ä¾‹å¦‚ 128G SSD
  - ç³»ç»Ÿé‡å¯åŽç¼“å­˜ä¾ç„¶å¯ç”¨

```bash
zpool add tank log ada3             # æ·»åŠ  ZIL - å•ç£ç›˜
zpool add tank log mirror ada3 ada4 # æ·»åŠ  ZIL - RAID1 - åä¸€ä¸ª SSD å†™å…¥çš„æ•°æ®ä¹Ÿä¸ä¼šä¸¢
zpool add tank cache ada3           # æ·»åŠ  L2ARC
```

## ZFS æ€§èƒ½ä¼°ç®—

> è°ƒä¼˜åº”å…ˆæ‰¾åˆ°ç“¶é¢ˆåœ¨å“ªé‡Œã€‚

- RAIDZn é¡ºåº 4KB è¯»å– - æ—  cache åœºæ™¯
  - RAIDZ1 - `N/(N-1) * IOPS`
  - RAIDZ2 - `N/(N-2) * IOPS`
  - RAIDZ3 - `N/(N-3) * IOPS`
  - æœ‰ cache æ—¶ï¼Œåˆ™ä¸Šé™ä¸º cache ç£ç›˜çš„ IOPS
- å†™å…¥æ€§èƒ½
  - æ— æ³•ç›´æŽ¥ä¼°ç®—ï¼Œzfs å†…éƒ¨ zil ä¸ºå¼‚æ­¥å†™å…¥
  - é¢å¤–çš„ ZIL è®¾å¤‡å¯æå‡ write æ€§èƒ½
  - é»˜è®¤ä¼šåœ¨æ¯ä¸ªç£ç›˜é¢„ç•™ç©ºé—´å­˜å‚¨ ZIL
- æ€§èƒ½å½±å“å› ç´ 
  - recordsize - é»˜è®¤ 128k
  - compression
  - ashift
  - dedup - é»˜è®¤å…³é—­ - ç‰¹æ®Šåœºæ™¯åŽ»é‡èƒ½æå‡æ€§èƒ½
  - atime - é»˜è®¤å¼€å¯ - ä¸€èˆ¬ä¸éœ€è¦ï¼Œå¯å…³é—­æå‡è¯»å–æ€§èƒ½
  - logbias - é»˜è®¤ latency, å¯è®¾ç½®ä¸º throughput, å‡å°‘ä½¿ç”¨é¢å¤– zil è®¾å¤‡
  - sync
    - å…³é—­æœ€å¤šä¸¢å¤± 30s æ•°æ® - å¦‚æžœåœºæ™¯å…è®¸ä¸¢å¤±ï¼Œåˆ™ä¸å½±å“
    - é€šè¿‡ UPS ç¡®ä¿å­˜å‚¨ æ¯” ç½‘ç»œåŽå¼‚å¸¸ å¯è€ƒè™‘å…³é—­ sync
  - primarycache
  - secondarycache

## zfs import

- æ­£å¸¸ç³»ç»Ÿå¯åŠ¨ä¼šä»Žç¼“å­˜ å¯¼å…¥ - zfs import -c /etc/zfs/zpool.cache
- å¦‚æžœç¼“å­˜ä¸¢å¤±ï¼Œåˆ™å¯ä»¥ç›´æŽ¥æœç´¢ç£ç›˜
  - ä¾‹å¦‚: æ›´æ¢äº†ç³»ç»Ÿ
- [zpool-import.8](https://openzfs.github.io/openzfs-docs/man/8/zpool-import.8.html)

```bash
# æŸ¥çœ‹ å¯å¯¼å…¥ çš„ pool
# ä½¿ç”¨ lsblk æœç´¢
zpool import
# æ‰§è¡Œå¯¼å…¥ - å¯¼å…¥æ‰€çš„
zpool import -a

# æ‰‹åŠ¨æŒ‡å®šæœç´¢ç›®å½•
zpool import -d /dev/disk/by-id
```

## å…³é—­æ‰€æœ‰ atime

```bash
zfs get atime | grep '\son\s' | cut -d ' ' -f 1 | xargs -n1 sudo zfs set atime=off
```

## atime=on temporary

- https://gitlab.alpinelinux.org/alpine/aports/-/issues/12382
- https://github.com/openzfs/zfs/issues/7947

```sh title=/etc/conf.d/zfs
MOUNT_EXTRA_OPTIONS="-o atime=off"
```

## zvol vs zfs

- zvol - å—è®¾å¤‡
  - raidzã€åŽ‹ç¼©
  - æ²¡æœ‰æ‰€æœ‰ zfs ä¼´éšçš„èƒ½åŠ›
  - blocksize=8k
- zfs - æ–‡ä»¶ç³»ç»Ÿ - dataset
  - å¿«ç…§ã€å…‹éš†
  - æ–‡ä»¶ç³»ç»Ÿæœ‰ä¸€å®šç‰¹æ€§ - ä¹Ÿæœ‰ç¼ºé™·
    - ~~ä¸»è¦ç¼ºé™·: ä¸æ”¯æŒ rename2/overlay~~ - ZFS v2.2+
  - recordsize=128k

## High System Usage

- z_wr_iss
- spl_dynamic_tas
- z_wr_iss_h
- l2arc_feed
- z_wr_int_h
- rcu_sched
- txg_sync
- z_ioctl_int
- kworker/0:1-events
- z_null_iss
- z_null_int
- dp_sync_taskq
- z_wr_int
- arc_reap
- ksoftirqd
- dbuf_evict
- mmp
- migration/0

## zfs list slow

- dataset å¤šäº†åŽ `zfs list` éžå¸¸æ…¢

```bash
time zfs list | wc -l

# docker zfs volume ä½¿ç”¨çš„å‘½ä»¤
zfs list -s name -o name,guid,available -H -p
zfs list -r -t all -Hp -o name,origin,used,available,mountpoint,compression,type,volsize,quota,referenced,written,logicalused,usedbydataset main/docker

# containerd
zfs list -Hp -o name,origin,used,available,mountpoint,compression,type,volsize,quota,referenced,written,logicalused,usedbydataset data/var/k3s/snapshotter/60519
```

```
758

real    0m1.777s
user    0m0.177s
sys     0m1.599s
```

- https://github.com/openzfs/zfs/discussions/8898

```bash
time zfs list -s name -o name,guid,available -H -p > zfs-list.txt
```

```
real    2m10.183s
user    0m3.016s
sys     2m6.836s
```

```bash
wc -l zfs-list.txt
# 20177 zfs-list.txt
```

## ZFS vs Hard RAID

- ZFS æœ‰æ ¡éªŒå’Œ,å’Œå¯é¿å…ä½ç¿»è½¬ç­‰é—®é¢˜,è€Œ RAID ä¸»è¦ç”¨äºŽé¿å…æ•´ä¸ªç£ç›˜çš„æŸå
- ZFS åªéœ€è¦ HBAs (host bus adapter ) è€Œä¸éœ€è¦ RAID æŽ§åˆ¶å™¨
- æœ€å¤šåªéœ€è¦ Z2, Z3 å¾ˆå°‘ä½¿ç”¨,å¹¶ä¸”å¯èƒ½ä¼šæœ‰é—®é¢˜,æœ‰å…¶ä»–çš„åŠžæ³•æ¥é¿å…å¯èƒ½çš„é”™è¯¯
- ZFS å¹¶ä¸æ˜¯ RAID, è€Œæ˜¯ä¸€ä¸ªè½¯ä»¶,ä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿ
- ZFS é‡å»ºæ¯” RAID æ›´å¿«,ä¾‹å¦‚ 1TB çš„äº‘ç›˜,å®žé™…æ•°æ®åªæœ‰ 100MB, é‚£ä¹ˆ ZFS åªéœ€è¦ 100MB çš„ IO, è€Œ RAID éœ€è¦ 1TB çš„ IO.
- scrub æ˜¯ç”¨æ¥ä¿è¯æ•°æ®å®‰å…¨çš„,è€Œä¸æ˜¯ä¿è¯ç£ç›˜å¥åº·çš„.ä¸æ˜¯è‡ªåŠ¨çš„,éœ€è¦å®šæ—¶è°ƒåº¦.
- é¢å¤–ç‰¹æ€§
  - è‡ªå®šä¹‰åˆ’åˆ†å­˜å‚¨ç©ºé—´
  - å¯æ ¹æ®åº”ç”¨è°ƒä¼˜
  - åŠ å¯†
  - å¢žé‡åŒæ­¥

---

- "PFA"s, as in Pre-Failure Alerts
- [ZFS vs RAID6](https://www.reddit.com/r/storage/comments/3jcg2r/zfs_vs_raid6/)

## z0 is write-protected but explicit read-write mode requested

```bash
umount /dev/z0
e2fsck /dev/z0
mount /dev/z0
```

## Superblock needs_recovery flag is clear, but journal has data.

```
Buffer I/O error on dev zd0, logical block 0, lost async page write
```

**ç£ç›˜æ»¡äº†**

```bash
zfs list -o space,mountpoint
```

## is in use and contains a unknown filesystem

- mdraid, lvm, multipath

```bash
cat /proc/mdstat

mdadm --stop /dev/md127
```

## zvol æ‰©å®¹

```bash
zfs get volsize data/vol      # å½“å‰
zfs set volsize=500G data/vol # ä¿®æ”¹ Quota
resize2fs /dev/zvol/data/vol  # æ‰©å®¹ fs
```

## cannot label 'sdf': failed to detect device partitions on '/dev/sdf1': 19

## Missing /dev/zvol

```bash
apk add zfs zfs-{scripts,udev}

udevadm trigger
```

## cannot trim: no devices in pool support trim operations

```bash
zpool trim data

hdparm -I /dev/sda | grep -i trim # æ£€æŸ¥ TRIM æ”¯æŒ
```

- SATA æŽ§åˆ¶å™¨
- https://github.com/openzfs/zfs/discussions/14231
  - L2ARC device is in use as a cache
- https://github.com/openzfs/zfs/issues/13108

## retry UNAVAL

```bash
zpool online data DISK
zpool clear data
zpool scrube data # æŽ¨è
```

## remount zvol rw

```bash
mount -o remount,rw /data/docker
```

- cache å¼‚å¸¸åŽå¯¼è‡´ zvol è¢«é‡æ–°æŒ‚è½½ä¸º ro
- clear cache çš„ error åŽè¿˜æ˜¯æ— æ³•æŒ‚è½½ï¼Œå› ä¸º fs æŸå


```ansi
[0;33mEXT4-fs warning (device zd0): [0;1mext4_end_bio:343: I/O error 3 writing to inode 5767264 starting block 14909936)[0m
[0;31mBuffer I/O error on device zd0, logical block 14909936[0m
[0;33mEXT4-fs warning (device zd0): [0;1mext4_end_bio:343: I/O error 3 writing to inode 5898267 starting block 11927556)[0m
[0;31mBuffer I/O error on device zd0, logical block 11927556[0m
[0;33mEXT4-fs warning (device zd0): [0;1mext4_end_bio:343: I/O error 3 writing to inode 5898258 starting block 20496389)[0m
[0;31mBuffer I/O error on device zd0, logical block 20496389[0m
[0;33mEXT4-fs warning (device zd0): [0;1mext4_end_bio:343: I/O error 3 writing to inode 5898266 starting block 2630818)[0m
[0;31mBuffer I/O error on device zd0, logical block 2630818[0m
[0;33mEXT4-fs warning (device zd0): [0;1mext4_end_bio:343: I/O error 3 writing to inode 2919521 starting block 16194810)[0m
[0;31mBuffer I/O error on device zd0, logical block 16194810[0m
[0;31mBuffer I/O error on device zd0, logical block 16194811[0m
[0;31mBuffer I/O error on device zd0, logical block 16194812[0m
[0;31mBuffer I/O error on device zd0, logical block 16194813[0m
[0;33mEXT4-fs warning (device zd0): [0;1mext4_end_bio:343: I/O error 3 writing to inode 2920494 starting block 14332529)[0m
[0;33mEXT4-fs warning (device zd0): [0;1mext4_end_bio:343: I/O error 3 writing to inode 2883634 starting block 24493815)[0m
[0;31mBuffer I/O error on device zd0, logical block 24493815[0m
[0;33mEXT4-fs warning (device zd0): [0;1mext4_end_bio:343: I/O error 3 writing to inode 2883634 starting block 24493816)[0m
[0;31mBuffer I/O error on device zd0, logical block 14332529[0m
[0;31mBuffer I/O error on dev zd0, logical block 0, lost async page write[0m
[0;31mBuffer I/O error on dev zd0, logical block 1, lost async page write[0m
[0;31mBuffer I/O error on dev zd0, logical block 2, lost async page write[0m
[0;33mEXT4-fs error (device zd0): [0;31;1mext4_check_bdev_write_error:217: comm kworker/u8:0: Error while async write back metadata[0m
[0;33mEXT4-fs (zd0): [0;31mprevious I/O error to superblock detected[0m
[0;31mBuffer I/O error on dev zd0, logical block 5, lost async page write[0m
[0;31mBuffer I/O error on dev zd0, logical block 6, lost async page write[0m
[0;31mBuffer I/O error on dev zd0, logical block 8, lost async page write[0m
[0;31mBuffer I/O error on dev zd0, logical block 1048588, lost async page write[0m
[0;31mBuffer I/O error on dev zd0, logical block 1048589, lost async page write[0m
[0;31mBuffer I/O error on dev zd0, logical block 1466067, lost async page write[0m
[0;31mBuffer I/O error on dev zd0, logical block 1505175, lost async page write[0m
[0;33mEXT4-fs warning (device zd0): [0;1mext4_end_bio:343: I/O error 3 writing to inode 2883634 starting block 24493838)[0m
[0;33mEXT4-fs error (device zd0): [0;31;1mext4_check_bdev_write_error:217: comm VM Periodic Tas: Error while async write back metadata[0m
[0;33mEXT4-fs warning (device zd0): [0;1mext4_end_bio:343: I/O error 3 writing to inode 2883634 starting block 24493839)[0m
[0;31mAborting journal on device zd0-8.[0m
[0;33mEXT4-fs error (device zd0) in ext4_convert_unwritten_io_end_vec:4859: [0;31;1mIO failure[0m
[0;33mEXT4-fs (zd0): [0mfailed to convert unwritten extents to written extents -- potential data loss!  (inode 2883634, error -5)
[0;33mJBD2: [0;31mI/O error when updating journal superblock for zd0-8.[0m
[0;33mEXT4-fs error (device zd0): [0;31;1mext4_journal_check_start:83: comm k3s-server: Detected aborted journal[0m
[0;33mEXT4-fs (zd0): [0;31mprevious I/O error to superblock detected[0m
[0;33mEXT4-fs error (device zd0): [0;31;1mext4_journal_check_start:83: comm http-nio-8080-P: Detected aborted journal[0m
[0;33mEXT4-fs (zd0): [0;31mI/O error while writing superblock[0m
[0;33mEXT4-fs (zd0): [0;31;1mRemounting filesystem read-only[0m
[0;33mEXT4-fs (zd0): [0;31mI/O error while writing superblock
```

- åœæ­¢æœåŠ¡è‡ªåŠ¨å¯åŠ¨
- reboot
- fsck

```bash
umount /dev/zd0
fsck -y /dev/zd0
mount -a

# ensure mount point working as expected
touch /data/docker/test

# start service
```

## zfs destory container snapshots

```bash
zfs list > zfs.txt
# main/1poezhz45yv210xqwve9vft0d
grep -E '^main/\w{25}\W' zfs.txt | cut -f 1 -d ' ' | xargs -n 1 sudo zfs destroy -r -R
```

## Feature Flags

```bash
zpool get all | grep feature@
zpool upgrade -v
```

```
async_destroy                         (read-only compatible)
     Destroy filesystems asynchronously.
empty_bpobj                           (read-only compatible)
     Snapshots use less space.
lz4_compress
     LZ4 compression algorithm support.
multi_vdev_crash_dump
     Crash dumps to multiple vdev pools.
spacemap_histogram                    (read-only compatible)
     Spacemaps maintain space histograms.
enabled_txg                           (read-only compatible)
     Record txg at which a feature is enabled
hole_birth
     Retain hole birth txg for more precise zfs send
extensible_dataset
     Enhanced dataset functionality, used by other features.
embedded_data
     Blocks which compress very well use even less space.
bookmarks                             (read-only compatible)
     "zfs bookmark" command
filesystem_limits                     (read-only compatible)
     Filesystem and snapshot limits.
large_blocks
     Support for blocks larger than 128KB.
large_dnode
     Variable on-disk size of dnodes.
sha512
     SHA-512/256 hash algorithm.
skein
     Skein hash algorithm.
edonr
     Edon-R hash algorithm.
userobj_accounting                    (read-only compatible)
     User/Group object accounting.
encryption
     Support for dataset level encryption
project_quota                         (read-only compatible)
     space/object accounting based on project ID.
device_removal
     Top-level vdevs can be removed, reducing logical pool size.
obsolete_counts                       (read-only compatible)
     Reduce memory used by removed devices when their blocks are freed or remapped.
zpool_checkpoint                      (read-only compatible)
     Pool state can be checkpointed, allowing rewind later.
spacemap_v2                           (read-only compatible)
     Space maps representing large segments are more efficient.
allocation_classes                    (read-only compatible)
     Support for separate allocation classes.
resilver_defer                        (read-only compatible)
     Support for deferring new resilvers when one is already running.
bookmark_v2
     Support for larger bookmarks
redaction_bookmarks
     Support for bookmarks which store redaction lists for zfs redacted send/recv.
redacted_datasets
     Support for redacted datasets, produced by receiving a redacted zfs send stream.
bookmark_written
     Additional accounting, enabling the written#<bookmark> property (space written since a bookmark), and estimates of send stream sizes for incrementals from bookmarks.
log_spacemap                          (read-only compatible)
     Log metaslab changes on a single spacemap and flush them periodically.
livelist                              (read-only compatible)
     Improved clone deletion performance.
device_rebuild                        (read-only compatible)
     Support for sequential mirror/dRAID device rebuilds
zstd_compress
     zstd compression algorithm support.
draid
     Support for distributed spare RAID
zilsaxattr                            (read-only compatible)
     Support for xattr=sa extended attribute logging in ZIL.
head_errlog
     Support for per-dataset on-disk error logs.
blake3
     BLAKE3 hash algorithm.
block_cloning                         (read-only compatible)
     Support for block cloning via Block Reference Table.
vdev_zaps_v2
     Support for root vdev ZAP.
```
