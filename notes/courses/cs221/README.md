---
title: CS221 AI - Principles and Techniques
---

# CS221 AI: Principles and Techniques

- åŸºäºåˆºæ¿€çš„æ¨¡å‹ - [Reflex-based models](./cs221-reflex.md)
- åŸºäºçŠ¶æ€çš„æ¨¡å‹ - [States-based models](./cs221-state.md)
- åŸºäºå˜é‡çš„æ¨¡å‹ - variable
- åŸºäºé€»è¾‘çš„æ¨¡å‹ - logic

---

- https://www.youtube.com/watch?v=J8Eh7RqggsU&list=PLoROMvodv4rO1NB9TD4iUZ3qghGEGtqNX
- https://www.youtube.com/watch?v=ZiwogMtbjr4&list=PLoROMvodv4rOca_Ovz1DvdtWuz8BfSWL2
- shervine [cs-221](https://stanford.edu/~shervine/teaching/cs-221/)

# Stanford CS221: Artificial Intelligence: Principles and Techniques | Autumn 2021

- https://stanford-cs221.github.io/autumn2021/
- [Youtube æ’­æ”¾åˆ—è¡¨](https://www.youtube.com/playlist?list=PLoROMvodv4rOca_Ovz1DvdtWuz8BfSWL2)

## Lession 1: Overview

Reflex-based models
: åŸºäº åå°„/åˆºæ¿€ çš„æ¨¡å‹
: $
\text{\color{orange}input } x
->
\stackrel{\color{orange}\text{predicator}}{\boxed{f(x)} }
->
y \text{\color{orange} output}
$
: æœ€ç®€å•çš„æ¨¡å‹ï¼Œä¸è€ƒè™‘å†å²ï¼Œåªè€ƒè™‘å½“å‰æƒ…å†µ

Binary Classification
: äºŒå…ƒåˆ†ç±»
: $
x ->
\stackrel{\color{orange}\text{classifier}}{\boxed{f(x)} }
-> y \in \color{orange} \{+1,-1\} \text{ \color{red}label}
$
: è¾“å‡ºäºŒå…ƒç»“æœ - true/false, yes/no, positive/negative, 1/-1, 1/0

Regression
: å›å½’
: $
x -> \boxed{f(x)} -> y \in \color{orange} \mathbb{R} \text{ \color{red}response}
$
: è¾“å‡ºå®æ•°ç»“æœ

Structured prediction
: ç»“æ„åŒ–é¢„æµ‹
: $
x -> \boxed{f(x)} -> y \text{ is a } \text{\color{orange}complex object}
$
: è¾“å‡ºå¤æ‚å¯¹è±¡

## Lession 2: Linear Regression

Linear regression framework
: çº¿æ€§å›å½’æ¡†æ¶
: Decision boundary - ä¸€æ¡çº¿
: Hypothesis class - å‡è®¾ç±» - å“ªäº›é¢„æµ‹æ˜¯å¯èƒ½çš„
: Loss function - æŸå¤±å‡½æ•° - å¦‚ä½•è¡¡é‡é¢„æµ‹çš„å¥½å
: Optimization algorithm - ä¼˜åŒ–ç®—æ³• - å¦‚ä½•æ‰¾åˆ°æœ€å¥½çš„é¢„æµ‹

Hypothesis class
: å‡è®¾ç±»
: å“ªäº›é¢„æµ‹æ˜¯å¯èƒ½çš„

$$
\begin{alignat*}{2}
\mathcal{F}
&=\{ f_\mathbf{w} : \mathbf{w} \in \mathbb R ^d \} \\
&=\{ f_\mathbf{w} = \mathbf{w} \cdot \phi(x) : \mathbf w \in \mathbb R ^d \}
\end{alignat*}
$$

**ç¬¦å·è¯´æ˜**

| name              | notation                      | å«ä¹‰       |
| ----------------- | ----------------------------- | ---------- |
| weight vector     | $\mathbf w = [ w_1, w_2 ]$    | æƒé‡å‘é‡   |
| feature extractor | $\phi(x)$                     | ç‰¹å¾æå–å™¨ |
| feature vector    | $\phi(x)=\color{red}[1,x]$    | ç‰¹å¾å‘é‡   |
| train set         | $\mathcal D _ \textrm{train}$ | è®­ç»ƒé›†     |
| test set          | $\mathcal D _ \textrm{test}$  | æµ‹è¯•é›†     |

Feature vector
: ç‰¹å¾å‘é‡
: ç‰¹å¾å·¥ç¨‹ - feature-engineering
: å°†åŸå§‹æ•°æ®æŠ½è±¡ä¸ºç‰¹å¾å‘é‡

$$
\phi(x)=
  \begin{bmatrix}
    \phi_1(x)\\
    \vdots\\
    \phi_d(x)
  \end{bmatrix}
  \in
  \reals^d
$$


Score
: åˆ†æ•°
: å¦‚æœæ˜¯æœ€ç»ˆç»“æœï¼Œåˆ™ä»£é’ˆå¯¹æŸä¸ªç»“è®ºçš„è‚¯å®šç¨‹åº¦
: $
s(x,\mathbf w) = \mathbf w \cdot \phi(x) = \sum _{i=1}^d \mathbf w_i \phi_i(x)
$

- w - weight - æƒé‡
  - å¯¹äºä¸€ä¸ªè¾“å‡ºï¼Œä¸åŒçš„ç‰¹å¾å¯¹è¾“å‡ºçš„å½±å“ä¸åŒ
  - ä¾‹å¦‚: ä¸€ä¸ªäººçš„èº«é«˜ï¼Œä½“é‡ï¼Œå¹´é¾„ï¼Œæ€§åˆ«ï¼Œå¯¹äº æ€§åˆ«å’Œå¹´é¾„ çš„å½±å“ä¸åŒ
- s - score - åˆ†æ•°
  - ç‰¹å¾\*æƒé‡
  - ä¾‹å¦‚: 0.78 æ˜¯ ç”·æ€§


Loss function
: æŸå¤±å‡½æ•°
: è¯„ä»·æ¨¡å‹çš„**é¢„æµ‹å€¼**å’Œ**çœŸå®å€¼**ä¸ä¸€æ ·çš„ç¨‹åº¦
: åˆ†ä¸º **ç»éªŒé£é™©æŸå¤±å‡½æ•°** å’Œ **ç»“æ„é£é™©æŸå¤±å‡½æ•°**

$$
\text{Loss}(x,y,\mathbf w) = 1[f_\mathbf w (x) \ne y] \text{\color{orange} zero-one loss}
$$

$$
\text{Loss}(x,y,\mathbf w) = (f_\mathbf w(x) - y)^2 \text{\color{orange} squared loss}
$$

TrainLoss
: è®­ç»ƒæŸå¤±
: åœ¨è®­ç»ƒä¸­å¸Œæœ›**å‡å°**çš„å€¼
: value of the objective function that you are minimizing

$$
\textrm{TrainLoss}(\mathbf w)=
\frac{1}{|\mathcal{D}_{\textrm{train}}|}\sum_{(x,y)\in\mathcal{D}_{\textrm{train}}}\textrm{Loss}(x,y,\mathbf w)
$$

:::tip æœºå™¨å­¦ä¹ ç›®æ ‡

**æœ€å°åŒ– TrainLoss/è®­ç»ƒæŸå¤±**

$$
\text{min}_\mathbf w \textrm{TrainLoss}(\mathbf w)
$$

:::

gradient
: the gradient $\nabla_\mathbf w\textrm{TrainLoss}(\mathbf w)$ is the direction that increases the training loss the most
: æ¢¯åº¦ æ˜¯è®©è®­ç»ƒæŸå¤±æœ€å¤§åŒ–çš„æ–¹å‘
: $\nabla_\mathbf w \textrm{Loss}(x,y,\mathbf w)$
: $\nabla_\mathbf w\textrm{TrainLoss}(\mathbf w)$

:::tip gradient descent - æ¢¯åº¦ä¸‹é™ç®—æ³•

- åˆå§‹åŒ– $\mathbf w = [0,...,0]$
- for $t = 1,..., T \text{ \tiny\color{orange}å‘¨æœŸ/epoch}$
  - $
\mathbf w \longleftarrow
\mathbf w -
  \underbrace{ \color{red} \eta  }_{\text{step size}}
  \underbrace{ \color{purple} \nabla_\mathbf w\textrm{TrainLoss}(\mathbf w) }_{\text{gradient}}
$

> - $\eta \in \mathbb R$
>   - learning rate - step size
>   - å­¦ä¹ é€Ÿç‡ - æ¯æ¬¡æ›´æ–°å¤šå°‘
> - æƒé‡ $\mathbf w$ åœ¨æ¯ä¸ªå‘¨æœŸè¢«æ›´æ–° - **Machine å­¦ä¹ çš„å†…å®¹**

![](https://stanford.edu/~shervine/teaching/cs-221/illustrations/gradient-descent.png)

:::

Objective function
: ç›®æ ‡å‡½æ•°
: ç»Ÿç§°
: loss function **is a part of** a cost function **which is a type of** an objective function.
: Objective function ä¸€èˆ¬æŒ‡éœ€è¦ **ä¼˜åŒ–** çš„å‡½æ•°
: Loss/Cost function ä¸€èˆ¬æŒ‡éœ€è¦ **æœ€å°åŒ–** çš„å‡½æ•°

$$
\begin{alignat*}{2}
\textrm{TrainLoss}(\mathbf w)
&=\frac{1}{|\mathcal{D}_{\textrm{train}}|}
  \sum_{(x,y)\in\mathcal{D}_{\textrm{train}}}
  \textrm{Loss}(x,y,\mathbf w) \\
&=\frac{1}{|\mathcal{D}_{\textrm{train}}|}
  \sum_{(x,y)\in\mathcal{D}_{\textrm{train}}}
  (\mathbf w \cdot \phi(x) - y)^2 \text{ \tiny\color{orange}squared loss}
\end{alignat*}
$$

> **Note** ä½¿ç”¨æ¯ä¸ª loss çš„å¹³å‡ä½œä¸ºåˆå§‹ TrainLoss

$$
\nabla_\mathbf w\textrm{TrainLoss}(\mathbf w)=
  \frac 1 {|\mathcal{D}_{\textrm{train}}|}
  \sum_{(x,y)\in\mathcal{D}_{\textrm{train}}}
  2(
    \underbrace{
    {\color{red} \mathbf w \cdot \phi(x)} - {\color{green}y}
    }_{\text{{\color{red}predication} - \color{green}target}}
  ) \phi(x)
$$

> **Note**
>
> - $()^2 \longrightarrow 2()$ çš„ gradient/$\nabla$ çš„è½¬æ¢é€»è¾‘åé¢ä¼šè®²åˆ°
> - ä½¿ç”¨ squared loss çš„ gradient

import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import {Lession2Demo} from '@theme/CS221';

<Admonition type="note" icon="ğŸ’¡" title="Demo">

<details>

<summary>ä»£ç :</summary>

<Tabs>
  <TabItem value="javascript" label="JavaScript" default>

```js
function train({ iterations = 200, learningRate = 0.1, log = console.log.bind(console) } = {}) {
  // è®­ç»ƒé›†
  const trainSet = [
    [1, 1],
    [2, 3],
    [4, 3],
  ];
  log(`train epochs:${iterations} eta:${learningRate}`);
  // Optimization problem
  // 1/3 * sum((w*phi(x) - y) ^ 2)
  const trainLoss = (w) => {
    let sum = 0;
    for (const [x, y] of trainSet) {
      sum += (w[0] * 1 + w[1] * x - y) ** 2;
    }
    return sum * (1 / trainSet.length);
  };
  // 1/3 * sum(2(w*phi(x) - y)phi(x))
  const gradientTrainLoss = (w) => {
    let sum = [0, 0];
    for (const [x, y] of trainSet) {
      let d = 2 * (w[0] * 1 + w[1] * x - y);
      let z = [d * 1, d * x];
      sum = [sum[0] + z[0], sum[1] + z[1]];
    }
    const loss = [sum[0] * (1.0 / trainSet.length), sum[1] * (1.0 / trainSet.length)];
    return loss;
  };
  // Optimization algorithm
  const gradientDescent = (F, gradientF, initialWeightVector) => {
    let w = initialWeightVector;
    let eta = learningRate;
    for (let i = 0; i < iterations; i++) {
      let value = F(w);
      let gradient = gradientF(w);
      w = [w[0] - eta * gradient[0], w[1] - eta * gradient[1]];
      //
      log(`epoch ${i + 1}:`, `w: ${w}, F(w)=${value}, gradient: ${gradient}`);
    }
    return w;
  };
  const w = gradientDescent(trainLoss, gradientTrainLoss, [0, 0]);
  log(`w: ${w}`);
  return { w };
}
```

  </TabItem>
</Tabs>

</details>

<Lession2Demo/>

![](./assets/lesson2-demo.svg)

</Admonition>

:::tip å‘é‡è®¡ç®—

$$
\begin{pmatrix}
  a_1&a_2
\end{pmatrix}
\cdot
\begin{pmatrix}
  b_1&b_2
\end{pmatrix} = a_1b_1+a_2b_2
$$

:::

## Lession 3: Linear Classification

- which classfiers are possible - æœ‰å“ªäº›å¯èƒ½åˆ†ç±»å™¨ - å‡è®¾ç±» - hypothesis class
- how good is a classifier - è¯„ä»·æ ‡å‡† - æŸå¤±å‡½æ•° - loss function
- how to compute the best classifier - å¦‚ä½•è®¡ç®— - ä¼˜åŒ–ç®—æ³• - optimization algorithm

Decision boundary
: å†³ç­–è¾¹ç•Œ
: $x$ for $\mathbf w \cdot \phi(x) = 0$

Binary classfier
: äºŒåˆ†ç±»å™¨
: $f_\mathbf w(x) = \text{sign}(\mathbf w \cdot \phi(x))$
  - è¾“å‡º label
: $\mathbf w \cdot \phi(x) \geq 0 \longrightarrow y = +1$


Hypothesis class
: å‡è®¾ç±»
: $\mathcal{F}=\{ f_\mathbf{w} : \mathbf{w} \in \mathbb R ^2 \}$

score
: åˆ†æ•°
: $\mathbf w \cdot \phi(x)$
: å¯ä¿¡åº¦ - how **confident** the classifier is

margin
: è¾¹è·
: $(\mathbf w \cdot \phi(x))y$
: æ­£ç¡®åº¦ - how **correct** the classifier is

Loss function
: æŸå¤±å‡½æ•°

$$
\begin{alignat*}{2}
\text{Loss}_{0-1}(x,y,\mathbf w)
  &= 1[f_\mathbf w (x) \ne y] \\
  &= 1[
    \underbrace{(\mathbf w \cdot \phi(x))y}_\text{margin}
     \le 0] \\
\end{alignat*}
$$

![zero one loss margin](./assets/loss-zero-one.svg)



**è®­ç»ƒç›®æ ‡**
$$\text{min}_\mathbf w \text{TrainLoss}(\mathbf w)$$
**æ¢¯åº¦ä¸‹é™**
$$
\nabla_\mathbf w\text{TrainLoss}(\mathbf w)=\sum_{(x,y)\in \mathcal D _ \textrm{train}} \nabla\text{Loos}_{0-1}(x,y,\mathbf w)
$$

$$
\nabla\text{Loos}_{0-1}(x,y,\mathbf w)
=\nabla 1[(\mathbf w \cdot \phi(x))y \le 0]
$$

- ç”±äºä½¿ç”¨äº† zero-one lossï¼Œæ­¤æ—¶æ¢¯åº¦å¤§å¤šæ•°éƒ½æ˜¯ä¸º 0
- å› æ­¤æ— æ³•æ­£å¸¸ä¸‹é™ï¼Œéœ€è¦ä½¿ç”¨å…¶ä»–æŸå¤±å‡½æ•°

Hinge loss
: é¿å… zero-one loss &le; 0 æ—¶å¤§å¤šä¸º 0 çš„é—®é¢˜

$$
\text{Loos}_\text{hinge}(x,y,\mathbf w)
= \mathrm{max}\{{\color{orange}1 - (\mathbf w\cdot \phi(x))y}, 0\}
$$

$$
\nabla\text{Loos}_\text{hinge}(x,y,\mathbf w)=
\begin{cases}
  -\phi(x) y & \text{if} \space {\color{orange}1- (\mathbf w \cdot \phi(x))y} > 0 \\
  0 & \text{otherwise}
\end{cases}
$$

Logistic loss
: åœ¨è¶…è¿‡ 1 åè¿˜åœ¨å°è¯•å¢åŠ  margin

$$
\text{Loos}_\text{logistic}(x,y,\mathbf w)
= \text{log}(1+e^{âˆ’(\mathbf w \cdot \phi(x))y})
$$

![loss-hinge-and-zero-one](./assets/loss-hinge-and-zero-one-and-logistic.svg)

<!-- TODO DEMO -->

<Admonition type="note" icon="ğŸ’¡" title="Demo">

<details>

<summary>ä»£ç :</summary>
TODO
</details>

TODO

![](./assets/lesson3-demo.svg)

</Admonition>

## Lession 4: SGD

## Lession 5: Group DRO

## Lession 6: Non-Linear Features

## Lession 7: Feature Template

## Lession 8: Neural Networks

## Lession 9: Backpropagation

## Lession 10: Differentiable Programming

## Lession 11: Generalization

## Lession 12: Best Practices

## Lession 13: K-means

# Misc

Cost function
: sum of loss &times; weight
: Mean Squared Error
