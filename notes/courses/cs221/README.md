---
title: CS221 AI
---

# CS221 AI

- åŸºäºåˆºæ¿€çš„æ¨¡å‹ - [Reflex-based models](./cs221-reflex.md)
- åŸºäºçŠ¶æ€çš„æ¨¡å‹ - [States-based models](./cs221-state.md)
- åŸºäºå˜é‡çš„æ¨¡å‹ - variable
- åŸºäºé€»è¾‘çš„æ¨¡å‹ - logic

---

- https://www.youtube.com/watch?v=J8Eh7RqggsU&list=PLoROMvodv4rO1NB9TD4iUZ3qghGEGtqNX
- https://www.youtube.com/watch?v=ZiwogMtbjr4&list=PLoROMvodv4rOca_Ovz1DvdtWuz8BfSWL2
- shervine [cs-221](https://stanford.edu/~shervine/teaching/cs-221/)

# Stanford CS221: Artificial Intelligence: Principles and Techniques | Autumn 2021

- https://stanford-cs221.github.io/autumn2021/
- [Youtube æ’­æ”¾åˆ—è¡¨](https://www.youtube.com/playlist?list=PLoROMvodv4rOca_Ovz1DvdtWuz8BfSWL2)

## Lession 1: Overview

Reflex-based models
: åŸºäº åå°„/åˆºæ¿€ çš„æ¨¡å‹
: $
\text{\color{orange}input } x
->
\stackrel{\color{orange}\text{predicator}}{\boxed{f(x)} }
->
y \text{\color{orange} output}
$
: æœ€ç®€å•çš„æ¨¡å‹ï¼Œä¸è€ƒè™‘å†å²ï¼Œåªè€ƒè™‘å½“å‰æƒ…å†µ

Binary Classification
: äºŒå…ƒåˆ†ç±»
: $
x ->
\stackrel{\color{orange}\text{classifier}}{\boxed{f(x)} }
-> y \in \color{orange} \{+1,-1\} \text{ \color{red}label}
$
: è¾“å‡ºäºŒå…ƒç»“æœ - true/false, yes/no, positive/negative, 1/-1, 1/0

Regression
: å›å½’
: $
x -> \boxed{f(x)} -> y \in \color{orange} \mathbb{R} \text{ \color{red}response}
$
: è¾“å‡ºå®æ•°ç»“æœ

Structured prediction
: ç»“æ„åŒ–é¢„æµ‹
: $
x -> \boxed{f(x)} -> y \text{ is a } \text{\color{orange}complex object}
$
: è¾“å‡ºå¤æ‚å¯¹è±¡

## Lession 2: Linear Regression

Linear regression framework
: çº¿æ€§å›å½’æ¡†æ¶
: Decision boundary - ä¸€æ¡çº¿
: Hypothesis class - å‡è®¾ç±» - å“ªäº›é¢„æµ‹æ˜¯å¯èƒ½çš„
: Loss function - æŸå¤±å‡½æ•° - å¦‚ä½•è¡¡é‡é¢„æµ‹çš„å¥½å
: Optimization algorithm - ä¼˜åŒ–ç®—æ³• - å¦‚ä½•æ‰¾åˆ°æœ€å¥½çš„é¢„æµ‹

Hypothesis class
: å‡è®¾ç±»
: å“ªäº›é¢„æµ‹æ˜¯å¯èƒ½çš„

$$
\begin{alignat*}{2}
\mathcal{F}
&=\{ f_\mathbf{w} : \mathbf{w} \in \mathbb R ^d \} \\
&=\{ f_\mathbf{w} = \mathbf{w} \cdot \phi(x) : \mathbf w \in \mathbb R ^d \}
\end{alignat*}
$$

**ç¬¦å·è¯´æ˜**

| name              | notation                      | å«ä¹‰       |
| ----------------- | ----------------------------- | ---------- |
| weight vector     | $\mathbf w = [ w_1, w_2 ]$    | æƒé‡å‘é‡   |
| feature extractor | $\phi(x)$                     | ç‰¹å¾æå–å™¨ |
| feature vector    | $\phi(x)=\color{red}[1,x]$    | ç‰¹å¾å‘é‡   |
| train set         | $\mathcal D _ \textrm{train}$ | è®­ç»ƒé›†     |
| test set          | $\mathcal D _ \textrm{test}$  | æµ‹è¯•é›†     |

Loss function
: æŸå¤±å‡½æ•°

$$
\text{Loss}(x,y,\mathbf w) = 1[f_\mathbf w (x) \ne y] \text{\color{orange} zero-one loss}
$$

$$
\text{Loss}(x,y,\mathbf w) = (f_\mathbf w(x) - y)^2 \text{\color{orange} squared loss}
$$

$$
\textrm{TrainLoss}(\mathbf w)=
\frac{1}{|\mathcal{D}_{\textrm{train}}|}\sum_{(x,y)\in\mathcal{D}_{\textrm{train}}}\textrm{Loss}(x,y,\mathbf w)
$$

:::tip æœºå™¨å­¦ä¹ ç›®æ ‡

**æœ€å°åŒ– TrainLoss**

$$
\text{min}_\mathbf w \textrm{TrainLoss}(\mathbf w)
$$

:::

gradient
: the gradient $\nabla_\mathbf w\textrm{TrainLoss}(\mathbf w)$ is the direction that increases the training loss the most
: æ¢¯åº¦ æ˜¯è®©è®­ç»ƒæŸå¤±æœ€å¤§åŒ–çš„æ–¹å‘
: $\nabla_\mathbf w \textrm{Loss}(x,y,\mathbf w)$
: $\nabla_\mathbf w\textrm{TrainLoss}(\mathbf w)$

:::tip gradient descent - æ¢¯åº¦ä¸‹é™ç®—æ³•

- åˆå§‹åŒ– $\mathbf w = [0,...,0]$
- for $t = 1,..., T \text{ \tiny\color{orange}å‘¨æœŸ/epoch}$
  - $
\mathbf w \longleftarrow
\mathbf w -
  \underbrace{ \color{red} \eta  }_{\text{step size}}
  \underbrace{ \color{purple} \nabla_\mathbf w\textrm{TrainLoss}(\mathbf w) }_{\text{gradient}}
$

> - $\eta \in \mathbb R$
>   - learning rate - step size
>   - å­¦ä¹ é€Ÿç‡ - æ¯æ¬¡æ›´æ–°å¤šå°‘
> - æƒé‡ $\mathbf w$ åœ¨æ¯ä¸ªå‘¨æœŸè¢«æ›´æ–° - **Machine å­¦ä¹ çš„å†…å®¹**

![](https://stanford.edu/~shervine/teaching/cs-221/illustrations/gradient-descent.png)

:::

Objective function
: åˆå§‹åŒ– **æƒé‡** çš„å‡½æ•°

$$
\begin{alignat*}{2}
\textrm{TrainLoss}(\mathbf w)
&=\frac{1}{|\mathcal{D}_{\textrm{train}}|}
  \sum_{(x,y)\in\mathcal{D}_{\textrm{train}}}
  \textrm{Loss}(x,y,\mathbf w) \\
&=\frac{1}{|\mathcal{D}_{\textrm{train}}|}
  \sum_{(x,y)\in\mathcal{D}_{\textrm{train}}}
  (\mathbf w \cdot \phi(x) - y)^2 \text{ \tiny\color{orange}squared loss}
\end{alignat*}
$$

> **Note** ä½¿ç”¨æ¯ä¸ª loss çš„å¹³å‡ä½œä¸ºåˆå§‹ TrainLoss

$$
\nabla_\mathbf w\textrm{TrainLoss}(\mathbf w)=
  \frac 1 {|\mathcal{D}_{\textrm{train}}|}
  \sum_{(x,y)\in\mathcal{D}_{\textrm{train}}}
  2(
    \underbrace{
    {\color{red} \mathbf w \cdot \phi(x)} - {\color{green}y}
    }_{\text{{\color{red}predication} - \color{green}target}}
  ) \phi(x)
$$

> **Note**
>
> - $()^2 \longrightarrow 2()$ çš„ gradient/$\nabla$ çš„è½¬æ¢é€»è¾‘åé¢ä¼šè®²åˆ°
> - ä½¿ç”¨ squared loss çš„ gradient

import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import {Lession2Demo} from '@theme/CS221';

<Admonition type="tip" icon="ğŸ’¡" title="Demo">

<details>

<summary>ä»£ç :</summary>



<Tabs>
  <TabItem value="javascript" label="JavaScript" default>

```js
function train({ iterations = 200, learningRate = 0.1, log = console.log.bind(console) } = {}) {
  // è®­ç»ƒé›†
  const trainSet = [
    [1, 1],
    [2, 3],
    [4, 3],
  ];
  log(`train epochs:${iterations} eta:${learningRate}`);
  // Optimization problem
  // 1/3 * sum((w*phi(x) - y) ^ 2)
  const trainLoss = (w) => {
    let sum = 0;
    for (const [x, y] of trainSet) {
      sum += (w[0] * 1 + w[1] * x - y) ** 2;
    }
    return sum * (1 / trainSet.length);
  };
  // 1/3 * sum(2(w*phi(x) - y)phi(x))
  const gradientTrainLoss = (w) => {
    let sum = [0, 0];
    for (const [x, y] of trainSet) {
      let d = 2 * (w[0] * 1 + w[1] * x - y);
      let z = [d * 1, d * x];
      sum = [sum[0] + z[0], sum[1] + z[1]];
    }
    const loss = [sum[0] * (1.0 / trainSet.length), sum[1] * (1.0 / trainSet.length)];
    return loss;
  };
  // Optimization algorithm
  const gradientDescent = (F, gradientF, initialWeightVector) => {
    let w = initialWeightVector;
    let eta = learningRate;
    for (let i = 0; i < iterations; i++) {
      let value = F(w);
      let gradient = gradientF(w);
      w = [w[0] - eta * gradient[0], w[1] - eta * gradient[1]];
      //
      log(`epoch ${i + 1}:`, `w: ${w}, F(w)=${value}, gradient: ${gradient}`);
    }
    return w;
  };
  const w = gradientDescent(trainLoss, gradientTrainLoss, [0, 0]);
  log(`w: ${w}`);
  return { w };
}
```

  </TabItem>
</Tabs>

</details>


<Lession2Demo/>

</Admonition>

:::tip å‘é‡è®¡ç®—

$$
\begin{pmatrix}
  a_1&a_2
\end{pmatrix}
\cdot
\begin{pmatrix}
  b_1&b_2
\end{pmatrix} = a_1b_1+a_2b_2
$$

:::

## Lession 3: Linear Classification

## Lession 4: SGD

## Lession 5: Group DRO

## Lession 6: Non-Linear Features

## Lession 7: Feature Template

## Lession 8: Neural Networks

## Lession 9: Backpropagation

## Lession 10: Differentiable Programming

## Lession 11: Generalization

## Lession 12: Best Practices

## Lession 13: K-means
