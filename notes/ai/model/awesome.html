<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-ai/model/ai-model-awesome" data-has-hydrated=false><head><meta charset=UTF-8><meta name=generator content="Docusaurus v3.9.1"><title data-rh=true>Models | Wener Live & Life</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"/><meta data-rh=true name=twitter:card content=summary_large_image /><meta data-rh=true property=og:url content=https://wener.me/notes/ai/model/awesome /><meta data-rh=true property=og:locale content=en /><meta data-rh=true name=docusaurus_locale content=en /><meta data-rh=true name=docsearch:language content=en /><meta data-rh=true name=docusaurus_version content=current /><meta data-rh=true name=docusaurus_tag content=docs-default-current /><meta data-rh=true name=docsearch:version content=current /><meta data-rh=true name=docsearch:docusaurus_tag content=docs-default-current /><meta data-rh=true property=og:title content="Models | Wener Live & Life"/><meta data-rh=true name=description content="Open Weights/Transformer"/><meta data-rh=true property=og:description content="Open Weights/Transformer"/><link data-rh=true rel=icon href=/img/favicon.ico /><link data-rh=true rel=canonical href=https://wener.me/notes/ai/model/awesome /><link data-rh=true rel=alternate href=https://wener.me/notes/ai/model/awesome hreflang=en /><link data-rh=true rel=alternate href=https://wener.me/notes/ai/model/awesome hreflang=x-default /><link data-rh=true rel=preconnect href=https://37P8DMWBKF-dsn.algolia.net crossorigin=anonymous /><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://wener.me/notes/ai/","name":"AI","position":1},{"@type":"ListItem","item":"https://wener.me/notes/ai/model/awesome","name":"Models","position":2}]}</script><link rel=alternate type=application/rss+xml href=/story/rss.xml title="Wener Live & Life RSS Feed"><link rel=alternate type=application/atom+xml href=/story/atom.xml title="Wener Live & Life Atom Feed"><link rel=preconnect href=https://www.google-analytics.com><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-30404720-1","auto"),ga("send","pageview")</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=UA-30404720-1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-30404720-1",{})</script><link rel=search type=application/opensearchdescription+xml title="Wener Live & Life" href=/opensearch.xml><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css><script src=https://static.cloudflareinsights.com/beacon.min.js async data-cf-beacon='{"token": "e9a1b931103044f3940ee67b78c7df70"}' defer></script><link rel=stylesheet href=/assets/css/styles.fa221ee1.css /><script src=/assets/js/runtime~main.72c320db.js defer></script><script src=/assets/js/main.c07313b6.js defer></script></head><body class=navigation-with-keyboard><svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_jKDA href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="theme-layout-navbar navbar navbar--fixed-top"><div class=navbar__inner><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/><div class=navbar__logo><img src=/img/wener-logo-head.svg alt="Wener Logo" class="themedComponent_j2y5 themedComponent--light_v877"/><img src=/img/wener-logo-head.svg alt="Wener Logo" class="themedComponent_j2y5 themedComponent--dark_PUQY"/></div><b class="navbar__title text--truncate">Wener</b></a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/notes>笔记</a><a class="navbar__item navbar__link" href=/story>故事</a><a class="navbar__item navbar__link" href=/notes/howto/network/dns-prevent-spoofing>指南</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href=https://github.com/wenerme/wener target=_blank rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width=13.5 height=13.5 aria-label="(opens in new tab)" class=iconExternalLink_kUGX><use href=#theme-svg-external-link /></svg></a><div class="toggle_N7Mq colorModeToggle_vh_y"><button class="clean-btn toggleButton_PaHe toggleButtonDisabled_RC4w" type=button disabled title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_Q188 lightToggleIcon_M1mU"><path fill=currentColor d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"/></svg><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_Q188 darkToggleIcon_sEdo"><path fill=currentColor d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"/></svg><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_Q188 systemToggleIcon_cOyE"><path fill=currentColor d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"/></svg></button></div><div class=navbarSearchContainer_d_Bn><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Meta+k)" aria-keyshortcuts=Meta+k><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 24 24" aria-hidden=true><circle cx=11 cy=11 r=8 stroke=currentColor fill=none stroke-width=1.4 /><path d="m21 21-4.3-4.3" stroke=currentColor fill=none stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="theme-layout-main main-wrapper mainWrapper_c22C"><div class=docsWrapper_oymo><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_ZPA9" type=button></button><div class=docRoot_ng2Q><aside class="theme-doc-sidebar-container docSidebarContainer_nyHU"><div class=sidebarViewport_rLoj><div class=sidebar_TmDF><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_jRin"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/notes><span title=笔记 class=linkLabel_JPPZ>笔记</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false href=/notes/adobe/photoshop><span title=adobe class=categoryLinkLabel_RkOu>adobe</span></a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist menu__link--active" href=/notes/ai><span title=AI class=categoryLinkLabel_RkOu>AI</span></a><button aria-label="Collapse sidebar category 'AI'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/awesome><span title="AI Awesome" class=linkLabel_JPPZ>AI Awesome</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/faq><span title="AI FAQ" class=linkLabel_JPPZ>AI FAQ</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/glossary><span title="AI Glossary" class=linkLabel_JPPZ>AI Glossary</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/notes/ai/coding/continue><span title=coding class=categoryLinkLabel_RkOu>coding</span></a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/notes/ai/dev/agent/awesome><span title=dev class=categoryLinkLabel_RkOu>dev</span></a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/diffusion><span title=Diffusion class=categoryLinkLabel_RkOu>Diffusion</span></a><button aria-label="Expand sidebar category 'Diffusion'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/embedding><span title=Embedding class=linkLabel_JPPZ>Embedding</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/gan><span title=GANs class=categoryLinkLabel_RkOu>GANs</span></a><button aria-label="Expand sidebar category 'GANs'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/gpt><span title=GPT class=categoryLinkLabel_RkOu>GPT</span></a><button aria-label="Expand sidebar category 'GPT'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/inference><span title=推理 class=categoryLinkLabel_RkOu>推理</span></a><button aria-label="Expand sidebar category '推理'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/llm><span title=LLM class=categoryLinkLabel_RkOu>LLM</span></a><button aria-label="Expand sidebar category 'LLM'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/ml><span title=机器学习 class=categoryLinkLabel_RkOu>机器学习</span></a><button aria-label="Expand sidebar category '机器学习'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role=button aria-expanded=true tabindex=0 href=/notes/ai/model/awesome><span title=model class=categoryLinkLabel_RkOu>model</span></a></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/notes/ai/model/awesome><span title=Models class=linkLabel_JPPZ>Models</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/alpaca><span title=Alpaca class=linkLabel_JPPZ>Alpaca</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/bagel><span title=BAGEL class=linkLabel_JPPZ>BAGEL</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/birefnet><span title=BiRefNet class=linkLabel_JPPZ>BiRefNet</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/cosyvoice><span title=CosyVoice class=linkLabel_JPPZ>CosyVoice</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/model/dino><span title=DINO class=categoryLinkLabel_RkOu>DINO</span></a><button aria-label="Expand sidebar category 'DINO'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/dots-ocr><span title=dots.ocr class=linkLabel_JPPZ>dots.ocr</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/flux><span title=FLUX class=linkLabel_JPPZ>FLUX</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/glm><span title=GLM class=linkLabel_JPPZ>GLM</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/hunyuan><span title=混元 class=linkLabel_JPPZ>混元</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/img2img-turbo><span title=img2img-turbo class=linkLabel_JPPZ>img2img-turbo</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/img2img><span title=img2img class=linkLabel_JPPZ>img2img</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/internvl><span title=InternVL class=linkLabel_JPPZ>InternVL</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/kokoro><span title=kokoro class=linkLabel_JPPZ>kokoro</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/ltx-video><span title=LTX-Video class=linkLabel_JPPZ>LTX-Video</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/omniconsistency><span title=OmniConsistency class=linkLabel_JPPZ>OmniConsistency</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/omniparser><span title=OmniParser class=linkLabel_JPPZ>OmniParser</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/qwen><span title=QwenLM class=linkLabel_JPPZ>QwenLM</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/model/stable-diffusion><span title="Stable Diffusion" class=categoryLinkLabel_RkOu>Stable Diffusion</span></a><button aria-label="Expand sidebar category 'Stable Diffusion'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/model/voxtral><span title=Voxtral class=linkLabel_JPPZ>Voxtral</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/model/yolo><span title=Yolo class=categoryLinkLabel_RkOu>Yolo</span></a><button aria-label="Expand sidebar category 'Yolo'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/ner><span title="Named Entity Recognition" class=linkLabel_JPPZ>Named Entity Recognition</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/nlp><span title=NLP class=categoryLinkLabel_RkOu>NLP</span></a><button aria-label="Expand sidebar category 'NLP'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/ocr><span title=OCR class=categoryLinkLabel_RkOu>OCR</span></a><button aria-label="Expand sidebar category 'OCR'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/precision><span title=精度 class=linkLabel_JPPZ>精度</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/prompt-awesome><span title="Prompt Awesome" class=linkLabel_JPPZ>Prompt Awesome</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/service><span title="AI Service" class=categoryLinkLabel_RkOu>AI Service</span></a><button aria-label="Expand sidebar category 'AI Service'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/traning><span title=训练 class=categoryLinkLabel_RkOu>训练</span></a><button aria-label="Expand sidebar category '训练'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/notes/ai/vision><span title=视觉 class=linkLabel_JPPZ>视觉</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" tabindex=0 href=/notes/ai/voice><span title=Voice class=categoryLinkLabel_RkOu>Voice</span></a><button aria-label="Expand sidebar category 'Voice'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/algorithm><span title=算法 class=categoryLinkLabel_RkOu>算法</span></a><button aria-label="Expand sidebar category '算法'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/blockchain><span title=区块链 class=categoryLinkLabel_RkOu>区块链</span></a><button aria-label="Expand sidebar category '区块链'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/cn><span title=CN class=categoryLinkLabel_RkOu>CN</span></a><button aria-label="Expand sidebar category 'CN'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/courses><span title=课程 class=categoryLinkLabel_RkOu>课程</span></a><button aria-label="Expand sidebar category '课程'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/culture><span title=文化 class=categoryLinkLabel_RkOu>文化</span></a><button aria-label="Expand sidebar category '文化'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/db><span title=数据库 class=categoryLinkLabel_RkOu>数据库</span></a><button aria-label="Expand sidebar category '数据库'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/dev><span title=开发 class=categoryLinkLabel_RkOu>开发</span></a><button aria-label="Expand sidebar category '开发'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/devops><span title=DevOps class=categoryLinkLabel_RkOu>DevOps</span></a><button aria-label="Expand sidebar category 'DevOps'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/economics><span title=经济学 class=categoryLinkLabel_RkOu>经济学</span></a><button aria-label="Expand sidebar category '经济学'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/electrical><span title=电学基础 class=categoryLinkLabel_RkOu>电学基础</span></a><button aria-label="Expand sidebar category '电学基础'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false href=/notes/embedded/awesome><span title=embedded class=categoryLinkLabel_RkOu>embedded</span></a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/evolve><span title=自我成长 class=categoryLinkLabel_RkOu>自我成长</span></a><button aria-label="Expand sidebar category '自我成长'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/hardware><span title=硬件 class=categoryLinkLabel_RkOu>硬件</span></a><button aria-label="Expand sidebar category '硬件'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/healthcare><span title=健康 class=categoryLinkLabel_RkOu>健康</span></a><button aria-label="Expand sidebar category '健康'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false href=/notes/howto/network/dns-prevent-spoofing><span title=howto class=categoryLinkLabel_RkOu>howto</span></a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/java><span title=Java class=categoryLinkLabel_RkOu>Java</span></a><button aria-label="Expand sidebar category 'Java'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/languages><span title=语言 class=categoryLinkLabel_RkOu>语言</span></a><button aria-label="Expand sidebar category '语言'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/notes/linguistics><span title=Linguistics class=linkLabel_JPPZ>Linguistics</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/math><span title=数学 class=categoryLinkLabel_RkOu>数学</span></a><button aria-label="Expand sidebar category '数学'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/mgmt><span title=管理 class=categoryLinkLabel_RkOu>管理</span></a><button aria-label="Expand sidebar category '管理'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false href=/notes/network/application/dns><span title=network class=categoryLinkLabel_RkOu>network</span></a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/ops><span title=运维 class=categoryLinkLabel_RkOu>运维</span></a><button aria-label="Expand sidebar category '运维'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/os><span title=操作系统 class=categoryLinkLabel_RkOu>操作系统</span></a><button aria-label="Expand sidebar category '操作系统'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/philosophy><span title=理念 class=categoryLinkLabel_RkOu>理念</span></a><button aria-label="Expand sidebar category '理念'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/photography><span title=摄影 class=categoryLinkLabel_RkOu>摄影</span></a><button aria-label="Expand sidebar category '摄影'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/platform><span title=平台 class=categoryLinkLabel_RkOu>平台</span></a><button aria-label="Expand sidebar category '平台'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false href=/notes/psychology/glossary><span title=psychology class=categoryLinkLabel_RkOu>psychology</span></a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/queue><span title=Queue class=categoryLinkLabel_RkOu>Queue</span></a><button aria-label="Expand sidebar category 'Queue'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/security><span title=安全 class=categoryLinkLabel_RkOu>安全</span></a><button aria-label="Expand sidebar category '安全'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/service><span title=服务 class=categoryLinkLabel_RkOu>服务</span></a><button aria-label="Expand sidebar category '服务'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/software><span title=软件 class=categoryLinkLabel_RkOu>软件</span></a><button aria-label="Expand sidebar category '软件'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/std><span title=标准数据 class=categoryLinkLabel_RkOu>标准数据</span></a><button aria-label="Expand sidebar category '标准数据'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/voip><span title=VoIP class=categoryLinkLabel_RkOu>VoIP</span></a><button aria-label="Expand sidebar category 'VoIP'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_irRK menu__link menu__link--sublist" href=/notes/web><span title=Web class=categoryLinkLabel_RkOu>Web</span></a><button aria-label="Expand sidebar category 'Web'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul></nav><button type=button title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_NY7h"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_c8nQ><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_GAGP><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_YQ1L"><div class=docItemContainer_Wjg4><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_tiqF" aria-label=Breadcrumbs><ul class=breadcrumbs><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_WTWT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li class=breadcrumbs__item><a class=breadcrumbs__link href=/notes/ai><span>AI</span></a><li class=breadcrumbs__item><span class=breadcrumbs__link>model</span><li class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>Models</span></ul></nav><div class="tocCollapsible_GvsH theme-doc-toc-mobile tocMobile_qJgM"><button type=button class="clean-btn tocCollapsibleButton_LnP0">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Models</h1></header>
<p><strong>Open Weights/Transformer</strong></p>





















































































































































































































































































































































































<table><thead><tr><th style=text-align:left>Date<th style=text-align:left>Model<th style=text-align:left>Size<th style=text-align:left>Context Window<th style=text-align:left>Creator<th>notes<tbody><tr><td style=text-align:left>2025-09-15<td style=text-align:left>Qwen3-Next<td style=text-align:left>80B<td style=text-align:left><td style=text-align:left><td><tr><td style=text-align:left>2025-09-01<td style=text-align:left>Hunyuan-MT-Chimera-7B<td style=text-align:left>7B<td style=text-align:left><td style=text-align:left><td><tr><td style=text-align:left>2025-08-25<td style=text-align:left>InternVL3.5<td style=text-align:left>1B - 241B - Qwen3, GPT OSS FT<td style=text-align:left><td style=text-align:left><td><tr><td style=text-align:left>2025-08-22<td style=text-align:left>Intern-S1<td style=text-align:left>Qwen3<td style=text-align:left><td style=text-align:left><td><tr><td style=text-align:left>2025-08-11<td style=text-align:left><a href=https://huggingface.co/zai-org/GLM-4.5V target=_blank rel="noopener noreferrer">GLM 4.5V</a><td style=text-align:left>based on GLM-4.5-Air-106-12A<td style=text-align:left><td style=text-align:left><td>Hybrid Reasoning<tr><td style=text-align:left>2025-08-06<td style=text-align:left>GPT OSS<td style=text-align:left><a href=https://huggingface.co/openai/gpt-oss-20b target=_blank rel="noopener noreferrer">20B</a>, <a href=https://huggingface.co/openai/gpt-oss-120b target=_blank rel="noopener noreferrer">120B</a><td style=text-align:left>128K<td style=text-align:left>OpenAI<td>Reasoning, Tools<tr><td style=text-align:left>2025-07-28<td style=text-align:left>Intern-S1<td style=text-align:left>235B<td style=text-align:left><td style=text-align:left><td>Qwen3 + 6B InternViT<tr><td style=text-align:left>2025-07-28<td style=text-align:left>GLM 4.5<td style=text-align:left>355-32A, Air 106-12A<td style=text-align:left>128K<td style=text-align:left>Zhipu<td>Reasoning, Multilingual<tr><td style=text-align:left>2025-07-23<td style=text-align:left>Qwen3 2507<td style=text-align:left>Coder 480B-A35B, Coder-Flash 30B-A3B, 235B-A22B, 30B-A3B<td style=text-align:left>256K, Yarn 1M<td style=text-align:left><td><tr><td style=text-align:left>2025-07-28<td style=text-align:left>WAN-2.2<td style=text-align:left>TI2V-5B, T2V-27B-A14B, I2V-27B-A14B<td style=text-align:left><td style=text-align:left>Alibaba<td>T2V, I2V, VACE, FLF2V, Reasoning, Multilingual<tr><td style=text-align:left>2025-07-15<td style=text-align:left>Voxtral 1.0<td style=text-align:left>Mini 3B, Small 24B<td style=text-align:left>32K<td style=text-align:left>Mistral AI<td>Audio, 30min transcription, 40 min understanding<tr><td style=text-align:left>2025-07-11<td style=text-align:left>Kimi k2<td style=text-align:left>1T-A32B<td style=text-align:left>128K<td style=text-align:left>Moonshot AI<td>MoE<tr><td style=text-align:left>2025-07-02<td style=text-align:left>GLM-4.1V<td style=text-align:left>9B<td style=text-align:left>64K<td style=text-align:left>Zhipu,THUDM<td>Vision, Reasoning<tr><td style=text-align:left>2025-06-11<td style=text-align:left>Magistral<td style=text-align:left>small 24B<td style=text-align:left>39K<td style=text-align:left>Mistral AI<td>Reasoning, Multilingual<tr><td style=text-align:left>2025-06-07<td style=text-align:left>Comma v0.1<td style=text-align:left>7B<td style=text-align:left><td style=text-align:left>EleutherAI<td>Full OSS, English<tr><td style=text-align:left>2025-06-05<td style=text-align:left>Qwen3-Embedding<td style=text-align:left>0.6b, 4b, 8b<td style=text-align:left>32K<td style=text-align:left>Alibaba<td>Embedding, Reranking, Multilingual(100+), Instruction Aware, MRL(1024, 2560, 4096)<tr><td style=text-align:left>2025-05-28<td style=text-align:left>DeepSeek R1 0528<td style=text-align:left><td style=text-align:left><td style=text-align:left>DeepSeek AI<td>Update<tr><td style=text-align:left>2025-05-26<td style=text-align:left>QwenLong-L1<td style=text-align:left>32b<td style=text-align:left>120K<td style=text-align:left>Alibaba<td>text<tr><td style=text-align:left>2025-05-20<td style=text-align:left>Gemma3n<td style=text-align:left>5b-e2b, 8b-e4b<td style=text-align:left><td style=text-align:left>Google<td>Edge, PLE<tr><td style=text-align:left>2025-04-29<td style=text-align:left>Qwen3<td style=text-align:left>0.6b, 1.7b, 4b, 8b, 14b, 30b, 32b, 235b, 30b-a3b, 235b-a22b<td style=text-align:left>40K<td style=text-align:left>Alibaba<td>MoE, Reasoning<tr><td style=text-align:left>2025-04-05<td style=text-align:left>Llama 4<td style=text-align:left>scout 109b-a17b ,marverik 400b-a17b, <em>2T</em><td style=text-align:left>1M, 10M<td style=text-align:left>Meta<td>MoE, Vision<tr><td style=text-align:left>2025-03-26<td style=text-align:left>Qwen2.5-Omni<td style=text-align:left>3B, 7B<td style=text-align:left><td style=text-align:left>Alibaba<td>text, audio, image, video, speech<tr><td style=text-align:left>2025-03-12<td style=text-align:left>Gemma3<td style=text-align:left>1b, 4b, 12b, 27b<td style=text-align:left>128K<td style=text-align:left>Google DeepMind<td>Vision<tr><td style=text-align:left>2025-02-25<td style=text-align:left>Wan 2.1<td style=text-align:left>1.3b,14b<td style=text-align:left><td style=text-align:left>Alibaba<td>t2v, 480P, 720p<tr><td style=text-align:left>2025-02-24<td style=text-align:left>smollm2<td style=text-align:left>135m, 360m, 1.7b<td style=text-align:left>8K<td style=text-align:left>HuggingFaceTB<td><tr><td style=text-align:left>2025-01-28<td style=text-align:left>Qwen2.5-VL<td style=text-align:left>3b, 7b, 32b, 72b<td style=text-align:left>125K<td style=text-align:left>Alibaba<td>Vision<tr><td style=text-align:left>2025-01-28<td style=text-align:left>Qwen2.5<td style=text-align:left>0.5b, 1.5b, 3b, 7b, 14b, 32b, 72b<td style=text-align:left>32K,1M<td style=text-align:left>Alibaba<td><tr><td style=text-align:left>2025-01-20<td style=text-align:left>DeepSeek R1<td style=text-align:left>1.5b, 7b, 8b, 14b, 32b, 70b, 671b<td style=text-align:left>128K<td style=text-align:left>DeepSeek AI<td>Reasoning<tr><td style=text-align:left>2024-12-07<td style=text-align:left>Llama 3.3<td style=text-align:left>70B<td style=text-align:left>128K<td style=text-align:left>Meta<td><tr><td style=text-align:left>2024-12<td style=text-align:left>Phi-4<td style=text-align:left>14b<td style=text-align:left>128K<td style=text-align:left>Microsoft<td>mini-reasoning,reasoning,multimodal<tr><td style=text-align:left>2024-11-21<td style=text-align:left>LTX-Video<td style=text-align:left>2b, 13b<td style=text-align:left><td style=text-align:left>Lightricks<td>T2V<tr><td style=text-align:left>2024-10-05<td style=text-align:left>LLaVA<td style=text-align:left>7b, 13b, 34b<td style=text-align:left>4K, 32K<td style=text-align:left><td>Vision<tr><td style=text-align:left>2024-09-25<td style=text-align:left>Llama 3.2<td style=text-align:left>1B, 3B, 11B, 90B<td style=text-align:left>128K<td style=text-align:left>Meta<td><tr><td style=text-align:left>2024-07-23<td style=text-align:left>Llama 3.1<td style=text-align:left>8B, 70.6B, 405B<td style=text-align:left>128K<td style=text-align:left>Meta<td><tr><td style=text-align:left>2024-06-27<td style=text-align:left>Gemma 2<td style=text-align:left>9b, 27.2b<td style=text-align:left>8K<td style=text-align:left>Google DeepMind<td><tr><td style=text-align:left>2024-06-07<td style=text-align:left>Qwen2<td style=text-align:left>0.5b, 1.5b, 7b, 57b (A14b), 72b<td style=text-align:left>32K, 64K, 128K<td style=text-align:left>Alibaba<td><tr><td style=text-align:left>2024-04-23<td style=text-align:left>Phi-3<td style=text-align:left>3.8b , 7b , 14b<td style=text-align:left>4K, 128K<td style=text-align:left>Microsoft<td><tr><td style=text-align:left>2024-04-18<td style=text-align:left>Llama 3<td style=text-align:left>8b, 70.6b<td style=text-align:left>8K, 128K<td style=text-align:left>Meta<td><tr><td style=text-align:left>2024-02-21<td style=text-align:left>Gemma<td style=text-align:left>2b, 7b<td style=text-align:left>8K<td style=text-align:left>Google DeepMind<td><tr><td style=text-align:left>2023-12-11<td style=text-align:left>Mistral<td style=text-align:left>7b, 46.7b (8x7B MoE)<td style=text-align:left>33K<td style=text-align:left>Mistral AI<td><tr><td style=text-align:left>2023-07-18<td style=text-align:left>Llama 2<td style=text-align:left>6.7b, 13b, 69b<td style=text-align:left>4K<td style=text-align:left>Meta<td><tr><td style=text-align:left>2023-02-24<td style=text-align:left>LLaMA<td style=text-align:left>6.7B, 13B, 32.5B, 65.2B<td style=text-align:left>2K<td style=text-align:left>Meta<td><tr><td style=text-align:left>2020-06-11<td style=text-align:left>GPT-3<td style=text-align:left>175b<td style=text-align:left>2K<td style=text-align:left>OpenAI<td><tr><td style=text-align:left>2019-02-14<td style=text-align:left>GPT-2<td style=text-align:left>1.5b<td style=text-align:left>1K<td style=text-align:left>OpenAI<td><tr><td style=text-align:left>2018-06-11<td style=text-align:left>GPT-1<td style=text-align:left>117m<td style=text-align:left>512<td style=text-align:left>OpenAI<td></table>





































































































































































<table><thead><tr><th>date<th>model<th>parameters<th>context length<th>hidden size<th>attention<th>heads (Q/KV/Group)<th>act func<th>head size<th>layers<th>experts (total/active)<th>vocab size<th>data type<th>tokenizer<tbody><tr><td>2025-08-05<td>gpt-oss-120b<td>117B (5.1B active)<td>128K<td>2880<td>GQA + Sparse<td>64 / - / 8<td>SwiGLU<td>64<td>36<td>128 / 4<td>201,088<td>MXFP4 / bf16<td>o200k_harmony (BPE)<tr><td>2025-08-05<td>gpt-oss-20b<td>21B (3.6B active)<td>128K<td>2880<td>GQA + Sparse<td>64 / - / 8<td>SwiGLU<td>64<td>24<td>32 / 4<td>201,088<td>MXFP4 / bf16<td>o200k_harmony (BPE)<tr><td>2025-08-23<td>Seed-OSS-36B<td>36B<td>512K<td>5120<td>GQA<td>80 / 8 / -<td>SwiGLU<td>128<td>64<td>N/A (Dense)<td>155K<td>bf16<td>BPE<tr><td>2025-03-12<td>Gemma3-27B<td>27B<td>128K<td>-<td>Interleaved Local/Global<td>-<td>-<td>-<td>-<td>N/A (Dense)<td>262K<td>bf16<td>SentencePiece<tr><td>2025-01-22<td>Deepseek R1<td>671B (37B active)<td>128K<td>-<td>MLA<td>-<td>SwiGLU<td>-<td>61<td><td><td>fp8 / bf16<td><tr><td>2025-05<td>Qwen3-30B-A3B<td>30.5B (3.3B active)<td>256K<td>4096<td>GQA<td>32 / 4 / -<td>SwiGLU<td>128<td>48<td>128 / 8<td>151,669<td>bf16<td>BPE (Byte-level)<tr><td>2025-05<td>Qwen3-32B<td>32.8B<td>128K<td>-<td>GQA<td>64 / 8 / -<td>SwiGLU<td>-<td>64<td>N/A (Dense)<td>151,936<td>bf16<td>BPE (Byte-level)<tr><td>2024-12<td>Deepseek V3<td>671B (37B active)<td>128K<td>-<td>MLA<td>-<td>SwiGLU<td>-<td>61<td>256 routed, 1 shared<td><td>fp8 / bf16<td><tr><td>2019-02-14<td>GPT-2 1.5B<td>1.542B<td>1024<td>1600<td>Multi-Head<td>25 / 25 / -<td>GELU<td>64<td>48<td>N/A (Dense)<td>50,257<td>fp16<td>BPE (Byte-level)</table>
<ul>
<li>Qwen3 tokenizer
<ul>
<li><a href=https://huggingface.co/Qwen/Qwen3-235B-A22B/blob/main/tokenizer.json target=_blank rel="noopener noreferrer">https://huggingface.co/Qwen/Qwen3-235B-A22B/blob/main/tokenizer.json</a></li>
<li><a href=https://github.com/dqbd/tiktokenizer/issues/39 target=_blank rel="noopener noreferrer">https://github.com/dqbd/tiktokenizer/issues/39</a></li>
</ul>
</li>
</ul>



























































<table><thead><tr><th>date<th>model<th>author<th>notes<tbody><tr><td>2025-06<td>MobileNet V5<td>Google<td>256x256, 512x512, 768x768, CNN,Gemma 3n<tr><td>2025-02-19<td><a href=https://github.com/sunsmarterjie/yolov12 target=_blank rel="noopener noreferrer">YOLOv12</a><td><td><tr><td>2024-08<td><a href=https://github.com/facebookresearch/segment-anything target=_blank rel="noopener noreferrer">SAM</a> v2<td>Meta<td><tr><td>2024-04<td>MobileNet V4<td>Google<td><tr><td>2023-04<td><a href=https://github.com/facebookresearch/segment-anything target=_blank rel="noopener noreferrer">SAM</a><td>Meta<td><tr><td>2019-05<td>MobileNet V3<td>Google<td><tr><td>2019-03<td>MobileNet V2<td>Google<td><tr><td>2017-04<td><a href=https://arxiv.org/abs/1704.04861 target=_blank rel="noopener noreferrer">MobileNet</a><td>Google<td></table>
<ul>
<li>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications
<ul>
<li><a href=https://arxiv.org/abs/1704.04861 target=_blank rel="noopener noreferrer">https://arxiv.org/abs/1704.04861</a></li>
<li><a href=https://en.wikipedia.org/wiki/MobileNet target=_blank rel="noopener noreferrer">https://en.wikipedia.org/wiki/MobileNet</a></li>
<li>MobileNetV3 <a href=https://arxiv.org/abs/1905.02244 target=_blank rel="noopener noreferrer">https://arxiv.org/abs/1905.02244</a></li>
<li>MobileNetV4 <a href=https://arxiv.org/abs/2404.10518 target=_blank rel="noopener noreferrer">https://arxiv.org/abs/2404.10518</a></li>
</ul>
</li>
<li>YOLO
<ul>
<li>YOLO12 Attention-Centric Object Detection
<ul>
<li><a href=https://github.com/sunsmarterjie/yolov12 target=_blank rel="noopener noreferrer">sunsmarterjie/yolov12</a></li>
<li><a href=https://arxiv.org/abs/2502.12524 target=_blank rel="noopener noreferrer">https://arxiv.org/abs/2502.12524</a></li>
<li><a href=https://github.com/sunsmarterjie/yolov12/issues/74 target=_blank rel="noopener noreferrer">https://github.com/sunsmarterjie/yolov12/issues/74</a></li>
</ul>
</li>
<li><a href=https://github.com/ultralytics/ultralytics target=_blank rel="noopener noreferrer">https://github.com/ultralytics/ultralytics</a></li>
</ul>
</li>
<li>SAM - Segment Anything Model
<ul>
<li><a href=https://github.com/facebookresearch/segment-anything target=_blank rel="noopener noreferrer">https://github.com/facebookresearch/segment-anything</a></li>
</ul>
</li>
<li>SAM v2
<ul>
<li><a href=https://arxiv.org/abs/2408.00714 target=_blank rel="noopener noreferrer">https://arxiv.org/abs/2408.00714</a></li>
</ul>
</li>
</ul>
<p><strong>Diffusion/Image Models</strong></p>





















































































































<table><thead><tr><th>date<th>model<th>size<th>author<th>notes<tbody><tr><td>2025-08-04<td><a href=https://huggingface.co/Qwen/Qwen-Image target=_blank rel="noopener noreferrer">Qwen-Image</a><td>20B<td>Alibaba<td>Apache-2.0,MMDiT , T2I,Editing, Text<tr><td>2025-07-16<td>HiDream-E1-1<td><td><td>Editing<tr><td>2025-05-29<td>FLUX.1 Kontext<td>dev 12B,<del>max</del>,<del>pro</del><td>Black Forest Labs<td><tr><td>2025-04-07<td>HiDream-I1<td>17B, Fast 16step, Dev 28step, Full 50step<td><td><tr><td>2025-01-25<td>Lumina-Image 2.0<td>2B<td>OpenGVLab<td>Apache-2.0<tr><td>2024-10-22<td>SD 3.5<td>turbo, large, medium ,2.5B, 8B<td>Stability AI<td><tr><td>2024-08-01<td>FLUX.1<td>dev, schnell, 12B, <del>pro</del><td>Black Forest Labs<td><tr><td>2024-02<td>SD 3.0<td>800M, 8B<td>Stability AI<td><tr><td>2023-11<td>SDXL Turbo<td><td>Stability AI<td><tr><td>2023-07<td>SDXL 1.0<td>3.5B<td><td><tr><td>2022-12<td>SD v2.1<td><td><td><tr><td>2022-11<td>SD v2.0<td><td><td><tr><td>2022-10<td>SD 1.5<td>983M<td>RunwayML<td><tr><td>2022-08<td>SD 1.1 1.2 1.3 1.4<td><td>CompVis<td><tr><td>2025-06-16<td>OmniGen2<td>7B<td>VectorSpaceLab<td>T2I, Editing, Composing</table>
<p><strong>Proprietary Models</strong></p>





























































































































































































































































































































<table><thead><tr><th style=text-align:left>release<th style=text-align:left>model<th style=text-align:right>output<th style=text-align:right>input price<th style=text-align:left>author<th style=text-align:left>notes<tbody><tr><td style=text-align:left>2025-07-31<td style=text-align:left>Horizon Alpha<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left>256K<tr><td style=text-align:left>2025-06<td style=text-align:left>Kling 2.1<td style=text-align:right>$0.28/s<td style=text-align:right><td style=text-align:left><td style=text-align:left><tr><td style=text-align:left>2025-06-17<td style=text-align:left>Gemini 2.5 Pro<td style=text-align:right>$10.00/1M<td style=text-align:right>$1.25/1M<td style=text-align:left>Google<td style=text-align:left>1M<tr><td style=text-align:left>2025-06<td style=text-align:left>Gemini 2.5 Flash-Lite<td style=text-align:right>$0.40/1M<td style=text-align:right><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>0.10</mn><mi mathvariant=normal>/</mi><mn>1</mn><mi>M</mi><mo separator=true>,</mo><mi>a</mi><mi>u</mi><mi>d</mi><mi>i</mi><mi>o</mi></mrow><annotation encoding=application/x-tex>0.10/1M, audio </annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>0.10/1</span><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">a</span><span class="mord mathnormal">u</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span></span></span></span>0.50/1M<td style=text-align:left>Google<td style=text-align:left><tr><td style=text-align:left>2025-06<td style=text-align:left>Gemini 2.5 Flash<td style=text-align:right>$2.50/1M<td style=text-align:right><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>0.30</mn><mi mathvariant=normal>/</mi><mn>1</mn><mi>M</mi><mo separator=true>,</mo><mi>a</mi><mi>u</mi><mi>d</mi><mi>i</mi><mi>o</mi></mrow><annotation encoding=application/x-tex>0.30/1M, audio </annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>0.30/1</span><span class="mord mathnormal" style=margin-right:0.10903em>M</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">a</span><span class="mord mathnormal">u</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span></span></span></span>1.00/1M<td style=text-align:left>Google<td style=text-align:left><tr><td style=text-align:left>2025-05-22<td style=text-align:left>Claude 4 Opus<td style=text-align:right>$15/1M<td style=text-align:right>$3/1M<td style=text-align:left>Anthropic<td style=text-align:left>200K<tr><td style=text-align:left>2025-05-22<td style=text-align:left>Claude 4 Sonnet<td style=text-align:right>$75/1M<td style=text-align:right>$15/1M<td style=text-align:left>Anthropic<td style=text-align:left>200K<tr><td style=text-align:left>2025-05-20<td style=text-align:left>Imagen 4<td style=text-align:right><td style=text-align:right><td style=text-align:left>Google<td style=text-align:left>t2i<tr><td style=text-align:left>2025-05<td style=text-align:left>Veo 3<td style=text-align:right><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>0.50</mn><mi mathvariant=normal>/</mi><mi>s</mi><mo separator=true>,</mo><mi>a</mi><mi>u</mi><mi>d</mi><mi>i</mi><mi>o</mi></mrow><annotation encoding=application/x-tex>0.50/s, audio </annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>0.50/</span><span class="mord mathnormal">s</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em></span><span class="mord mathnormal">a</span><span class="mord mathnormal">u</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span></span></span></span>0.75/s<td style=text-align:right><td style=text-align:left>Google<td style=text-align:left>t2v<tr><td style=text-align:left>2025-05<td style=text-align:left>FLUX.1 Kontext max/pro<td style=text-align:right><td style=text-align:right><td style=text-align:left>Black Forest Labs<td style=text-align:left>t2i<tr><td style=text-align:left>2025-04-17<td style=text-align:left>Gemini 2.0 Flash<td style=text-align:right><td style=text-align:right><td style=text-align:left>Google<td style=text-align:left><tr><td style=text-align:left>2025-04-16<td style=text-align:left>Seedream 3.0<td style=text-align:right><td style=text-align:right><td style=text-align:left>Bytedance<td style=text-align:left>t2i<tr><td style=text-align:left>2025-04-14<td style=text-align:left>GPT-4.1, mini, nano<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left><tr><td style=text-align:left>2025-03-25<td style=text-align:left>Gemini 2.0 Pro<td style=text-align:right><td style=text-align:right><td style=text-align:left>Google<td style=text-align:left>2M<tr><td style=text-align:left>2025-02-27<td style=text-align:left>ChatGPT 4.5<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left>128K<tr><td style=text-align:left>2025-02-24<td style=text-align:left>Claude 3.7<td style=text-align:right><td style=text-align:right><td style=text-align:left><td style=text-align:left><tr><td style=text-align:left>2025-02-05<td style=text-align:left>Gemini 2.0 Flash<td style=text-align:right><td style=text-align:right><td style=text-align:left>Google<td style=text-align:left>audio, video<tr><td style=text-align:left>2025-02-01<td style=text-align:left>Gemini 2.0 Flash-Lite<td style=text-align:right><td style=text-align:right><td style=text-align:left>Google<td style=text-align:left><tr><td style=text-align:left>2025-01-10<td style=text-align:left>o3, o3-mini<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left>Reasoning<tr><td style=text-align:left>2024-12-17<td style=text-align:left>o1<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left><tr><td style=text-align:left>2024-12<td style=text-align:left>Veo 2<td style=text-align:right>$0.35/s<td style=text-align:right><td style=text-align:left>Google<td style=text-align:left>t2v<tr><td style=text-align:left>2024-10<td style=text-align:left>Recraft V3<td style=text-align:right><td style=text-align:right><td style=text-align:left>Recraft<td style=text-align:left><tr><td style=text-align:left>2024-09-12<td style=text-align:left>o1-preview<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left>Reasoning<tr><td style=text-align:left>2024-08<td style=text-align:left>Imagen 3<td style=text-align:right><td style=text-align:right><td style=text-align:left>Google<td style=text-align:left>t2i<tr><td style=text-align:left>2024-07-18<td style=text-align:left>GPT-4o mini<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left><tr><td style=text-align:left>2024-06-20<td style=text-align:left>Claude 3.5 Haiku<td style=text-align:right><td style=text-align:right><td style=text-align:left><td style=text-align:left><tr><td style=text-align:left>2024-05-13<td style=text-align:left>GPT-4o<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left>text, audio, image<tr><td style=text-align:left>2024-03-04<td style=text-align:left>Claude 3 Haiku, Sonnet, Opus<td style=text-align:right><td style=text-align:right><td style=text-align:left>Anthropic<td style=text-align:left>200K<tr><td style=text-align:left>2024-02-15<td style=text-align:left>Gemini 1.5 Pro<td style=text-align:right><td style=text-align:right><td style=text-align:left>Google<td style=text-align:left>突破性的100万token超长上下文窗口<tr><td style=text-align:left>2023-12-06<td style=text-align:left>Gemini 1.0 Pro<td style=text-align:right><td style=text-align:right><td style=text-align:left>Google<td style=text-align:left>原生多模态模型家族<tr><td style=text-align:left>2023-11-21<td style=text-align:left>Claude 2.1<td style=text-align:right><td style=text-align:right><td style=text-align:left>Anthropic<td style=text-align:left>200K<tr><td style=text-align:left>2023-11-06<td style=text-align:left>GPT-4V<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left>128K, Vision<tr><td style=text-align:left>2023-11-06<td style=text-align:left>GPT-4 Turbo<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left>128K<tr><td style=text-align:left>2023-07-11<td style=text-align:left>Claude 2<td style=text-align:right><td style=text-align:right><td style=text-align:left>Anthropic<td style=text-align:left>100K<tr><td style=text-align:left>2023-06-27<td style=text-align:left>GPT-3.5-16k<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left>16K<tr><td style=text-align:left>2023-03-14<td style=text-align:left>GPT-4<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left>8K, 32K , image<tr><td style=text-align:left>2023-03-01<td style=text-align:left>GPT-3.5-turbo<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left>4K<tr><td style=text-align:left>2022-11-30<td style=text-align:left>GPT-3.5<td style=text-align:right><td style=text-align:right><td style=text-align:left>OpenAI<td style=text-align:left>4K</table>








































<table><thead><tr><th>abbr.<th>stand for<th>meaning<tbody><tr><td>MRL<td>Matryoshka Representation Learning<td><tr><td>R2V<td>reference-to-video<td><tr><td>MV2V<td>masked video-to-video<td><tr><td>V2V<td>video-to-video<td><tr><td>MoE<td>Mixture of Experts<td>混合专家模型<tr><td>VACE<td>Video Animation, Composition, and Editing<td></table>
<ul>
<li>MRL - Matryoshka Representation Learning
<ul>
<li>Embedding 模型支持 支持自定义最终嵌入的维度</li>
<li><a href=https://huggingface.co/blog/matryoshka target=_blank rel="noopener noreferrer">https://huggingface.co/blog/matryoshka</a></li>
</ul>
</li>
<li>VACE: All-in-One Video Creation and Editing
<ul>
<li>2025-03-11</li>
<li>VACE - Video Animation, Composition, and Editing</li>
<li>一体化的视频处理框架</li>
<li>r2v, mv2v, v2v</li>
<li><a href=https://arxiv.org/abs/2503.07598 target=_blank rel="noopener noreferrer">https://arxiv.org/abs/2503.07598</a></li>
</ul>
</li>
<li>R2V - reference-to-video</li>
<li>MV2V - masked video-to-video</li>
<li><code>*-pt</code> - Pre-Training - 预训练模型
<ul>
<li>在大规模数据集上进行初始训练，学习语言模式和结构。</li>
<li>该模型适合作为基础模型，供开发者在特定任务上进行进一步的微调。</li>
</ul>
</li>
<li><code>*-ft</code>
<ul>
<li>Fine-tuned</li>
</ul>
</li>
<li><code>*-it</code> - Instruction Tuning - 经过指令微调的模型
<ul>
<li>在预训练模型的基础上，进一步针对特定任务或指令进行了微调。</li>
<li>此版本更适合直接应用于实际任务，因为它已经针对特定用途进行了优化。</li>
</ul>
</li>
</ul>
<hr/>
<ul>
<li>内存占用计算方式
<ul>
<li>参数x精度</li>
<li>目前理想精度是 float16, bfloat16 - 1 个参数占用 16bit
<ul>
<li>1B -> 2GB</li>
</ul>
</li>
<li>量化参数 - 常见量化 int4
<ul>
<li>1B -> 0.5GB</li>
<li><a href=https://huggingface.co/datasets/christopherthompson81/quant_exploration target=_blank rel="noopener noreferrer">https://huggingface.co/datasets/christopherthompson81/quant_exploration</a></li>
<li>Q4_0 - worse accuracy but higher speed</li>
<li>Q4_1 - more accurate but slower</li>
<li>q4_2, q4_3 - new generations of q4_0 and q4_1, more accurate</li>
<li><a href=https://github.com/ggerganov/llama.cpp/discussions/406 target=_blank rel="noopener noreferrer">https://github.com/ggerganov/llama.cpp/discussions/406</a></li>
</ul>
</li>
</ul>
</li>
<li>7B - 8GB 内存</li>
<li>13B - 16GB 内存</li>
<li>70B - 32GB/48G 内存</li>
<li>小 context window 适用于 RAG</li>
<li>Context Window
<ul>
<li>LLama-3 8B 8K-1M <a href=https://ollama.com/library/llama3-gradient target=_blank rel="noopener noreferrer">https://ollama.com/library/llama3-gradient</a>
<ul>
<li>256k context window requires at least 64GB of memory</li>
<li>1M+ context window requires significantly more (100GB+)</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr/>
<blockquote>
<p>按照 商业公司分类 模型之间关联性高，模型有连续性。虽然会扩展调整各种能力，但是 Base 模型的发展和用到的技术会相对连续。</p>
</blockquote>
<ul>
<li>Leader board/Index/排行/Ranking
<ul>
<li>LLM
<ul>
<li><a href=https://huggingface.co/open-llm-leaderboard target=_blank rel="noopener noreferrer">https://huggingface.co/open-llm-leaderboard</a></li>
<li><a href=https://lmarena.ai/ target=_blank rel="noopener noreferrer">https://lmarena.ai/</a></li>
<li><a href=https://www.vellum.ai/llm-leaderboard target=_blank rel="noopener noreferrer">https://www.vellum.ai/llm-leaderboard</a></li>
<li><a href=https://pricepertoken.com/ target=_blank rel="noopener noreferrer">https://pricepertoken.com/</a></li>
</ul>
</li>
<li>Text-to-Image
<ul>
<li><a href=https://huggingface.co/spaces/ArtificialAnalysis/Text-to-Image-Leaderboard target=_blank rel="noopener noreferrer">ArtificialAnalysis/Text-to-Image-Leaderboard</a></li>
</ul>
</li>
<li>Usage/Adoption/Coding
<ul>
<li><a href=https://openrouter.ai/rankings target=_blank rel="noopener noreferrer">https://openrouter.ai/rankings</a></li>
<li><a href=https://aider.chat/docs/leaderboards/ target=_blank rel="noopener noreferrer">https://aider.chat/docs/leaderboards/</a></li>
</ul>
</li>
<li>Indexing
<ul>
<li><a href=https://ollama.com/library target=_blank rel="noopener noreferrer">https://ollama.com/library</a></li>
<li><a href=https://livebench.ai/ target=_blank rel="noopener noreferrer">https://livebench.ai/</a></li>
<li><a href=https://huggingface.co/models target=_blank rel="noopener noreferrer">https://huggingface.co/models</a></li>
</ul>
</li>
<li>BFCL Leaderboard <a href=https://gorilla.cs.berkeley.edu/leaderboard.html target=_blank rel="noopener noreferrer">https://gorilla.cs.berkeley.edu/leaderboard.html</a>
<ul>
<li>Berkeley Function-Calling Leaderboard</li>
</ul>
</li>
<li><a href=https://models.litellm.ai/ target=_blank rel="noopener noreferrer">https://models.litellm.ai/</a></li>
<li><a href=https://arena.xlang.ai/leaderboard target=_blank rel="noopener noreferrer">https://arena.xlang.ai/leaderboard</a></li>
</ul>
</li>
<li>Benchmark/Eval
<ul>
<li><a href=https://huggingface.co/spaces/Jellyfish042/UncheatableEval target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/Jellyfish042/UncheatableEval</a></li>
<li><a href=https://github.com/open-compass/VLMEvalKit target=_blank rel="noopener noreferrer">https://github.com/open-compass/VLMEvalKit</a></li>
</ul>
</li>
<li>价格/Pricing/成本/Cost
<ul>
<li><a href=https://www.llm-prices.com/ target=_blank rel="noopener noreferrer">https://www.llm-prices.com/</a></li>
<li><a href=https://openrouter.ai/models target=_blank rel="noopener noreferrer">https://openrouter.ai/models</a></li>
<li><a href=https://ai.google.dev/gemini-api/docs/pricing target=_blank rel="noopener noreferrer">https://ai.google.dev/gemini-api/docs/pricing</a></li>
<li><a href=https://idp-leaderboard.org/ target=_blank rel="noopener noreferrer">https://idp-leaderboard.org/</a></li>
</ul>
</li>
<li>Visual
<ul>
<li><a href=https://huggingface.co/microsoft/Florence-2-large target=_blank rel="noopener noreferrer">microsoft/Florence-2-large</a>
<ul>
<li>MIT</li>
<li>base 0.23B, large 0.77B</li>
<li>Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks</li>
</ul>
</li>
</ul>
</li>
<li>阿里云/Alibaba
<ul>
<li><a href=https://github.com/QwenLM target=_blank rel="noopener noreferrer">QwenLM</a>
<ul>
<li><a href=https://huggingface.co/Qwen target=_blank rel="noopener noreferrer">Qwen</a></li>
<li><a href=https://huggingface.co/Qwen/QwQ-32B target=_blank rel="noopener noreferrer">QwQ 32B</a></li>
<li>Qwen2 VL
<ul>
<li><a href=https://huggingface.co/Qwen/QVQ-72B-Preview target=_blank rel="noopener noreferrer">Qwen/QVQ-72B-Preview</a></li>
</ul>
</li>
<li><a href=https://github.com/QwenLM/Qwen2.5 target=_blank rel="noopener noreferrer">QwenLM/Qwen2.5</a>
<ul>
<li>Qwen2.5 Coder</li>
<li>Qwen2.5 VL</li>
<li>Qwen2.5 Math</li>
<li>Collection <a href=https://huggingface.co/collections/Qwen/qwen25-vl-6795ffac22b334a837c0f9a5 target=_blank rel="noopener noreferrer">Qwen/Qwen2.5-VL</a></li>
</ul>
</li>
<li><a href=https://github.com/QwenLM/Qwen target=_blank rel="noopener noreferrer">QwenLM/Qwen</a></li>
<li>Qwen3
<ul>
<li>推荐参数
<ul>
<li>Thinking - temperature=0.6, top_p=0.95, top_k=20</li>
<li>temperature=0.7, top_p=0.8, top_k=20</li>
<li>min_p=0.0</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href=https://github.com/Wan-Video target=_blank rel="noopener noreferrer">Wan-Video</a>
<ul>
<li><a href=https://github.com/Wan-Video/Wan2.1 target=_blank rel="noopener noreferrer">Wan-Video/Wan2.1</a>
<ul>
<li>1.3B, 14B</li>
<li>T2V-1.3B, VACE-1.3B</li>
<li>T2V-14B, I2V-14B-720P, I2V-14B-480P, FLF2V-14B, VACE-14B</li>
<li>VACE
<ul>
<li>视频编辑</li>
</ul>
</li>
<li>FLF2V - First-Last-Frame-to-Video - 首末帧到视频
<ul>
<li>生成中间的过渡动画</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href=https://github.com/ali-vilab/VACE target=_blank rel="noopener noreferrer">ali-vilab/VACE</a>
<ul>
<li>all-in-one Video Creation and Editing</li>
<li>VACE-Wan2.1-1.3B-Preview</li>
<li>VACE-LTX-Video-0.9</li>
<li>Wan2.1-VACE-1.3B,14B</li>
</ul>
</li>
<li><a href=https://github.com/HumanMLLM/R1-Omni target=_blank rel="noopener noreferrer">HumanMLLM/R1-Omni</a>
<ul>
<li>阿里通义实验室</li>
<li>Explainable Omni-Multimodal Emotion Recognition with Reinforcement Learning</li>
</ul>
</li>
</ul>
</li>
<li>deepseek
<ul>
<li><a href=https://github.com/deepseek-ai/Janus target=_blank rel="noopener noreferrer">deepseek-ai/Janus</a>
<ul>
<li>Janus-Series: Unified Multimodal Understanding and Generation Models</li>
<li>理解图像，生成图像</li>
<li>基于 DeepSeek-LLM-1.5b-base/DeepSeek-LLM-7b-base</li>
<li>hf <a href=https://huggingface.co/deepseek-ai/Janus-Pro-7B target=_blank rel="noopener noreferrer">deepseek-ai/Janus-Pro-7B</a></li>
</ul>
</li>
<li><a href=https://github.com/deepseek-ai/DeepSeek-R1 target=_blank rel="noopener noreferrer">deepseek-ai/DeepSeek-R1</a>
<ul>
<li>MoE, GRPO, MLA, RL, MTP, FP8</li>
</ul>
</li>
<li><a href=https://github.com/deepseek-ai/DeepSeek-V3 target=_blank rel="noopener noreferrer">deepseek-ai/DeepSeek-V3</a></li>
<li><a href=https://github.com/deepseek-ai/DeepSeek-VL2 target=_blank rel="noopener noreferrer">deepseek-ai/DeepSeek-VL2</a>
<ul>
<li>DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding</li>
</ul>
</li>
<li>DeepSeek-V2
<ul>
<li>MLA</li>
</ul>
</li>
</ul>
</li>
<li>Google
<ul>
<li>SigLIP2</li>
<li>SigLIP1</li>
<li><a href=https://github.com/google-deepmind/gemma target=_blank rel="noopener noreferrer">google-deepmind/gemma</a>
<ul>
<li>Apache-2.0, Flax, JAX</li>
<li>by Google DeepMind</li>
<li>Ultra, Pro, Flash, Nano</li>
<li><a href=https://ai.google.dev/gemma/docs/core target=_blank rel="noopener noreferrer">https://ai.google.dev/gemma/docs/core</a></li>
<li>gemma 3
<ul>
<li>1B text only, 4, 12, 27B Vision + text. 14T tokens</li>
<li>128K context length further trained from 32K. 1B is 32K.</li>
<li>Removed attn softcapping. Replaced with QK norm</li>
<li>5 sliding + 1 global attn</li>
<li>1024 sliding window attention</li>
<li>RL - BOND, WARM, WARP</li>
<li>推荐参数: temperature=1.0, top_k=64, top_p=0.95, min_p=0.0</li>
<li>⚠️注意 不支持获取对象检测的坐标</li>
<li><a href=https://huggingface.co/collections/google/gemma-3-release-67c6c6f89c4f76621268bb6d target=_blank rel="noopener noreferrer">https://huggingface.co/collections/google/gemma-3-release-67c6c6f89c4f76621268bb6d</a></li>
<li><a href=https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf target=_blank rel="noopener noreferrer">https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf</a></li>
<li><a href=https://blog.google/technology/developers/gemma-3/ target=_blank rel="noopener noreferrer">https://blog.google/technology/developers/gemma-3/</a></li>
<li><a href=https://huggingface.co/blog/gemma3 target=_blank rel="noopener noreferrer">https://huggingface.co/blog/gemma3</a></li>
<li><a href=https://blog.roboflow.com/gemma-3/ target=_blank rel="noopener noreferrer">https://blog.roboflow.com/gemma-3/</a></li>
<li><a href=https://docs.unsloth.ai/basics/gemma-3-how-to-run-and-fine-tune target=_blank rel="noopener noreferrer">https://docs.unsloth.ai/basics/gemma-3-how-to-run-and-fine-tune</a></li>
<li>Ollama 3 Tools support <a href=https://github.com/ollama/ollama/issues/9680 target=_blank rel="noopener noreferrer">https://github.com/ollama/ollama/issues/9680</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>bytedance/字节跳动
<ul>
<li><del><a href=https://github.com/ByteDance-Seed/Seed1.5-VL target=_blank rel="noopener noreferrer">ByteDance-Seed/Seed1.5-VL</a></del>
<ul>
<li><a href=https://huggingface.co/spaces/ByteDance-Seed/Seed1.5-VL target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/ByteDance-Seed/Seed1.5-VL</a></li>
</ul>
</li>
<li><a href=https://github.com/bytedance-seed/BAGEL target=_blank rel="noopener noreferrer">bytedance-seed/BAGEL</a>
<ul>
<li><a href=https://huggingface.co/ByteDance-Seed/BAGEL-7B-MoT target=_blank rel="noopener noreferrer">ByteDance-Seed/BAGEL-7B-MoT</a>
<ul>
<li>图片理解、生成、编辑</li>
<li><a href=https://huggingface.co/spaces/ByteDance-Seed/BAGEL target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/ByteDance-Seed/BAGEL</a></li>
<li>要求
<ul>
<li>1024 × 1024 Image Gen 80GB vRAM</li>
<li>4×16G GPU 能运行</li>
<li>e.g. 1 minute on 3xRTX3090, 8 minutes on A100</li>
<li><a href=https://github.com/ByteDance-Seed/Bagel/issues/4 target=_blank rel="noopener noreferrer">https://github.com/ByteDance-Seed/Bagel/issues/4</a></li>
</ul>
</li>
<li><a href=https://github.com/neverbiasu/ComfyUI-BAGEL target=_blank rel="noopener noreferrer">https://github.com/neverbiasu/ComfyUI-BAGEL</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=https://github.com/bytedance/UI-TARS target=_blank rel="noopener noreferrer">UI-TARS</a>
<ul>
<li><a href=https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B target=_blank rel="noopener noreferrer">https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B</a></li>
</ul>
</li>
<li><a href=https://github.com/bytedance/MegaTTS3 target=_blank rel="noopener noreferrer">bytedance/MegaTTS3</a>
<ul>
<li>TTS Diffusion Transformer</li>
<li>0.45B</li>
<li>中文、英文</li>
</ul>
</li>
<li>SeedVR - 3B, 7B
<ul>
<li>视频修复（Video Restoration, VR） - 视频画质增强</li>
<li>hf collection <a href=https://huggingface.co/collections/ByteDance-Seed/seedvr-6849deeb461c4e425f3e6f9e target=_blank rel="noopener noreferrer">SeedVR</a></li>
</ul>
</li>
<li><a href=https://huggingface.co/ByteDance-Seed/SeedVR2-3B target=_blank rel="noopener noreferrer">ByteDance-Seed/SeedVR2-3B</a></li>
</ul>
</li>
<li>Tencent/腾讯
<ul>
<li><a href=https://huggingface.co/tencent target=_blank rel="noopener noreferrer">https://huggingface.co/tencent</a></li>
<li>混元</li>
<li><a href=https://github.com/Tencent-Hunyuan/HunyuanVideo-Avatar target=_blank rel="noopener noreferrer">Tencent-Hunyuan/HunyuanVideo-Avatar</a>
<ul>
<li>Image-to-Video</li>
<li><a href=https://arxiv.org/html/2505.20156v1 target=_blank rel="noopener noreferrer">https://arxiv.org/html/2505.20156v1</a></li>
<li><a href=https://aivideo.hunyuan.tencent.com/ target=_blank rel="noopener noreferrer">https://aivideo.hunyuan.tencent.com/</a></li>
<li>hf <a href=https://huggingface.co/tencent/HunyuanVideo-Avatar target=_blank rel="noopener noreferrer">tencent/HunyuanVideo-Avatar</a></li>
</ul>
</li>
<li>hf <a href=https://huggingface.co/tencent/Hunyuan3D-2 target=_blank rel="noopener noreferrer">tencent/Hunyuan3D-2</a>
<ul>
<li>2025-01-21</li>
</ul>
</li>
<li>hf <a href=https://huggingface.co/tencent/HunyuanVideo target=_blank rel="noopener noreferrer">tencent/HunyuanVideo</a>
<ul>
<li>Text-to-Video</li>
<li>2024-10-03</li>
</ul>
</li>
<li><a href=https://github.com/Tencent/HunyuanVideo-I2V target=_blank rel="noopener noreferrer">Tencent/HunyuanVideo-I2V</a>
<ul>
<li>Image-to-Video</li>
<li>720P, vRAM 60GB - 推荐 vRAM 80GB</li>
<li>2025-03-06</li>
<li>hf <a href=https://huggingface.co/tencent/HunyuanVideo-I2V target=_blank rel="noopener noreferrer">tencent/HunyuanVideo-I2V</a>
<ul>
<li>for diffusers <a href=https://huggingface.co/hunyuanvideo-community/HunyuanVideo-I2V target=_blank rel="noopener noreferrer">hunyuanvideo-community/HunyuanVideo-I2V</a></li>
</ul>
</li>
</ul>
</li>
<li>hf <a href=https://huggingface.co/tencent/SongGeneration target=_blank rel="noopener noreferrer">tencent/SongGeneration</a></li>
</ul>
</li>
<li>Microsoft
<ul>
<li>phi
<ul>
<li><a href=https://huggingface.co/microsoft/phi-4 target=_blank rel="noopener noreferrer">phi4</a>
<ul>
<li>Text: Arabic, Chinese, Czech, Danish, Dutch, English, Finnish, French, German, Hebrew, Hungarian, Italian, Japanese, Korean, Norwegian, Polish, Portuguese, Russian, Spanish, Swedish, Thai, Turkish, Ukrainian</li>
<li>Vision: 英语</li>
<li>Audio: English, Chinese, German, French, Italian, Japanese, Spanish, Portuguese</li>
<li><a href=https://huggingface.co/microsoft/Phi-4-multimodal-instruct target=_blank rel="noopener noreferrer">https://huggingface.co/microsoft/Phi-4-multimodal-instruct</a></li>
</ul>
</li>
<li>phi3</li>
</ul>
</li>
<li><a href=https://github.com/microsoft/OmniParser target=_blank rel="noopener noreferrer">microsoft/OmniParser</a>
<ul>
<li>识别 UI 交互元素, 屏幕分析</li>
<li>Pure Vision Based GUI Agent</li>
<li>hf <a href=https://huggingface.co/microsoft/OmniParser-v2.0 target=_blank rel="noopener noreferrer">microsoft/OmniParser-v2.0</a></li>
<li>demo <a href=https://huggingface.co/spaces/microsoft/OmniParser-v2 target=_blank rel="noopener noreferrer">microsoft/OmniParser-v2</a></li>
<li>provider
<ul>
<li><a href=https://replicate.com/microsoft/omniparser-v2 target=_blank rel="noopener noreferrer">https://replicate.com/microsoft/omniparser-v2</a></li>
</ul>
</li>
<li><a href=https://microsoft.github.io/WindowsAgentArena/ target=_blank rel="noopener noreferrer">https://microsoft.github.io/WindowsAgentArena/</a></li>
</ul>
</li>
<li><a href=https://github.com/microsoft/SoM target=_blank rel="noopener noreferrer">microsoft/SoM</a>
<ul>
<li>Set-of-Mark Prompting for GPT-4V and LMMs</li>
<li>Segment+Mark</li>
</ul>
</li>
<li><a href=https://github.com/microsoft/Magma target=_blank rel="noopener noreferrer">microsoft/Magma</a>
<ul>
<li>2025.02.18</li>
<li>A Foundation Model for Multimodal AI Agents</li>
<li>CLIP-ConvneXt-XXLarge</li>
<li>usecase/capabilities
<ul>
<li>Visual Planning and Action / 视觉规划和行动</li>
<li>Robotics Manipulations / 机器人操作</li>
<li>Environment Interaction / 环境交互</li>
<li>Visual Navigation / 视觉导航</li>
<li>高级图文理解</li>
</ul>
</li>
<li><a href=https://huggingface.co/MagmaAI target=_blank rel="noopener noreferrer">https://huggingface.co/MagmaAI</a></li>
<li><a href=https://huggingface.co/microsoft/Magma-8B target=_blank rel="noopener noreferrer">https://huggingface.co/microsoft/Magma-8B</a></li>
<li>demo <a href=https://huggingface.co/spaces/microsoft/Magma-UI target=_blank rel="noopener noreferrer">microsoft/Magma-UI</a></li>
<li>OLLAMA <a href=https://github.com/ollama/ollama/issues/9366 target=_blank rel="noopener noreferrer">https://github.com/ollama/ollama/issues/9366</a></li>
</ul>
</li>
</ul>
</li>
<li>Cohere for AI</li>
<li><a href=https://huggingface.co/CohereLabs/aya-vision-32b target=_blank rel="noopener noreferrer">https://huggingface.co/CohereLabs/aya-vision-32b</a>
<ul>
<li>多语言，23种语言</li>
</ul>
</li>
<li>OCR/Document Understanding
<ul>
<li><a href=https://github.com/opendatalab/OmniDocBench target=_blank rel="noopener noreferrer">opendatalab/OmniDocBench</a></li>
<li>Demo
<ul>
<li><a href=https://huggingface.co/spaces/prithivMLmods/Multimodal-OCR2 target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/prithivMLmods/Multimodal-OCR2</a></li>
</ul>
</li>
<li>Qwen VL</li>
<li>InternVL</li>
<li><a href=https://github.com/mindee/doctr target=_blank rel="noopener noreferrer">mindee/doctr</a>
<ul>
<li>Apache-2.0, Python, TensorFlow 2, PyTorch</li>
<li>Document Text Recognition</li>
<li>⚠️ french vocab, 不支持 中文</li>
<li><a href=https://huggingface.co/spaces/mindee/doctr target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/mindee/doctr</a></li>
<li>Multilingual support <a href=https://github.com/mindee/doctr/issues/1699 target=_blank rel="noopener noreferrer">mindee/doctr#1699</a></li>
</ul>
</li>
<li><a href=https://github.com/PaddlePaddle/PaddleOCR target=_blank rel="noopener noreferrer">PaddlePaddle/PaddleOCR</a></li>
<li>RapidOCR</li>
<li>tesseract</li>
<li>surya</li>
<li><a href=https://github.com/breezedeus/Pix2Text target=_blank rel="noopener noreferrer">breezedeus/Pix2Text</a></li>
<li><a href=https://github.com/docling-project/docling target=_blank rel="noopener noreferrer">docling-project/docling</a>
<ul>
<li><a href=https://huggingface.co/ds4sd/docling-models target=_blank rel="noopener noreferrer">ds4sd/docling-models</a></li>
<li>hf <a href=https://huggingface.co/ds4sd/SmolDocling-256M-preview target=_blank rel="noopener noreferrer">ds4sd/SmolDocling-256M-preview</a>
<ul>
<li>只支持英文</li>
<li>by Docling Team, IBM Research</li>
<li>based on SmolVLM-256M-Instruct</li>
</ul>
</li>
</ul>
</li>
<li><a href=https://github.com/Yuliang-Liu/MonkeyOCR target=_blank rel="noopener noreferrer">Yuliang-Liu/MonkeyOCR</a>
<ul>
<li>MonkeyOCR: Document Parsing with a Structure-Recognition-Relation Triplet Paradigm</li>
<li>2025.06.05</li>
<li>基于 Qwen2.5-VL-3b</li>
<li>支持 中文、英文</li>
<li>hf <a href=https://huggingface.co/echo840/MonkeyOCR target=_blank rel="noopener noreferrer">echo840/MonkeyOCR</a></li>
<li>Document Parsing LMM</li>
<li>擅长 公式识别、表格识别</li>
<li>传统方式: 版面分析、OCR、结构分析</li>
<li>SRR (Structure-Recognition-Relation)
<ul>
<li>结构检测 (Structure Detection)：一眼看懂文档的宏观布局，识别出这是一个表格、一个公式，还是一个普通段落。</li>
<li>内容识别 (Content Recognition)：在识别出结构的同时，完成对内部文字的 OCR 识别。</li>
<li>关系预测 (Relationship Prediction)：理解这些结构之间的关联，比如知道某个图表是为哪一段文字作解释的。</li>
</ul>
</li>
</ul>
</li>
<li><a href=https://huggingface.co/nanonets/Nanonets-OCR-s target=_blank rel="noopener noreferrer">nanonets/Nanonets-OCR-s</a>
<ul>
<li>基于 Qwen2.5-VL-3b</li>
<li>Image -> Structure Markdown</li>
</ul>
</li>
<li><a href=https://huggingface.co/ByteDance/Dolphin target=_blank rel="noopener noreferrer">ByteDance/Dolphin</a>
<ul>
<li>Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting</li>
</ul>
</li>
<li><a href=https://huggingface.co/ChatDOC/OCRFlux-3B target=_blank rel="noopener noreferrer">ChatDOC/OCRFlux-3B</a>
<ul>
<li>基于 Qwen/Qwen2.5-VL-3B-Instruct</li>
</ul>
</li>
<li><a href=https://github.com/ocrmypdf/OCRmyPDF target=_blank rel="noopener noreferrer">ocrmypdf/OCRmyPDF</a>
<ul>
<li>adds an OCR text layer to scanned PDF</li>
</ul>
</li>
<li><a href=https://github.com/Topdu/OpenOCR target=_blank rel="noopener noreferrer">Topdu/OpenOCR</a>
<ul>
<li>复旦大学</li>
</ul>
</li>
</ul>
</li>
<li>Document Structure/Layout Analysis/OCR Toolkit
<ul>
<li>Marker</li>
<li><a href=https://github.com/rednote-hilab/dots.ocr target=_blank rel="noopener noreferrer">rednote-hilab/dots.ocr</a>
<ul>
<li>MIT</li>
<li>2025.07.30</li>
<li>1.7B</li>
<li>hf <a href=https://huggingface.co/rednote-hilab/dots.ocr target=_blank rel="noopener noreferrer">rednote-hilab/dots.ocr</a></li>
<li><a href=https://huggingface.co/spaces/MohamedRashad/Dots-OCR target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/MohamedRashad/Dots-OCR</a></li>
<li>Ollama <a href=https://github.com/ollama/ollama/issues/11653 target=_blank rel="noopener noreferrer">https://github.com/ollama/ollama/issues/11653</a></li>
</ul>
</li>
<li><a href=https://github.com/allenai/olmocr target=_blank rel="noopener noreferrer">allenai/olmocr</a>
<ul>
<li>Apache-2.0, Python</li>
<li>Toolkit for linearizing PDFs for LLM datasets/training</li>
</ul>
</li>
<li><a href=https://github.com/opendatalab/MinerU target=_blank rel="noopener noreferrer">opendatalab/MinerU</a>
<ul>
<li>AGPLv3, Python</li>
<li>上海人工智能实验室（OpenDataLab）</li>
<li>PDF -> JSON, Markdown</li>
<li>LayoutLMv3</li>
<li>UniMERNet</li>
<li><a href=https://github.com/opendatalab/PDF-Extract-Kit target=_blank rel="noopener noreferrer">opendatalab/PDF-Extract-Kit</a></li>
</ul>
</li>
<li>DocLayout-YOLO</li>
</ul>
</li>
<li>Task Specific Models/任务模型/领域模型
<ul>
<li>WebWalkerQA <a href=https://huggingface.co/spaces/callanwu/WebWalkerQALeaderboard target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/callanwu/WebWalkerQALeaderboard</a></li>
<li><a href=https://github.com/Alibaba-NLP/WebAgent target=_blank rel="noopener noreferrer">Alibaba-NLP/WebAgent</a>
<ul>
<li>hf <a href=https://huggingface.co/Alibaba-NLP/WebDancer-32B target=_blank rel="noopener noreferrer">Alibaba-NLP/WebDancer-32B</a></li>
</ul>
</li>
<li><a href=https://huggingface.co/osmosis-ai/Osmosis-Structure-0.6B target=_blank rel="noopener noreferrer">osmosis-ai/Osmosis-Structure-0.6B</a>
<ul>
<li>基于 Qwen3-0.6B</li>
<li>文本 -> JSON</li>
</ul>
</li>
<li><a href=https://huggingface.co/osmosis-ai/osmosis-mcp-4b target=_blank rel="noopener noreferrer">osmosis-ai/osmosis-mcp-4b</a>
<ul>
<li>基于 Qwen3-4B</li>
<li>multi step MCP-style tool usage</li>
</ul>
</li>
<li><a href=https://huggingface.co/tencent/Hunyuan-MT-Chimera-7B target=_blank rel="noopener noreferrer">腾讯/Hunyuan-MT-Chimera-7B</a>
<ul>
<li>多语言翻译</li>
<li>30+语言</li>
</ul>
</li>
<li><a href=https://huggingface.co/tencent/Hunyuan-MT-7B target=_blank rel="noopener noreferrer">腾讯/Hunyuan-MT-7B</a>
<ul>
<li>中英双语翻译</li>
</ul>
</li>
</ul>
</li>
<li>LLaMA based
<ul>
<li>Vicuna</li>
</ul>
</li>
<li><a href=https://github.com/haotian-liu/LLaVA target=_blank rel="noopener noreferrer">haotian-liu/LLaVA</a>
<ul>
<li>LLaVA (Large Language and Vision Assistant)</li>
<li>Vicuna + CLIP</li>
</ul>
</li>
<li>OpenGVLab
<ul>
<li><a href=https://huggingface.co/OpenGVLab/InternVL3-8B target=_blank rel="noopener noreferrer">OpenGVLab/InternVL3-8B</a>
<ul>
<li><a href=https://huggingface.co/OpenGVLab/VisualPRM-8B-v1_1 target=_blank rel="noopener noreferrer">OpenGVLab/VisualPRM-8B-v1_1</a>
<ul>
<li>Process Reward Model (PRM)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>command-a
<ul>
<li>主要用于 Agent, 工具调用</li>
<li><a href=https://cohere.com/blog/command-a target=_blank rel="noopener noreferrer">https://cohere.com/blog/command-a</a></li>
<li><a href=https://huggingface.co/CohereForAI/c4ai-command-a-03-2025 target=_blank rel="noopener noreferrer">https://huggingface.co/CohereForAI/c4ai-command-a-03-2025</a></li>
</ul>
</li>
<li>llama2
<ul>
<li>7B, 13B, 70B</li>
</ul>
</li>
<li>uncensored/abliterated/CensorTune
<ul>
<li><a href=https://github.com/Sumandora/remove-refusals-with-transformers target=_blank rel="noopener noreferrer">Sumandora/remove-refusals-with-transformers</a></li>
<li><a href=https://huggingface.co/NSFW-API/NSFW_Wan_1.3b target=_blank rel="noopener noreferrer">https://huggingface.co/NSFW-API/NSFW_Wan_1.3b</a></li>
<li><a href=https://huggingface.co/huihui-ai target=_blank rel="noopener noreferrer">https://huggingface.co/huihui-ai</a></li>
<li><a href=https://huggingface.co/datasets/Guilherme34/uncensor target=_blank rel="noopener noreferrer">https://huggingface.co/datasets/Guilherme34/uncensor</a></li>
<li><a href="https://huggingface.co/models?search=uncensored" target=_blank rel="noopener noreferrer">https://huggingface.co/models?search=uncensored</a></li>
<li><a href=https://erichartford.com/uncensored-models target=_blank rel="noopener noreferrer">https://erichartford.com/uncensored-models</a></li>
<li><a href="https://www.pixiv.net/novel/show.php?id=21039830" target=_blank rel="noopener noreferrer">https://www.pixiv.net/novel/show.php?id=21039830</a>
<ul>
<li><a href=https://huggingface.co/a686d380/rwkv-5-h-world target=_blank rel="noopener noreferrer">https://huggingface.co/a686d380/rwkv-5-h-world</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=https://github.com/microsoft/BitNet target=_blank rel="noopener noreferrer">microsoft/BitNet</a>
<ul>
<li>MIT, C++, Python</li>
<li>by Microsoft</li>
<li><a href="https://news.ycombinator.com/item?id=41877609" target=_blank rel="noopener noreferrer">HN</a></li>
</ul>
</li>
<li>vicuna</li>
<li>mistral</li>
<li>mixtral</li>
<li>Flan</li>
<li>Alpaca</li>
<li>GPT4All</li>
<li>Chinese LLaMA</li>
<li>Vigogne (French)</li>
<li>LLaMA</li>
<li>Databricks Dolly 2.0
<ul>
<li><a href=https://huggingface.co/databricks/dolly-v2-12b target=_blank rel="noopener noreferrer">https://huggingface.co/databricks/dolly-v2-12b</a></li>
<li><a href=https://github.com/databrickslabs/dolly/tree/master/data target=_blank rel="noopener noreferrer">https://github.com/databrickslabs/dolly/tree/master/data</a></li>
</ul>
</li>
<li><a href=https://huggingface.co/stabilityai/stable-diffusion-2 target=_blank rel="noopener noreferrer">https://huggingface.co/stabilityai/stable-diffusion-2</a></li>
<li><a href=https://github.com/togethercomputer/OpenChatKit target=_blank rel="noopener noreferrer">togethercomputer/OpenChatKit</a></li>
<li><a href=/notes/ai/model/alpaca>Alpaca</a>
<ul>
<li>基于 LLaMA + 指令训练</li>
</ul>
</li>
<li><a href=https://github.com/FlagAI-Open/FlagAI target=_blank rel="noopener noreferrer">FlagAI-Open/FlagAI</a></li>
<li><a href=https://github.com/hpcaitech/ColossalAI target=_blank rel="noopener noreferrer">hpcaitech/ColossalAI</a></li>
<li><a href=https://github.com/BlinkDL/ChatRWKV target=_blank rel="noopener noreferrer">BlinkDL/ChatRWKV</a>
<ul>
<li>ChatGPT like</li>
<li>RWKV (100% RNN)</li>
</ul>
</li>
<li><a href=https://github.com/nebuly-ai/nebullvm target=_blank rel="noopener noreferrer">nebuly-ai/nebullvm</a></li>
<li><a href=https://github.com/FMInference/FlexGen target=_blank rel="noopener noreferrer">FMInference/FlexGen</a></li>
<li><a href=https://github.com/EssayKillerBrain/WriteGPT target=_blank rel="noopener noreferrer">EssayKillerBrain/WriteGPT</a>
<ul>
<li>GPT-2</li>
</ul>
</li>
<li><a href=https://github.com/ymcui/Chinese-LLaMA-Alpaca target=_blank rel="noopener noreferrer">ymcui/Chinese-LLaMA-Alpaca</a></li>
<li><a href=https://www.promptingguide.ai/zh/models/collection target=_blank rel="noopener noreferrer">https://www.promptingguide.ai/zh/models/collection</a></li>
<li><a href=https://www.together.xyz/blog/redpajama-models-v1 target=_blank rel="noopener noreferrer">Releasing 3B and 7B RedPajama-INCITE family of models including base, instruction-tuned & chat models</a></li>
<li>RedPajama-Data-v2
<ul>
<li><a href=https://together.ai/blog/redpajama-data-v2 target=_blank rel="noopener noreferrer">https://together.ai/blog/redpajama-data-v2</a></li>
<li><a href=https://github.com/togethercomputer/RedPajama-Data target=_blank rel="noopener noreferrer">https://github.com/togethercomputer/RedPajama-Data</a></li>
<li><a href=https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2 target=_blank rel="noopener noreferrer">https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2</a></li>
<li>en, de, fr, es, it</li>
</ul>
</li>
<li><a href=https://huggingface.co/spaces/hysts/ControlNet-v1-1 target=_blank rel="noopener noreferrer">hysts/ControlNet-v1-1</a></li>
<li>ggml
<ul>
<li><a href=https://github.com/ggerganov/ggml target=_blank rel="noopener noreferrer">ggerganov/ggml</a>
<ul>
<li>MIT, C</li>
</ul>
</li>
</ul>
</li>
<li>.pth - PyTorch
<ul>
<li>checklist.chk - MD5</li>
<li>params.json - <code>{"dim": 4096, "multiple_of": 256, "n_heads": 32, "n_layers": 32, "norm_eps": 1e-06, "vocab_size": -1}</code></li>
<li><a href=https://pytorch.org/tutorials/beginner/saving_loading_models.html target=_blank rel="noopener noreferrer">Saving & Loading Models</a></li>
</ul>
</li>
<li><a href=https://medium.com/geekculture/list-of-open-sourced-fine-tuned-large-language-models-llm-8d95a2e0dc76 target=_blank rel="noopener noreferrer">https://medium.com/geekculture/list-of-open-sourced-fine-tuned-large-language-models-llm-8d95a2e0dc76</a></li>
<li><a href=https://erichartford.com/uncensored-models target=_blank rel="noopener noreferrer">https://erichartford.com/uncensored-models</a></li>
<li><a href=https://huggingface.co/spaces/facebook/seamless_m4t target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/facebook/seamless_m4t</a></li>
<li><a href=https://github.com/LinkSoul-AI/Chinese-Llama-2-7b target=_blank rel="noopener noreferrer">https://github.com/LinkSoul-AI/Chinese-Llama-2-7b</a></li>
<li>Jina AI 8k text embedding
<ul>
<li><a href="https://news.ycombinator.com/item?id=38020109" target=_blank rel="noopener noreferrer">https://news.ycombinator.com/item?id=38020109</a></li>
<li><a href=https://huggingface.co/jinaai/jina-embeddings-v2-base-en target=_blank rel="noopener noreferrer">https://huggingface.co/jinaai/jina-embeddings-v2-base-en</a></li>
<li><a href=https://huggingface.co/jinaai/jina-embeddings-v2-small-en target=_blank rel="noopener noreferrer">https://huggingface.co/jinaai/jina-embeddings-v2-small-en</a></li>
</ul>
</li>
<li>Models
<ul>
<li><a href=https://huggingface.co/models target=_blank rel="noopener noreferrer">https://huggingface.co/models</a></li>
<li><a href=https://www.modelscope.cn/models target=_blank rel="noopener noreferrer">https://www.modelscope.cn/models</a></li>
<li><a href=https://civitai.com/ target=_blank rel="noopener noreferrer">https://civitai.com/</a></li>
<li><a href=https://openmodeldb.info/ target=_blank rel="noopener noreferrer">https://openmodeldb.info/</a></li>
</ul>
</li>
</ul>
<div class="language-bash codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-bash codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain"># AVX = 1 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 |</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">grep avx /proc/cpuinfo --color # x86_64</span><br/></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=domains>Domains<a href=#domains class=hash-link aria-label="Direct link to Domains" title="Direct link to Domains" translate=no>​</a></h2>
<ul>
<li>文本
<ul>
<li>Translate</li>
<li>Agentic</li>
<li>Reasoning</li>
<li>Coding</li>
</ul>
</li>
<li>视觉/图像
<ul>
<li>VLM</li>
<li>OCR</li>
<li>Layout Analysis</li>
<li>Object Detection</li>
<li>Image Classification</li>
<li>Image Segmentation</li>
<li>Image Generation</li>
<li>Image Editing</li>
</ul>
</li>
<li>音频/语音
<ul>
<li>ASR</li>
<li>TTS</li>
<li>STT</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=vlm>VLM<a href=#vlm class=hash-link aria-label="Direct link to VLM" title="Direct link to VLM" translate=no>​</a></h2>
<ul>
<li>VLM - Vision Language Model</li>
<li>box_2d format</li>
<li>Qwen (xmin, ymin, xmax, ymax) floats between 0-1</li>
<li>Gemini (ymin, xmin, ymax, xmax) integers between 0-1000</li>
<li>参考
<ul>
<li><a href=https://simedw.com/2025/07/10/gemini-bounding-boxes/ target=_blank rel="noopener noreferrer">Is Gemini 2.5 good at bounding boxes?</a>
<ul>
<li><a href="https://news.ycombinator.com/item?id=44520292" target=_blank rel="noopener noreferrer">https://news.ycombinator.com/item?id=44520292</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=computer-agent>Computer Agent<a href=#computer-agent class=hash-link aria-label="Direct link to Computer Agent" title="Direct link to Computer Agent" translate=no>​</a></h2>
<ul>
<li>Qwen 2.5 VL 72B</li>
<li>UI-TARS</li>
<li><a href=https://github.com/web-infra-dev/Midscene target=_blank rel="noopener noreferrer">web-infra-dev/Midscene</a>
<ul>
<li>MIT, TypeScript</li>
<li>UI-TARS, Qwen-2.5-VL</li>
</ul>
</li>
<li><a href=https://platform.openai.com/docs/models/computer-use-preview target=_blank rel="noopener noreferrer">https://platform.openai.com/docs/models/computer-use-preview</a>
<ul>
<li><span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>3</mn><mi mathvariant=normal>/</mi></mrow><annotation encoding=application/x-tex>3 / </annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em></span><span class=mord>3/</span></span></span></span>12</li>
</ul>
</li>
<li><a href=https://arena.xlang.ai/leaderboard target=_blank rel="noopener noreferrer">https://arena.xlang.ai/leaderboard</a></li>
<li><a href=https://huggingface.co/Menlo/Jan-nano target=_blank rel="noopener noreferrer">https://huggingface.co/Menlo/Jan-nano</a>
<ul>
<li>for deep research tasks</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=chinese>中文<a href=#chinese class=hash-link aria-label="Direct link to 中文" title="Direct link to 中文" translate=no>​</a></h2>
<ul>
<li>Qwen2</li>
<li><a href=https://github.com/LlamaFamily/Llama-Chinese target=_blank rel="noopener noreferrer">LlamaFamily/Llama-Chinese</a></li>
<li><a href=https://github.com/UnicomAI/Unichat-llama3-Chinese target=_blank rel="noopener noreferrer">UnicomAI/Unichat-llama3-Chinese</a>
<ul>
<li>联通 llama3 微调</li>
</ul>
</li>
<li><a href=https://github.com/datawhalechina/self-llm target=_blank rel="noopener noreferrer">https://github.com/datawhalechina/self-llm</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=fine-tuning>Fine-tuning<a href=#fine-tuning class=hash-link aria-label="Direct link to Fine-tuning" title="Direct link to Fine-tuning" translate=no>​</a></h2>
<ul>
<li><a href=https://huggingface.co/ValueFX9507/Tifa-Deepsex-14b-CoT-GGUF-Q4 target=_blank rel="noopener noreferrer">https://huggingface.co/ValueFX9507/Tifa-Deepsex-14b-CoT-GGUF-Q4</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=tts>TTS<a href=#tts class=hash-link aria-label="Direct link to TTS" title="Direct link to TTS" translate=no>​</a></h2>
<ul>
<li>TTS, Dialogue, Audio, Speech, Voice</li>
<li>TTS
<ul>
<li>Text Analysis</li>
<li>Acoustic</li>
<li>Vocoder</li>
<li><a href=https://huggingface.co/spaces/TTS-AGI/TTS-Arena target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/TTS-AGI/TTS-Arena</a></li>
<li><a href=https://huggingface.co/spaces/TTS-AGI/TTS-Arena-V2 target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/TTS-AGI/TTS-Arena-V2</a></li>
</ul>
</li>
<li>Turn / VAD / Voice Activity Detection
<ul>
<li>VAD (voice activity detection)
<ul>
<li>传统检测方式, 不能理解语言所以容易导致 FP 检测</li>
</ul>
</li>
<li><a href=https://huggingface.co/livekit/turn-detector target=_blank rel="noopener noreferrer">https://huggingface.co/livekit/turn-detector</a></li>
<li><a href=https://github.com/livekit/agents/tree/main/livekit-plugins/livekit-plugins-turn-detector target=_blank rel="noopener noreferrer">https://github.com/livekit/agents/tree/main/livekit-plugins/livekit-plugins-turn-detector</a></li>
<li><a href=https://huggingface.co/spaces/webml-community/conversational-webgpu target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/webml-community/conversational-webgpu</a></li>
</ul>
</li>
<li>选择因素
<ul>
<li>语音质量：合成语音需自然流畅，清晰易懂，适合长时间聆听，能表达情感。</li>
<li>个性化：支持音色、语速、语调等自定义，满足不同场景和品牌需求。</li>
<li>语言支持</li>
<li>延迟：低延迟适合实时交互场景，如语音助手；非实时应用对延迟要求较低。</li>
<li>资源需求</li>
<li>授权与使用：明确模型的授权方式和使用限制，注意是否需注明来源。</li>
</ul>
</li>
<li>KokoroTTS
<ul>
<li><a href=https://huggingface.co/onnx-community/Kokoro-82M-v1.0-ONNX target=_blank rel="noopener noreferrer">https://huggingface.co/onnx-community/Kokoro-82M-v1.0-ONNX</a></li>
</ul>
</li>
<li><a href=https://github.com/VITA-MLLM/VITA-Audio target=_blank rel="noopener noreferrer">VITA-MLLM/VITA-Audio</a>
<ul>
<li>ASR, TTS, SpokenQA</li>
<li><a href=https://huggingface.co/spaces/shenyunhang/VITA-Audio target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/shenyunhang/VITA-Audio</a></li>
</ul>
</li>
<li><a href=https://github.com/resemble-ai/chatterbox target=_blank rel="noopener noreferrer">resemble-ai/chatterbox</a>
<ul>
<li>MIT, Python</li>
<li>开源版本只支持 en</li>
<li>hf <a href=https://huggingface.co/ResembleAI/chatterbox target=_blank rel="noopener noreferrer">ResembleAI/chatterbox</a></li>
</ul>
</li>
<li><a href=https://github.com/FunAudioLLM/CosyVoice target=_blank rel="noopener noreferrer">FunAudioLLM/CosyVoice</a>
<ul>
<li>中文、英文、日文、韩文、中文方言（粤语、四川话、上海话、天津话、武汉话等）</li>
<li>hf <a href=https://huggingface.co/FunAudioLLM/CosyVoice2-0.5B target=_blank rel="noopener noreferrer">FunAudioLLM/CosyVoice2-0.5B</a></li>
</ul>
</li>
<li><a href=https://github.com/yl4579/HiFTNet target=_blank rel="noopener noreferrer">yl4579/HiFTNet</a></li>
<li><a href=https://github.com/THUDM/GLM-4-Voice target=_blank rel="noopener noreferrer">THUDM/GLM-4-Voice</a>
<ul>
<li>中英语音对话模型</li>
<li><a href=https://huggingface.co/THUDM/glm-4-voice-tokenizer target=_blank rel="noopener noreferrer">https://huggingface.co/THUDM/glm-4-voice-tokenizer</a></li>
<li><a href=https://huggingface.co/THUDM/glm-4-voice-decoder target=_blank rel="noopener noreferrer">https://huggingface.co/THUDM/glm-4-voice-decoder</a>
<ul>
<li>基于 CosyVoice 重新训练的支持流式推理的语音解码器，将离散化的语音 Token 转化为连续的语音输出。</li>
</ul>
</li>
</ul>
</li>
<li><a href=https://huggingface.co/datasets/gpt-omni/VoiceAssistant-400K target=_blank rel="noopener noreferrer">https://huggingface.co/datasets/gpt-omni/VoiceAssistant-400K</a></li>
<li><a href=https://github.com/shivammehta25/Matcha-TTS target=_blank rel="noopener noreferrer">shivammehta25/Matcha-TTS</a></li>
<li><a href=https://github.com/nari-labs/dia target=_blank rel="noopener noreferrer">nari-labs/dia</a>
<ul>
<li>text to dialogue</li>
<li>只支持 en</li>
<li><a href=https://huggingface.co/spaces/nari-labs/Dia-1.6B target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/nari-labs/Dia-1.6B</a></li>
</ul>
</li>
<li><a href=https://huggingface.co/fishaudio/openaudio-s1-mini target=_blank rel="noopener noreferrer">fishaudio/openaudio-s1-mini</a>
<ul>
<li>0.5B</li>
<li>S1 4B, 商业版本</li>
</ul>
</li>
<li>商业
<ul>
<li><a href=https://elevenlabs.io/ target=_blank rel="noopener noreferrer">https://elevenlabs.io/</a></li>
</ul>
</li>
<li><a href=https://huggingface.co/hf-audio target=_blank rel="noopener noreferrer">https://huggingface.co/hf-audio</a></li>
</ul>









































<table><thead><tr><th>case<th>desc<th>notes<th>models<tbody><tr><td>虚拟助手<td>AI助手提供自然语音应答，优化交互<td>自然度高、低延迟、多情感<td>XTTS-v2, MeloTTS, F5-TTS, ChatTTS<tr><td>无障碍解决方案<td>为视觉及学习障碍者提供语音内容<td>清晰度高、易懂、稳定性好<td>MeloTTS, Bark<tr><td>内容创作<td>生成播客、有声书等专业配音<td>音色多样、情感丰富、韵律自然<td>XTTSv2, F5-TTS, GPT-SoVITS-v2<tr><td>自动化客服<td>IVR系统赋能高效自动化客服<td>清晰稳定、可定制性强<td>Piper, ParlerTTS, XTTSv2<tr><td>语音自助终端<td>自助终端的交互式语音应答<td>响应快速、清晰易懂<td>Piper, MeloTTS</table>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=stt>STT<a href=#stt class=hash-link aria-label="Direct link to STT" title="Direct link to STT" translate=no>​</a></h2>
<ul>
<li>STT - Speech to Text - 语音转文本</li>
<li>ASR - Automatic Speech Recognition - 自动语音识别</li>
<li>STT / Speech-to-Text / ASR / Automatic Speech Recognition / Speech Recognition
<ul>
<li><a href=https://huggingface.co/spaces/hf-audio/open_asr_leaderboard target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/hf-audio/open_asr_leaderboard</a></li>
</ul>
</li>
<li><a href=https://github.com/modelscope/FunASR target=_blank rel="noopener noreferrer">modelscope/FunASR</a>
<ul>
<li>MIT, Python</li>
<li>ASR, VAD</li>
</ul>
</li>
<li>Voxtral
<ul>
<li>支持中文</li>
<li><a href=https://huggingface.co/mistralai/Voxtral-Mini-3B-2507 target=_blank rel="noopener noreferrer">mistralai/Voxtral-Mini-3B-2507</a></li>
<li><a href=https://huggingface.co/mistralai/Voxtral-Small-24B-2507 target=_blank rel="noopener noreferrer">mistralai/Voxtral-Small-24B-2507</a></li>
<li>Voxtral Mini Transcribe</li>
<li><a href=https://huggingface.co/docs/transformers/main/en/model_doc/voxtral target=_blank rel="noopener noreferrer">https://huggingface.co/docs/transformers/main/en/model_doc/voxtral</a></li>
<li><a href=https://mistral.ai/news/voxtral target=_blank rel="noopener noreferrer">https://mistral.ai/news/voxtral</a></li>
<li><a href=https://huggingface.co/spaces/MohamedRashad/Voxtral target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/MohamedRashad/Voxtral</a></li>
<li>参考
<ul>
<li><a href=https://github.com/coezbek/voxtral-test target=_blank rel="noopener noreferrer">https://github.com/coezbek/voxtral-test</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=https://huggingface.co/nvidia/canary-1b-flash target=_blank rel="noopener noreferrer">https://huggingface.co/nvidia/canary-1b-flash</a>
<ul>
<li>没有中文</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=music>Music<a href=#music class=hash-link aria-label="Direct link to Music" title="Direct link to Music" translate=no>​</a></h2>
<ul>
<li>Music Generation - 音乐生成</li>
<li>Song Generation - 歌曲生成</li>
<li><a href=https://huggingface.co/google/magenta-realtime target=_blank rel="noopener noreferrer">https://huggingface.co/google/magenta-realtime</a></li>
<li><a href=https://labs.google/fx/tools/music-fx-dj target=_blank rel="noopener noreferrer">https://labs.google/fx/tools/music-fx-dj</a></li>
<li><a href=http://goo.gle/lyria-realtime target=_blank rel="noopener noreferrer">http://goo.gle/lyria-realtime</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=mllm>MLLM<a href=#mllm class=hash-link aria-label="Direct link to MLLM" title="Direct link to MLLM" translate=no>​</a></h2>
<ul>
<li>Multimodal Large Language Model - 多模态大语言模型</li>
<li>结构: 视觉编码器 + 投影器 + 语言模型</li>
<li>Vision Model
<ul>
<li>ViT</li>
</ul>
</li>
<li>Language Model</li>
<li>Projector / Vision-Language Adapter
<ul>
<li>将视觉模型提取出的图像特征与语言模型的表示空间对齐</li>
<li>Cross-Attention Module - 交叉注意力模块</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=vision>Vision<a href=#vision class=hash-link aria-label="Direct link to Vision" title="Direct link to Vision" translate=no>​</a></h2>
<ul>
<li>Document OCR - 文档 OCR</li>
<li>Handwriting OCR - 手写 OCR</li>
<li>Visual QA / Image QA - 图片 QA</li>
<li>Visual Reasoning - 图像推理</li>
<li>Image Classification - 图片分类</li>
<li>Document Understanding - 文档理解</li>
<li>Video Understanding - 视频理解</li>
<li>Object Detection - 对象识别</li>
<li>Object Counting - 对象计数</li>
<li>Agent - 屏幕理解操作</li>
<li>Object Grounding - 物体定位
<ul>
<li>返回 Bounding Box 坐标</li>
<li>visual grounding poor performance after fine-tuning <a href=https://github.com/2U1/Qwen2-VL-Finetune/issues/77 target=_blank rel="noopener noreferrer">2U1/Qwen2-VL-Finetune#77</a></li>
</ul>
</li>
</ul>
<hr/>
<ul>
<li>Qwen2 VL
<ul>
<li>factor=28</li>
</ul>
</li>
<li>SmolVLM 256M
<ul>
<li>64 image tokens per 512px image</li>
<li><a href=https://huggingface.co/spaces/webml-community/smolvlm-realtime-webgpu target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/webml-community/smolvlm-realtime-webgpu</a>
<ul>
<li>500M, SmolVLM</li>
<li><a href=https://www.reddit.com/r/LocalLLaMA/comments/1kmi6vl target=_blank rel="noopener noreferrer">https://www.reddit.com/r/LocalLLaMA/comments/1kmi6vl</a></li>
</ul>
</li>
</ul>
</li>
<li>Video Understanding
<ul>
<li><a href=https://huggingface.co/google/videoprism target=_blank rel="noopener noreferrer">https://huggingface.co/google/videoprism</a></li>
</ul>
</li>
<li>参考
<ul>
<li><a href=https://blog.roboflow.com/multimodal-vision-models/ target=_blank rel="noopener noreferrer">https://blog.roboflow.com/multimodal-vision-models/</a></li>
<li><a href=https://github.com/0xsline/GeminiImageApp target=_blank rel="noopener noreferrer">https://github.com/0xsline/GeminiImageApp</a></li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=coding>Coding<a href=#coding class=hash-link aria-label="Direct link to Coding" title="Direct link to Coding" translate=no>​</a></h2>
<ul>
<li><a href=https://github.com/All-Hands-AI/OpenHands target=_blank rel="noopener noreferrer">All-Hands-AI/OpenHands</a></li>
<li><a href=https://github.com/block/goose target=_blank rel="noopener noreferrer">block/goose</a></li>
<li><a href=https://www.swebench.com/ target=_blank rel="noopener noreferrer">https://www.swebench.com/</a></li>
<li>模型
<ul>
<li>devstral 24B
<ul>
<li><a href=https://mistral.ai/news/devstral target=_blank rel="noopener noreferrer">https://mistral.ai/news/devstral</a></li>
<li><a href=https://ollama.com/library/devstral target=_blank rel="noopener noreferrer">https://ollama.com/library/devstral</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=video>Video<a href=#video class=hash-link aria-label="Direct link to Video" title="Direct link to Video" translate=no>​</a></h2>
<ul>
<li>整个流程</li>
<li>Flow</li>
<li><a href=https://github.com/harry0703/MoneyPrinterTurbo target=_blank rel="noopener noreferrer">harry0703/MoneyPrinterTurbo</a>
<ul>
<li>一键生成高清短视频</li>
<li><a href=https://huggingface.co/spaces/chaowenguo/avfwae target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/chaowenguo/avfwae</a></li>
</ul>
</li>
<li><a href=https://github.com/Lightricks/LTX-Video target=_blank rel="noopener noreferrer">Lightricks/LTX-Video</a>
<ul>
<li>30 FPS, 1216×704</li>
<li>text-to-image, image-to-video, keyframe-based animation, video extension, video-to-video</li>
</ul>
</li>
<li><a href=https://github.com/Wan-Video target=_blank rel="noopener noreferrer">Wan-Video</a>
<ul>
<li>WAN 2.1
<ul>
<li><a href=https://huggingface.co/lym00/Wan2.1-T2V-1.3B-Self-Forcing-VACE-Addon-Experiment target=_blank rel="noopener noreferrer">https://huggingface.co/lym00/Wan2.1-T2V-1.3B-Self-Forcing-VACE-Addon-Experiment</a></li>
<li><a href=https://huggingface.co/spaces/multimodalart/wan2-1-fast target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/multimodalart/wan2-1-fast</a></li>
</ul>
</li>
</ul>
</li>
<li>参考
<ul>
<li><a href=https://github.com/Olow304/memvid target=_blank rel="noopener noreferrer">Olow304/memvid</a></li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=image-generation>Image Generation<a href=#image-generation class=hash-link aria-label="Direct link to Image Generation" title="Direct link to Image Generation" translate=no>​</a></h2>
<ul>
<li>Image Generation - 图像生成</li>
<li>Image Editing - 图像编辑</li>
<li>Image Inpainting - 图像修复</li>
<li>Image Upscaling - 图像放大</li>
<li>Image Variation - 图像变体</li>
<li>Super Resolution - 超分辨率</li>
<li>Multimodal Understanding - 多模态理解</li>
<li>OpenCompass Multi-modal Academic Benchmarks
<ul>
<li>MMB MMS MMMU MathVista Hallusion AI2D OCRBench MMVet</li>
</ul>
</li>
<li>GenEval
<ul>
<li>Single object Two object Counting Colors Position Attribute binding</li>
</ul>
</li>
<li>DPG-Bench
<ul>
<li>Global Entity Attribute Relation Other</li>
</ul>
</li>
<li>ImgEdit-Bench
<ul>
<li>Add Adjust Extract Replace Remove Background Style Hybrid Action</li>
</ul>
</li>
<li>GEdit-Bench-EN
<ul>
<li>Background Change Color Alteration Material Modification Motion Change Portrait Beautification Style Transfer Subject Addition Subject Removal Subject Replacement Text Modification Tone Transformation</li>
</ul>
</li>
<li><a href=https://huggingface.co/AIDC-AI/Ovis-U1-3B target=_blank rel="noopener noreferrer">AIDC-AI/Ovis-U1-3B</a>
<ul>
<li>3B, Flux based</li>
</ul>
</li>
<li><a href=https://github.com/advimman/lama target=_blank rel="noopener noreferrer">advimman/lama</a>
<ul>
<li>Image Inpainting, Resolution-robust Large Mask Inpainting</li>
</ul>
</li>
<li>Styles
<ul>
<li><a href=https://huggingface.co/showlab/OmniConsistency target=_blank rel="noopener noreferrer">showlab/OmniConsistency</a>
<ul>
<li>OmniConsistency: Learning Style-Agnostic Consistency from Paired Stylization Data</li>
<li><a href=https://github.com/lc03lc/Comfyui_OmniConsistency target=_blank rel="noopener noreferrer">https://github.com/lc03lc/Comfyui_OmniConsistency</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=https://github.com/huggingface/diffusers target=_blank rel="noopener noreferrer">huggingface/diffusers</a>
<ul>
<li><a href=https://github.com/bghira/SimpleTuner target=_blank rel="noopener noreferrer">bghira/SimpleTuner</a></li>
<li><a href=https://github.com/ostris/ai-toolkit target=_blank rel="noopener noreferrer">ostris/ai-toolkit</a></li>
</ul>
</li>
<li><a href=https://huggingface.co/ByteDance/XVerse target=_blank rel="noopener noreferrer">ByteDance/XVerse</a>
<ul>
<li>Consistent Multi-Subject Control of Identity and Semantic Attributes via DiT Modulation</li>
</ul>
</li>
<li>FLUX.1
<ul>
<li><a href=https://playground.bfl.ai/ target=_blank rel="noopener noreferrer">https://playground.bfl.ai/</a></li>
<li>collection <a href=https://huggingface.co/collections/black-forest-labs/flux1-679d013aee236841c0e9d38a target=_blank rel="noopener noreferrer">FLUX.1</a></li>
<li>hf <a href=https://huggingface.co/black-forest-labs/FLUX.1-dev target=_blank rel="noopener noreferrer">black-forest-labs/FLUX.1-dev</a>
<ul>
<li>12B</li>
</ul>
</li>
<li>FLUX.1 Kontext
<ul>
<li>distilled variant of Kontext</li>
<li>目前生成的图有点糊</li>
<li><a href=https://bfl.ai/models/flux-kontext target=_blank rel="noopener noreferrer">https://bfl.ai/models/flux-kontext</a></li>
<li><a href=https://replicate.com/black-forest-labs/flux-kontext-pro target=_blank rel="noopener noreferrer">https://replicate.com/black-forest-labs/flux-kontext-pro</a></li>
<li><a href=https://replicate.com/flux-kontext-apps target=_blank rel="noopener noreferrer">https://replicate.com/flux-kontext-apps</a></li>
<li><a href="https://news.ycombinator.com/item?id=44128322" target=_blank rel="noopener noreferrer">https://news.ycombinator.com/item?id=44128322</a></li>
</ul>
</li>
<li><a href=https://huggingface.co/lodestones/Chroma target=_blank rel="noopener noreferrer">https://huggingface.co/lodestones/Chroma</a></li>
</ul>
</li>
<li><a href=https://genai-showdown.specr.net/ target=_blank rel="noopener noreferrer">https://genai-showdown.specr.net/</a></li>
</ul>
<p><strong>问题领域</strong></p>
<ul>
<li>Prompt adherence（提示词遵循度）</li>
<li>Generation quality（生成质量）</li>
<li>Instructiveness（可指导性）</li>
<li>Consistency of styles, characters, settings, etc.（风格、角色、设置的一致性）</li>
<li>Deliberate and exact intentional posing of characters and set pieces（角色和场景元素的精确姿态和故意摆放）</li>
<li>Compositing different images or layers together（将不同图像或图层组合在一起）</li>
<li>Relighting（重新打光）</li>
<li>Posing built into the model. No ControlNet hacks.（姿态控制内置于模型中，无需ControlNet等“黑科技”）</li>
<li>References built into the model. No IPAdapter, no required character/style LoRAs, etc.（参考功能内置于模型中，无需IPAdapter、角色/风格LoRA等）</li>
<li>Ability to address objects, characters, mannequins, etc. for deletion / insertion.（能够针对物体、角色、人体模型等进行删除/插入操作）</li>
<li>Ability to pull sources from across multiple images with or without "innovation" / change to their pixels.（能够从多张图片中提取来源，无论是否对其像素进行“创新”/更改）</li>
<li>Fine-tunable (so we can get higher quality and precision)（可微调，以获得更高的质量和精度）</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=media-generation>Media Generation<a href=#media-generation class=hash-link aria-label="Direct link to Media Generation" title="Direct link to Media Generation" translate=no>​</a></h2>
<ul>
<li>Image & Text to Image, Video, Audio</li>
<li>Lip Sync - 口型同步</li>
<li>Text-guided</li>
<li><a href=https://huggingface.co/OmniAvatar/OmniAvatar-14B target=_blank rel="noopener noreferrer">OmniAvatar/OmniAvatar-14B</a>
<ul>
<li>OmniAvatar: Efficient Audio-Driven Avatar Video Generation with Adaptive Body Animation</li>
</ul>
</li>
<li>商业/平台/Hub/Router
<ul>
<li><a href=https://fal.ai/ target=_blank rel="noopener noreferrer">https://fal.ai/</a></li>
<li><a href=https://replicate.com target=_blank rel="noopener noreferrer">https://replicate.com</a></li>
<li><a href=https://runware.ai target=_blank rel="noopener noreferrer">https://runware.ai</a></li>
<li><a href=https://www.together.ai target=_blank rel="noopener noreferrer">https://www.together.ai</a></li>
<li><a href=https://datacrunch.io/ target=_blank rel="noopener noreferrer">https://datacrunch.io/</a></li>
<li><a href=https://heygen.com target=_blank rel="noopener noreferrer">https://heygen.com</a></li>
<li><a href=https://aihubmix.com/ target=_blank rel="noopener noreferrer">https://aihubmix.com/</a></li>
<li><a href=https://www.dmxapi.cn/ target=_blank rel="noopener noreferrer">https://www.dmxapi.cn/</a>
<ul>
<li>中国</li>
<li>即梦</li>
</ul>
</li>
<li><a href=https://tokenflux.ai/ target=_blank rel="noopener noreferrer">https://tokenflux.ai/</a>
<ul>
<li>模型 <a href=https://tokenflux.ai/models target=_blank rel="noopener noreferrer">https://tokenflux.ai/models</a></li>
</ul>
</li>
<li><a href=https://www.siliconflow.com/ target=_blank rel="noopener noreferrer">https://www.siliconflow.com/</a>
<ul>
<li>硅基流动</li>
<li>北京硅动科技有限公司</li>
</ul>
</li>
<li><a href=https://xiaoice.com/ target=_blank rel="noopener noreferrer">https://xiaoice.com/</a>
<ul>
<li>小冰 数字人</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=generative-marketing>Generative Marketing<a href=#generative-marketing class=hash-link aria-label="Direct link to Generative Marketing" title="Direct link to Generative Marketing" translate=no>​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_EG6R" id=媒体>媒体<a href=#媒体 class=hash-link aria-label="Direct link to 媒体" title="Direct link to 媒体" translate=no>​</a></h3>
<ul>
<li>可灵 (Kling) 2.1:
<ul>
<li>根据图像生成视频，效果不错</li>
<li>动态表情、大动态运镜、精确手势控制、演唱口型</li>
<li>旋转机位运镜和口型演出</li>
</ul>
</li>
<li>Veo 3:
<ul>
<li>根据文本提示生成视频</li>
<li>实拍效果模拟</li>
</ul>
</li>
<li>Sora:
<ul>
<li>将现有视频转换为新风格</li>
</ul>
</li>
<li>Pika:
<ul>
<li>在场景中切换或添加内容</li>
</ul>
</li>
<li>Runway:
<ul>
<li>引用人物、地点或风格（Gen-3）</li>
</ul>
</li>
<li>Luma:
<ul>
<li>将视频重新调整为新的宽高比</li>
</ul>
</li>
<li>Hedra:
<ul>
<li>让角色说话（口型同步）</li>
</ul>
</li>
<li>即梦 (Instant Dream):
<ul>
<li>网上很多视频就是他做的</li>
<li>即梦 Omnihuman: 擅长静态口型</li>
</ul>
</li>
<li>Vidu:
<ul>
<li>二次元动漫演绎</li>
</ul>
</li>
<li>Viggle:
<ul>
<li>将角色添加到视频表情包中（角色动作迁移）</li>
</ul>
</li>
<li><a href=https://higgsfield.ai/ target=_blank rel="noopener noreferrer">Higgsfield</a>
<ul>
<li>使用好莱坞级视觉效果</li>
</ul>
</li>
<li>剪映专业版:
<ul>
<li>功能强大，素材特效丰富，剪辑视频必装软件</li>
</ul>
</li>
<li><a href=https://www.krea.ai/ target=_blank rel="noopener noreferrer">Krea</a>
<ul>
<li>使用 Wan 或 Hunyuan 等开源模型</li>
</ul>
</li>
<li>美图秀秀:
<ul>
<li>直接绘画，大家用的惯</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_EG6R" id=文本>文本<a href=#文本 class=hash-link aria-label="Direct link to 文本" title="Direct link to 文本" translate=no>​</a></h3>
<ul>
<li>豆包:
<ul>
<li>专注情感，生活场景必备</li>
</ul>
</li>
<li>Kimi:
<ul>
<li>专业长文，就是不怕内容多</li>
</ul>
</li>
<li>Deepseek:
<ul>
<li>写代码完全不出错，强的可怕</li>
</ul>
</li>
<li>知乎:
<ul>
<li>喜欢知乎文章的朋友必备</li>
</ul>
</li>
<li>gamma:
<ul>
<li>全球最牛的 PPT，根据你的文章直接定制化生成</li>
</ul>
</li>
<li>MindShow:
<ul>
<li>输入文字大纲，自动整理成思维导图，还能一键转换成演示文稿</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_EG6R" id=设计>设计<a href=#设计 class=hash-link aria-label="Direct link to 设计" title="Direct link to 设计" translate=no>​</a></h3>
<ul>
<li>稿定设计:
<ul>
<li>涵盖平面设计、电商设计等，提供超多可编辑模板，满足各种设计需求</li>
</ul>
</li>
<li>易企秀:
<ul>
<li>能快速做 H5 页面，模板种类多，适合活动宣传、产品推广</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_EG6R" id=检索>检索<a href=#检索 class=hash-link aria-label="Direct link to 检索" title="Direct link to 检索" translate=no>​</a></h3>
<ul>
<li><a href=https://felo.ai/ target=_blank rel="noopener noreferrer">https://felo.ai/</a>
<ul>
<li>全网最好用的小红书搜索工具，不知道的绝对是一大遗憾</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=avatar>Avatar<a href=#avatar class=hash-link aria-label="Direct link to Avatar" title="Direct link to Avatar" translate=no>​</a></h2>
<ul>
<li>
<p>数字人</p>
</li>
<li>
<p>HunyuanVideo-Avatar</p>
</li>
<li>
<p><a href=https://github.com/tencent-ailab/IP-Adapter target=_blank rel="noopener noreferrer">tencent-ailab/IP-Adapter</a></p>
<ul>
<li>Text-to-Image</li>
</ul>
</li>
<li>
<p>Pony</p>
<ul>
<li>finetune on SDXL</li>
<li>trained on 2.5 million furry/anthro/cartoon/anime images</li>
<li>能直接识别很多动漫角色，不需要 lora</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=diffusion>Diffusion<a href=#diffusion class=hash-link aria-label="Direct link to Diffusion" title="Direct link to Diffusion" translate=no>​</a></h2>
<ul>
<li>I2I Image to Image</li>
<li>Image Edit</li>
<li>Image Generation</li>
<li>Image Inpainting</li>
<li>Image Upscale</li>
<li>Image Variation</li>
<li>T2I Text to Image</li>
<li>T2V Text to Video</li>
<li>Video Generation</li>
<li>In/Out-Painting</li>
<li>Structural Conditioning</li>
</ul>
<hr/>
<ul>
<li><a href=https://github.com/Alpha-VLLM/Lumina-Image-2.0 target=_blank rel="noopener noreferrer">Alpha-VLLM/Lumina-Image-2.0</a>
<ul>
<li>hf <a href=https://huggingface.co/Alpha-VLLM/Lumina-Image-2.0 target=_blank rel="noopener noreferrer">Alpha-VLLM/Lumina-Image-2.0</a></li>
</ul>
</li>
</ul>





















































































































































































































<table><thead><tr><th>base model<th>date<tbody><tr><td>Aura Flow<td><tr><td>CogVideoX<td><tr><td>Flux .1 D, flux.1-dev<td>2024-08-01<tr><td>Flux .1 Kontext<td>2025-05-29<tr><td>Flux .1 S, flux.1-schnell<td>2024-08-01<tr><td>HiDream<td><tr><td>Hunyuan 1<td><tr><td>Hunyuan Video<td><tr><td>Illustrious<td><tr><td>Imagen 4<td>2025-05-20<tr><td>Kolors<td><tr><td>LTXV<td><tr><td>Lumina<td><tr><td>Mochi<td><tr><td>NoobAI<td><tr><td>ODOR<td><tr><td>Open AI<td><tr><td>Other<td><tr><td>PixArt Σ<td><tr><td>PixArt Α<td><tr><td>Playground V2<td><tr><td>Pony<td><tr><td>SD 1.4<td><tr><td>SD 1.5<td><tr><td>SD 1.5 Hyper<td><tr><td>SD 1.5 LCM<td><tr><td>SD 2.0<td><tr><td>SD 2.0 768<td><tr><td>SD 2.1<td><tr><td>SD 2.1 768<td><tr><td>SD 2.1 Unclip<td><tr><td>SD 3<td><tr><td>SD 3.5<td><tr><td>SD 3.5 Large<td><tr><td>SD 3.5 Large Turbo<td><tr><td>SD 3.5 Medium<td><tr><td>SDXL 0.9<td><tr><td>SDXL 1.0<td><tr><td>SDXL 1.0 LCM<td><tr><td>SDXL Distilled<td><tr><td>SDXL Hyper<td><tr><td>SDXL Lightning<td><tr><td>SDXL Turbo<td><tr><td>SVD<td><tr><td>SVD XT<td><tr><td>Stable Cascade<td><tr><td>WAN Video<td><tr><td>Wan Video 1.3B T2v<td><tr><td>Wan Video 14B I2v 480p<td><tr><td>Wan Video 14B I2v 720p<td><tr><td>Wan Video 14B T2v<td></table>









































































<table><thead><tr><th>Mode Type<th>cn<tbody><tr><td>Aesthetic Gradient<td>美学渐变<tr><td>Checkpoint<td>检查点<tr><td>Controlnet<td>控制网<tr><td>Detection<td>检测<tr><td>DoRA<td>DoRA<tr><td>Hypernetwork<td>超网络<tr><td>LoRA<td>LoRA<tr><td>LyCORIS<td>LyCORIS<tr><td>Motion<td>动态<tr><td>Other<td>其他<tr><td>Poses<td>姿势<tr><td>Embedding<td>嵌入<tr><td>Upscaler<td>超分辨率<tr><td>VAE<td>变分自编码器<tr><td>Wildcards<td>通配符<tr><td>Workflows<td>工作流</table>














<table><thead><tr><th>Checkpoint Type<tbody><tr><td>Merge<tr><td>Trained</table>
































<table><thead><tr><th>File Type<tbody><tr><td>Core ML<tr><td>Diffusers<tr><td>GGUF<tr><td>ONNX<tr><td>Other<tr><td>Pickle Tensor<tr><td>Safe Tensor<tr><td>Pt</table>













































































<table><thead><tr><th>Category<th>cn<tbody><tr><td>Action<td>动作<tr><td>Aesthetic<td>美学<tr><td>Architecture<td>建筑<tr><td>Animal<td>动物<tr><td>Assets<td>资产<tr><td>Background<td>背景<tr><td>Base Model<td>基础模型<tr><td>Buildings<td>建筑物<tr><td>Celebrity<td>名人<tr><td>Character<td>角色<tr><td>Clothing<td>服装<tr><td>Concept<td>概念<tr><td>Objects<td>物体<tr><td>Poses<td>姿势<tr><td>Style<td>风格<tr><td>Tool<td>工具<tr><td>Vehicle<td>交通工具</table>
<ul>
<li>常见出问题的地方
<ul>
<li>手指</li>
<li>眼睛</li>
<li>头发</li>
<li>下巴</li>
<li>皮肤</li>
</ul>
</li>
<li>CFG - Classifier-Free Diffusion Guidance (2022)</li>
<li><a href=https://github.com/black-forest-labs/flux target=_blank rel="noopener noreferrer">black-forest-labs/flux</a>
<ul>
<li>FLUX.1 [dev] Non-Commercial License
<ul>
<li>不能将这个模型或其生成的任何内容，用于任何以盈利为目的商业活动。</li>
<li>不允许 训练竞争模型</li>
<li>只有 FLUX.1-schnell 是 apache-2.0 协议</li>
</ul>
</li>
<li><a href=https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev target=_blank rel="noopener noreferrer">FLUX.1-Kontext dev</a>
<ul>
<li>Demo <a href=https://specularrealms.com/ai-transcripts/experiments-with-flux-kontext/ target=_blank rel="noopener noreferrer">https://specularrealms.com/ai-transcripts/experiments-with-flux-kontext/</a></li>
<li><a href=https://blog.fal.ai/announcing-flux-1-kontext-dev-inference-training/ target=_blank rel="noopener noreferrer">https://blog.fal.ai/announcing-flux-1-kontext-dev-inference-training/</a></li>
</ul>
</li>
<li>FLUX.1-kontext
<ul>
<li>in-context image generation</li>
<li><a href=https://bfl.ai/models/flux-kontext target=_blank rel="noopener noreferrer">https://bfl.ai/models/flux-kontext</a></li>
<li><a href=https://bfl.ai/announcements/flux-1-kontext target=_blank rel="noopener noreferrer">https://bfl.ai/announcements/flux-1-kontext</a></li>
</ul>
</li>
<li>hf collection <a href=https://huggingface.co/collections/black-forest-labs/flux1-679d013aee236841c0e9d38a target=_blank rel="noopener noreferrer">FLUX.1</a>
<ul>
<li><a href=https://huggingface.co/black-forest-labs/FLUX.1-dev target=_blank rel="noopener noreferrer">FLUX.1-dev</a> - FLUX.1 dev Non-Commercial License
<ul>
<li>图像质量</li>
<li>guidance distillation</li>
<li><a href=https://huggingface.co/Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro-2.0 target=_blank rel="noopener noreferrer">https://huggingface.co/Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro-2.0</a></li>
</ul>
</li>
<li><a href=https://huggingface.co/black-forest-labs/FLUX.1-schnell target=_blank rel="noopener noreferrer">FLUX.1-schnell</a> - Apache 2.0
<ul>
<li>生成速度和效率 - 1-4 步</li>
<li>latent adversarial diffusion distillation</li>
<li>Finetune/LoRA
<ul>
<li><a href=https://huggingface.co/black-forest-labs/FLUX.1-schnell target=_blank rel="noopener noreferrer">black-forest-labs/FLUX.1-schnell</a>
<ul>
<li><a href=https://huggingface.co/lodestones/Chroma target=_blank rel="noopener noreferrer">lodestones/Chroma</a>
<ul>
<li><a href=https://civitai.com/posts/13766416 target=_blank rel="noopener noreferrer">https://civitai.com/posts/13766416</a></li>
<li><a href=https://civitai.com/models/1330309/chroma target=_blank rel="noopener noreferrer">https://civitai.com/models/1330309/chroma</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href=https://huggingface.co/HiDream-ai/HiDream-I1-Full target=_blank rel="noopener noreferrer">HiDream-I1-Full</a>
<ul>
<li>2025-04-28</li>
<li>17B</li>
<li>VAE: FLUX.1 schnell</li>
<li>Text Encoder: google/t5-v1_1-xxl, meta-llama/Meta-Llama-3.1-8B-Instruct</li>
</ul>
</li>
<li><a href=https://github.com/VectorSpaceLab/OmniGen2 target=_blank rel="noopener noreferrer">VectorSpaceLab/OmniGen2</a>
<ul>
<li>Qwen-VL-2.5</li>
<li><a href=https://huggingface.co/spaces/OmniGen2/OmniGen2 target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/OmniGen2/OmniGen2</a></li>
<li><a href=https://blog.comfy.org/p/omnigen2-native-support-in-comfyui target=_blank rel="noopener noreferrer">https://blog.comfy.org/p/omnigen2-native-support-in-comfyui</a></li>
</ul>
</li>
<li><a href=https://huggingface.co/huanngzh/mv-adapter target=_blank rel="noopener noreferrer">huanngzh/mv-adapter</a></li>
<li>Stable Diffusion
<ul>
<li>Stable Diffusion XL (SDXL)</li>
<li><a href=https://github.com/Stability-AI/sd3.5 target=_blank rel="noopener noreferrer">Stable Diffusion 3.5</a>
<ul>
<li>OpenAI CLIP-L</li>
<li>OpenCLIP bigG</li>
<li>Google T5-XXL</li>
<li>hf collection <a href=https://huggingface.co/collections/stabilityai/stable-diffusion-35-671785cca799084f71fa2838 target=_blank rel="noopener noreferrer">Stable Diffusion 3.5</a></li>
<li><a href=https://huggingface.co/stabilityai/stable-diffusion-3.5-large target=_blank rel="noopener noreferrer">https://huggingface.co/stabilityai/stable-diffusion-3.5-large</a>
<ul>
<li>Multimodal Diffusion Transformer (MMDiT)</li>
</ul>
</li>
<li>Medium
<ul>
<li>2B 模型</li>
<li>MMDiT-X</li>
</ul>
</li>
<li>Large-Turbo
<ul>
<li>MMDiT + ADD</li>
<li>速度快, 4 个步骤</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Optimization
<ul>
<li><a href=https://github.com/TMElyralab/lyraDiff target=_blank rel="noopener noreferrer">TMElyralab/lyraDiff</a>
<ul>
<li>Apache-2.0, C++</li>
<li>acceleration engine for Diffusion and DiT models</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr/>
<ul>
<li>OpenAI CLIP
<ul>
<li>Contrastive Language-Image Pre-training - 对比语言-图像预训练</li>
<li>-L Vision Transformer, ViT, Large</li>
<li>零样本图像分类 (Zero-shot Image Classification)</li>
<li>ViT-L/14</li>
</ul>
</li>
<li>OpenCLIP
<ul>
<li>对 OpenAI CLIP 的开源复现和扩展, 提高透明度和性能</li>
<li>LAION数据集</li>
<li>bigG - ViT-bigG/14</li>
</ul>
</li>
<li>Google T5-XXL
<ul>
<li>Text-to-Text Transfer Transformer（文本到文本迁移Transformer）</li>
<li>将所有自然语言处理（NLP）任务都统一为一种“文本到文本”的格式</li>
<li>在输入文本前加上一个 <strong>任务前缀</strong> 来告诉模型需要做什么
<ul>
<li><code>translate English to German: That is good.</code></li>
<li><code>summarize: [一篇很长的文章]</code></li>
<li><code>cola sentence: The course is jumping well.</code></li>
</ul>
</li>
<li>FLAN-T5</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_EG6R" id=prompting>Prompting<a href=#prompting class=hash-link aria-label="Direct link to Prompting" title="Direct link to Prompting" translate=no>​</a></h3>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">[人物描述] [场景构建] [摄影参数] [氛围强化] [细节补充]</span><br/></span></code></pre></div></div>
<ul>
<li>场景构建
<ul>
<li>服装细节</li>
<li>动态姿势</li>
<li>光影氛围</li>
</ul>
</li>
<li><a href=https://huggingface.co/spaces/gokaygokay/FLUX-Prompt-Generator target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/gokaygokay/FLUX-Prompt-Generator</a></li>
<li><a href=https://github.com/dagthomas/comfyui_dagthomas target=_blank rel="noopener noreferrer">https://github.com/dagthomas/comfyui_dagthomas</a></li>
<li>参考
<ul>
<li><a href=https://huggingface.co/microsoft/Promptist target=_blank rel="noopener noreferrer">https://huggingface.co/microsoft/Promptist</a>
<ul>
<li>优化 Stable Diffusion v1.4 prompt</li>
</ul>
</li>
<li><a href=https://huggingface.co/Gustavosta/MagicPrompt-Stable-Diffusion target=_blank rel="noopener noreferrer">https://huggingface.co/Gustavosta/MagicPrompt-Stable-Diffusion</a>
<ul>
<li>GPT-2 models intended to generate prompt texts for imaging AIs</li>
</ul>
</li>
<li><a href=https://huggingface.co/daspartho/prompt-extend target=_blank rel="noopener noreferrer">https://huggingface.co/daspartho/prompt-extend</a>
<ul>
<li>GPT-2 model trained on dataset of stable diffusion prompts</li>
</ul>
</li>
<li><a href=https://huggingface.co/datasets/daspartho/stable-diffusion-prompts target=_blank rel="noopener noreferrer">https://huggingface.co/datasets/daspartho/stable-diffusion-prompts</a></li>
<li><a href=https://huggingface.co/succinctly/text2image-prompt-generator target=_blank rel="noopener noreferrer">https://huggingface.co/succinctly/text2image-prompt-generator</a>
<ul>
<li>GPT-2 model fine-tuned on the succinctly/midjourney-prompts dataset</li>
</ul>
</li>
</ul>
</li>
<li><a href=https://huggingface.co/AUTOMATIC/promptgen-lexart target=_blank rel="noopener noreferrer">AUTOMATIC/promptgen-lexart (~300mb)</a> - Finetuned using 134,819 prompts from lexica.art</li>
<li><a href=https://huggingface.co/AUTOMATIC/promptgen-majinai-safe target=_blank rel="noopener noreferrer">AUTOMATIC/promptgen-majinai-safe (~300mb)</a> - 1,654 prompts from majinai.art</li>
<li><a href=https://huggingface.co/AUTOMATIC/promptgen-majinai-unsafe target=_blank rel="noopener noreferrer">AUTOMATIC/promptgen-majinai-unsafe (~300mb)</a> - 825 prompts from majinai.art (NSFW)</li>
<li><a href=https://huggingface.co/Gustavosta/MagicPrompt-Dalle target=_blank rel="noopener noreferrer">Gustavosta/MagicPrompt-Dalle</a></li>
<li><a href=https://huggingface.co/kmewhort/stable-diffusion-prompt-bolster target=_blank rel="noopener noreferrer">kmewhort/stable-diffusion-prompt-bolster (~500mb)</a>,</li>
<li><a href=/notes/ai/model/Ar4ikov/gpt2-650k-stable-diffusion-prompt-generator>Ar4ikov/gpt2-650k-stable-diffusion-prompt-generator (~500mb)</a>,</li>
<li><a href=https://huggingface.co/Ar4ikov/gpt2-medium-650k-stable-diffusion-prompt-generator target=_blank rel="noopener noreferrer">Ar4ikov/gpt2-medium-650k-stable-diffusion-prompt-generator (~1.4gb)</a>,</li>
<li><a href=https://huggingface.co/crumb/bloom-560m-RLHF-SD2-prompter-aesthetic target=_blank rel="noopener noreferrer">crumb/bloom-560m-RLHF-SD2-prompter-aesthetic (~1.1gb)</a>,</li>
<li><a href=https://huggingface.co/Meli/GPT2-Prompt target=_blank rel="noopener noreferrer">Meli/GPT2-Prompt (~500mb)</a>,</li>
<li><a href=https://huggingface.co/DrishtiSharma/StableDiffusion-Prompt-Generator-GPT-Neo-125M target=_blank rel="noopener noreferrer">DrishtiSharma/StableDiffusion-Prompt-Generator-GPT-Neo-125M (~550mb)</a></li>
</ul>
<p><strong>Resolution</strong></p>
<ul>
<li>1:1
<ul>
<li>512x512</li>
<li>768x768</li>
<li>1024x1024</li>
</ul>
</li>
<li>4:3</li>
<li>16:9
<ul>
<li>1216x704</li>
</ul>
</li>
<li>9:16
<ul>
<li>704x1216</li>
</ul>
</li>
<li>Portrait
<ul>
<li>832x1216</li>
</ul>
</li>
<li>Landscape
<ul>
<li>1216x832</li>
</ul>
</li>
</ul>
<p><strong>Negative</strong></p>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">text</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">watermark</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">camera</span><br/></span></code></pre></div></div>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">out of frame, lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature,</span><br/></span></code></pre></div></div>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">(worst quality, low quality:1.4), (ugly:1.2), (stitching:1.2),</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">bad anatomy, deformed, disfigured, malformed limbs, extra limbs, fused limbs,</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">poorly drawn face, distorted face, malformed face, asymmetric eyes,</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">poorly drawn hands, extra fingers, fused fingers, malformed hands,</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">text, error, signature, watermark, username</span><br/></span></code></pre></div></div>
<ul>
<li><a href=https://huggingface.co/spaces/stabilityai/stable-diffusion/discussions/7857 target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/stabilityai/stable-diffusion/discussions/7857</a></li>
</ul>
<p><strong>动态姿势</strong></p>
<p><strong>服装细节</strong></p>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">trendy off-shoulder top</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">oversized cozy sweater</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">t-shirt with a cute cat print</span><br/></span></code></pre></div></div>
<p><strong>质量</strong></p>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">(shot on Sony A7 IV, 50mm f/1.8 lens)</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">photorealistic</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">ultra detailed</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">natural skin texture</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">soft film grain</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">8k uhd</span><br/></span></code></pre></div></div>
<p><strong>氛围强化</strong></p>
<ul>
<li>氛围</li>
</ul>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">serene, tranquil, intimate, modern elegance</span><br/></span></code></pre></div></div>
<ul>
<li>色彩</li>
</ul>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">Warm neutrals with pops of soft pastels in window light</span><br/></span></code></pre></div></div>
<ul>
<li>动态</li>
</ul>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">Subtle light reflection on sweater fabric, gentle light diffusion across the room</span><br/></span></code></pre></div></div>
<p><strong>摄影参数</strong></p>
<ul>
<li>视觉风格</li>
<li>光影处理</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_EG6R" id=chroma>Chroma<a href=#chroma class=hash-link aria-label="Direct link to Chroma" title="Direct link to Chroma" translate=no>​</a></h3>
<ul>
<li>FT on FLUX.1-schnell</li>
<li>Apache 2.0</li>
<li><a href=https://civitai.com/models/1330309/chroma target=_blank rel="noopener noreferrer">https://civitai.com/models/1330309/chroma</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_EG6R" id=realisian>Realisian<a href=#realisian class=hash-link aria-label="Direct link to Realisian" title="Direct link to Realisian" translate=no>​</a></h3>
<ul>
<li>SD 1.5</li>
<li>steps 12 (8 ≈ 16)</li>
<li>DPM++ SDE Karras</li>
<li>Hires Fix <strong>Required</strong>
<ul>
<li>On</li>
<li>Upscaler: Latent (bicubic antialised)</li>
<li>Hires Steps: 5 (4 ≈ 10)</li>
<li>Denoising Strenght: 0.55 (0.4 ≈ 0.7)</li>
<li>Upscale by: 2</li>
</ul>
</li>
<li>CFG Scale 3 (2 ≈ 5)</li>
<li>Clip Skip 1 (1 ≈ 2)</li>
</ul>
<p>Negative</p>
<ul>
<li><a href=https://civitai.com/models/289190/realisian-negative-embedding target=_blank rel="noopener noreferrer">https://civitai.com/models/289190/realisian-negative-embedding</a></li>
</ul>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">embedding:realisianNeg.Z5yh, Realisian-Neg</span><br/></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_EG6R" id=juggernaut-xl>Juggernaut XL<a href=#juggernaut-xl class=hash-link aria-label="Direct link to Juggernaut XL" title="Direct link to Juggernaut XL" translate=no>​</a></h3>
<ul>
<li>SDXL 1.0</li>
</ul>
<hr/>
<ul>
<li>Juggernaut Ragnarok
<ul>
<li>专注于提升照片写实感、数字绘画、人物姿势、手部和脚部等方面的表现。</li>
<li>该模型以 Jug XII 为基础，首先通过摄影数据集训练，进一步使用 Booru 标签进行重标注，并以 SDXL 作为底座进行训练。随后，作者又以 Lustify by Coyotte 为基础对同一数据集再次训练，并将其以一定比例合并，作为输出的稳定器。由于数据集采用 Booru 标签标注，Booru 风格的提示词和 X–XII 版本的描述方式在 Ragnarok 上都能很好地工作。</li>
<li>适合用于追求高质量写实风格的图像生成项目，但作为 SDXL 模型，仍存在如远距离人脸、文本渲染等方面的局限。推荐将其作为生成管道中的一环（如 FluxDev / Pixelwave / Jug Flux Pro → Juggernaut Ragnarok）以获得更佳效果。模型完全开源，支持自由合并、微调和商用。</li>
</ul>
</li>
</ul>

































<table><thead><tr><th>Base Model<th>SDXL 1.0<tbody><tr><td>Resolution<td>832x1216 for Portrait<tr><td>Sampler<td>DPM++ 2M SDE<tr><td>Steps<td>30-40<tr><td>CFG<td>3-6 (less is a bit more realistic)<tr><td>VAE<td>✅<tr><td>HiRes<td>4xNMKD-Siax_200k with 15 Steps and 0.3 Denoise + 1.5 Upscale</table>
<ul>
<li><a href=https://huggingface.co/RunDiffusion/Juggernaut-XI-v11 target=_blank rel="noopener noreferrer">https://huggingface.co/RunDiffusion/Juggernaut-XI-v11</a></li>
<li><a href=https://civitai.com/models/133005/juggernaut-xl target=_blank rel="noopener noreferrer">https://civitai.com/models/133005/juggernaut-xl</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_EG6R" id=cyberrealistic-pony>CyberRealistic Pony<a href=#cyberrealistic-pony class=hash-link aria-label="Direct link to CyberRealistic Pony" title="Direct link to CyberRealistic Pony" translate=no>​</a></h3>
<p>CyberRealistic Pony 是将 Pony Diffusion 的可爱风格与 CyberRealistic 的写实质感结合的模型。</p>
<ul>
<li>CyberRealistic Pony <a href=https://civitai.com/models/443821/cyberrealistic-pony target=_blank rel="noopener noreferrer">https://civitai.com/models/443821/cyberrealistic-pony</a></li>
</ul>





























<table><thead><tr><th>Base Model<th>Pony<tbody><tr><td>Resolution<td>896x1152 / 832x1216<tr><td>Sampler<td>DPM++ SDE Karras / DPM++ 2M Karras / Euler a<tr><td>Steps<td>30+ Steps<tr><td>CFG<td>5<tr><td>Clip Skip<td>2</table>
<p><strong>Positive</strong></p>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">score_9, score_8_up, score_7_up, (SUBJECT),</span><br/></span></code></pre></div></div>
<p><strong>Negative</strong></p>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">score_6, score_5, score_4, (worst quality:1.2), (low quality:1.2), (normal quality:1.2), lowres, bad anatomy, bad hands, signature, watermarks, ugly, imperfect eyes, skewed eyes, unnatural face, unnatural body, error, extra limb, missing limbs</span><br/></span></code></pre></div></div>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">score_6, score_5, score_4, simplified, abstract, unrealistic, impressionistic, low resolution, lowres, bad anatomy, bad hands, missing fingers, worst quality, low quality, normal quality, cartoon, anime, drawing, sketch, illustration, artificial, poor quality</span><br/></span></code></pre></div></div>
<p><strong>ADetailer</strong></p>
<div class="language-text codeBlockContainer_ljD1 theme-code-block" style=--prism-color:#bfc7d5;--prism-background-color:#292d3e><div class=codeBlockContent_rhaG><pre tabindex=0 class="prism-code language-text codeBlock_mx9Q thin-scrollbar" style=color:#bfc7d5;background-color:#292d3e><code class=codeBlockLines_NG8l><span class=token-line style=color:#bfc7d5><span class="token plain">Adetailer model: face_yolov9c.pt</span><br/></span><span class=token-line style=color:#bfc7d5><span class="token plain">If you only want the main face being refined set 'Mask only the top k largest' to 1.</span><br/></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=metric>Metric<a href=#metric class=hash-link aria-label="Direct link to Metric" title="Direct link to Metric" translate=no>​</a></h2>








































<table><thead><tr><th>abbr.<th>stand for<th>better<th>meaning<th>notes<tbody><tr><td>WER<td>Word Error Rate<td>⬇️ L<td>词错误率<td>STT<tr><td>RTFx<td>Real-Time Factor<td>⬆️ H<td>实时因子<td>STT<tr><td>CER<td>Character Error Rate<td><td>字符错误率<td>STT<tr><td>PER<td>Phoneme Error Rate<td><td>音素错误率<td>STT</table>
<ul>
<li>WER = (S + D + I) / N = (S + D + I) / (S + D + C)
<ul>
<li>S = Substitutions</li>
<li>D = Deletions</li>
<li>I = Insertions</li>
<li>C = Correct</li>
<li>N = Total number of words
<ul>
<li>N=S+D+C</li>
</ul>
</li>
</ul>
</li>
<li>RTFx = (number of seconds of audio inferred) / (compute time in seconds)</li>
<li>RTFx = RTFx = 1/RTF</li>
<li><a href=https://huggingface.co/docs/evaluate/index target=_blank rel="noopener noreferrer">huggingface/evaluate</a></li>
<li><a href=https://huggingface.co/spaces/evaluate-metric/wer target=_blank rel="noopener noreferrer">https://huggingface.co/spaces/evaluate-metric/wer</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_EG6R" id=datasets>Datasets<a href=#datasets class=hash-link aria-label="Direct link to Datasets" title="Direct link to Datasets" translate=no>​</a></h2>
<ul>
<li><a href=https://huggingface.co/datasets target=_blank rel="noopener noreferrer">https://huggingface.co/datasets</a></li>
<li><a href=https://github.com/mlabonne/llm-datasets target=_blank rel="noopener noreferrer">mlabonne/llm-datasets</a></li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class=col><b>Tags:</b><ul class="tags_noif padding--none margin-left--sm"><li class=tag_mzC7><a rel=tag class="tag_xI_x tagRegular_Q4uH" href=/notes/tags/model>Model</a><li class=tag_mzC7><a rel=tag class="tag_xI_x tagRegular_Q4uH" href=/notes/tags/reference>Reference</a><li class=tag_mzC7><a rel=tag class="tag_xI_x tagRegular_Q4uH" href=/notes/tags/awesome>Awesome</a></ul></div></div><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col><a href=https://github.com/wenerme/wener/edit/master/notes/../notes/ai/model/ai-model-awesome.md target=_blank rel="noopener noreferrer" class=theme-edit-this-page><svg fill=currentColor height=20 width=20 viewBox="0 0 40 40" class=iconEdit_A7Jz aria-hidden=true><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"/></g></svg>Edit this page</a></div><div class="col lastUpdated_Hg3U"><span class=theme-last-updated>Last updated<!-- --> on <b><time datetime=2025-09-20T16:20:08.000Z itemprop=dateModified>Sep 20, 2025</time></b> by <b>wener</b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/notes/ai/ml/x-anylabeling><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>X-AnyLabeling</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/notes/ai/model/alpaca><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>Alpaca</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_wpyd thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#domains class="table-of-contents__link toc-highlight">Domains</a><li><a href=#vlm class="table-of-contents__link toc-highlight">VLM</a><li><a href=#computer-agent class="table-of-contents__link toc-highlight">Computer Agent</a><li><a href=#chinese class="table-of-contents__link toc-highlight">中文</a><li><a href=#fine-tuning class="table-of-contents__link toc-highlight">Fine-tuning</a><li><a href=#tts class="table-of-contents__link toc-highlight">TTS</a><li><a href=#stt class="table-of-contents__link toc-highlight">STT</a><li><a href=#music class="table-of-contents__link toc-highlight">Music</a><li><a href=#mllm class="table-of-contents__link toc-highlight">MLLM</a><li><a href=#vision class="table-of-contents__link toc-highlight">Vision</a><li><a href=#coding class="table-of-contents__link toc-highlight">Coding</a><li><a href=#video class="table-of-contents__link toc-highlight">Video</a><li><a href=#image-generation class="table-of-contents__link toc-highlight">Image Generation</a><li><a href=#media-generation class="table-of-contents__link toc-highlight">Media Generation</a><li><a href=#generative-marketing class="table-of-contents__link toc-highlight">Generative Marketing</a><ul><li><a href=#媒体 class="table-of-contents__link toc-highlight">媒体</a><li><a href=#文本 class="table-of-contents__link toc-highlight">文本</a><li><a href=#设计 class="table-of-contents__link toc-highlight">设计</a><li><a href=#检索 class="table-of-contents__link toc-highlight">检索</a></ul><li><a href=#avatar class="table-of-contents__link toc-highlight">Avatar</a><li><a href=#diffusion class="table-of-contents__link toc-highlight">Diffusion</a><ul><li><a href=#prompting class="table-of-contents__link toc-highlight">Prompting</a><li><a href=#chroma class="table-of-contents__link toc-highlight">Chroma</a><li><a href=#realisian class="table-of-contents__link toc-highlight">Realisian</a><li><a href=#juggernaut-xl class="table-of-contents__link toc-highlight">Juggernaut XL</a><li><a href=#cyberrealistic-pony class="table-of-contents__link toc-highlight">CyberRealistic Pony</a></ul><li><a href=#metric class="table-of-contents__link toc-highlight">Metric</a><li><a href=#datasets class="table-of-contents__link toc-highlight">Datasets</a></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class=footer__title>笔记</div><ul class="footer__items clean-list"><li class=footer__item><a class=footer__link-item href=/notes/java>Java</a><li class=footer__item><a class=footer__link-item href=/notes/os/alpine>AlpineLinux</a><li class=footer__item><a class=footer__link-item href=/notes/devops/kubernetes>Kubernates</a><li class=footer__item><a class=footer__link-item href=/notes/voip>VoIP</a></ul></div><div class="theme-layout-footer-column col footer__col"><div class=footer__title>Projects</div><ul class="footer__items clean-list"><li class=footer__item>
              <div>
              <a class=footer__link-item href=https://github.com/wenerme/wener>Wener</a>
              -
              <a class=footer__link-item href=https://github.com/wenerme/wener/actions title="wenerme/wener - ci">
              <img style="vertical-align: middle;opacity: .4;" src=https://github.com/wenerme/wener/workflows/Build/badge.svg />
              </a>
              </div>
              <li class=footer__item><a href=https://apis.wener.me target=_blank rel="noopener noreferrer" class=footer__link-item>Wener's Apis<svg width=13.5 height=13.5 aria-label="(opens in new tab)" class=iconExternalLink_kUGX><use href=#theme-svg-external-link /></svg></a></ul></div><div class="theme-layout-footer-column col footer__col"><div class=footer__title>Social</div><ul class="footer__items clean-list"><li class=footer__item><a class=footer__link-item href=/story>Blog</a><li class=footer__item><a href=https://github.com/wenerme target=_blank rel="noopener noreferrer" class=footer__link-item>GitHub</a><li class=footer__item><a href=https://twitter.com/wenerme target=_blank rel="noopener noreferrer" class=footer__link-item>Twitter</a></ul></div></div><div class="footer__bottom text--center"><div class=margin-bottom--sm><img src=/img/wener-logo.svg alt="Wener Site" class="footer__logo themedComponent_j2y5 themedComponent--light_v877"/><img src=/img/wener-logo.svg alt="Wener Site" class="footer__logo themedComponent_j2y5 themedComponent--dark_PUQY"/></div><div class=footer__copyright>Copyright © 1992-2025 Wener - <img alt=cc-by-sa-4.0 src=https://mirrors.creativecommons.org/presskit/buttons/80x15/svg/by-sa.svg /> - Build @2025-10-09 13:46</div></div></div></footer></div></body>