"use strict";(self.webpackChunkwener_website=self.webpackChunkwener_website||[]).push([["549601"],{292300:function(n,e,t){t.r(e),t.d(e,{frontMatter:()=>r,toc:()=>c,default:()=>d,metadata:()=>a,assets:()=>s,contentTitle:()=>o});var a=JSON.parse('{"id":"ai/training/llama-factory","title":"LLaMA-Factory","description":"- hiyouga/LLaMA-Factory","source":"@site/../notes/ai/training/llama-factory.md","sourceDirName":"ai/training","slug":"/ai/training/llama-factory","permalink":"/notes/ai/training/llama-factory","draft":false,"unlisted":false,"editUrl":"https://github.com/wenerme/wener/edit/master/notes/../notes/ai/training/llama-factory.md","tags":[],"version":"current","lastUpdatedBy":"wener","lastUpdatedAt":1767451770000,"frontMatter":{"title":"LLaMA-Factory"},"sidebar":"docs","previous":{"title":"\u8BAD\u7EC3","permalink":"/notes/ai/training/"},"next":{"title":"training-faq","permalink":"/notes/ai/training/faq"}}'),l=t(486106),i=t(917776);let r={title:"LLaMA-Factory"},o="LLaMA-Factory",s={},c=[{value:"Alpaca \u683C\u5F0F",id:"alpaca-format",level:2},{value:"Sharegpt \u683C\u5F0F",id:"sharegpt-format",level:2},{value:"libcublas.so not found in the system path",id:"libcublasso-not-found-in-the-system-path",level:2},{value:"This model does not support image input",id:"this-model-does-not-support-image-input",level:2}];function u(n){let e={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...n.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(e.header,{children:(0,l.jsx)(e.h1,{id:"llama-factory",children:"LLaMA-Factory"})}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.a,{href:"https://github.com/hiyouga/LLaMA-Factory",children:"hiyouga/LLaMA-Factory"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"Apache-2.0, Python"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-bash",children:'git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\ncd LLaMA-Factory\n\nuv python pin 3.10\nuv venv\n\n# uv pip install setuptools\n# uv pip install\n# uv pip install -e ".[torch,metrics]" --no-build-isolation\nuv sync --extra torch --extra metrics --prerelease=allow\n\n# working\nuv run llamafactory-cli --help\n\n# \u542F\u52A8 API\nuv run llamafactory-cli api examples/inference/qwen2_5vl.yaml\ncurl http://0.0.0.0:8000/v1/models\n\n# \u8BAD\u7EC3 LoRA \u5FAE\u8C03\nuv run llamafactory-cli train examples/train_lora/llama3_lora_pretrain.yaml\n\n# hf-mirror.com\ncurl -o qwen2.5vl.tpl.json https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct/raw/main/chat_template.json\n\n# template https://github.com/hiyouga/LLaMA-Factory/blob/main/src/llamafactory/data/template.py\nuv run llamafactory-cli webchat --model_name_or_path Qwen/Qwen2.5-VL-7B-Instruct --template qwen2_vl\n'})}),"\n",(0,l.jsx)(e.h2,{id:"alpaca-format",children:"Alpaca \u683C\u5F0F"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-json",children:'[\n  {\n    "instruction": "\u7528\u6237\u6307\u4EE4\uFF08\u5FC5\u586B\uFF09",\n    "input": "\u7528\u6237\u8F93\u5165\uFF08\u9009\u586B\uFF09",\n    "output": "\u6A21\u578B\u56DE\u7B54\uFF08\u5FC5\u586B\uFF09",\n    "system": "\u7CFB\u7EDF\u63D0\u793A\u8BCD\uFF08\u9009\u586B\uFF09",\n    "history": [\n      ["\u7B2C\u4E00\u8F6E\u6307\u4EE4\uFF08\u9009\u586B\uFF09", "\u7B2C\u4E00\u8F6E\u56DE\u7B54\uFF08\u9009\u586B\uFF09"],\n      ["\u7B2C\u4E8C\u8F6E\u6307\u4EE4\uFF08\u9009\u586B\uFF09", "\u7B2C\u4E8C\u8F6E\u56DE\u7B54\uFF08\u9009\u586B\uFF09"]\n    ]\n  }\n]\n'})}),"\n",(0,l.jsx)(e.h2,{id:"sharegpt-format",children:"Sharegpt \u683C\u5F0F"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:["sharegpt \u683C\u5F0F\u652F\u6301",(0,l.jsx)(e.strong,{children:"\u66F4\u591A\u7684\u89D2\u8272\u79CD\u7C7B"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"\u4F8B\u5982 human\u3001gpt\u3001observation\u3001function \u7B49\u7B49"}),"\n",(0,l.jsxs)(e.li,{children:["\u5B83\u4EEC\u6784\u6210\u4E00\u4E2A\u5BF9\u8C61\u5217\u8868\u5448\u73B0\u5728 ",(0,l.jsx)(e.code,{children:"conversations"})," \u5217\u4E2D\u3002"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.blockquote,{children:["\n",(0,l.jsx)(e.p,{children:"\u6CE8\u610F\u5176\u4E2D human \u548C observation \u5FC5\u987B\u51FA\u73B0\u5728\u5947\u6570\u4F4D\u7F6E\uFF0Cgpt \u548C function \u5FC5\u987B\u51FA\u73B0\u5728\u5076\u6570\u4F4D\u7F6E\u3002"}),"\n"]}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-json",children:'[\n  {\n    "conversations": [\n      {\n        "from": "human",\n        "value": "\u7528\u6237\u6307\u4EE4"\n      },\n      {\n        "from": "function_call",\n        "value": "\u5DE5\u5177\u53C2\u6570"\n      },\n      {\n        "from": "observation",\n        "value": "\u5DE5\u5177\u7ED3\u679C"\n      },\n      {\n        "from": "gpt",\n        "value": "\u6A21\u578B\u56DE\u7B54"\n      }\n    ],\n    "system": "\u7CFB\u7EDF\u63D0\u793A\u8BCD\uFF08\u9009\u586B\uFF09",\n    "tools": "\u5DE5\u5177\u63CF\u8FF0\uFF08\u9009\u586B\uFF09"\n  }\n]\n'})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-json",children:'[\n  {\n    "conversations": [\n      {\n        "from": "human",\n        "value": "<image><image>\u7528\u6237\u6307\u4EE4"\n      },\n      {\n        "from": "gpt",\n        "value": "\u6A21\u578B\u56DE\u7B54"\n      }\n    ],\n    "images": ["\u56FE\u50CF\u8DEF\u5F84\uFF08\u5FC5\u586B\uFF09", "\u56FE\u50CF\u8DEF\u5F84\uFF08\u5FC5\u586B\uFF09"]\n  }\n]\n'})}),"\n",(0,l.jsx)(e.h1,{id:"faq",children:"FAQ"}),"\n",(0,l.jsx)(e.h2,{id:"libcublasso-not-found-in-the-system-path",children:"libcublas.so not found in the system path"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-txt",children:"ImportError: libcudnn.so.9: cannot open shared object file: No such file or directory\nImportError: libcusparseLt.so.0: cannot open shared object file: No such file or directory\nImportError: libnccl.so.2: cannot open shared object file: No such file or directory\nNo module named 'sympy'\n"})}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-bash",children:"#export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\napt install nvidia-cuda-toolkit nvidia-cuda-toolkit-gcc\nfind /usr/lib -iname 'libcuda*'\n\n# nvidia-cudnn 8.x\n# apt install nvidia-cudnn\n\napt install libcudnn9-cuda-12 libcusparselt0\n"})}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:["NVIDIA cuSPARSELt\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"\u4E00\u4E2A\u9AD8\u6027\u80FD\u7684 CUDA \u5E93\uFF0C\u4E13\u95E8\u4E3A\u5728 NVIDIA GPU \u4E0A\u6267\u884C\u7A00\u758F\u77E9\u9635-\u77E9\u9635\u4E58\u6CD5 (SpMM) \u4EE5\u53CA\u76F8\u5173\u7684\u8FD0\u7B97\u800C\u8BBE\u8BA1\u3002"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(e.li,{children:["libnccl\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"NVIDIA Collective Communications Library (NCCL)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(e.h2,{id:"this-model-does-not-support-image-input",children:"This model does not support image input"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:(0,l.jsx)(e.code,{children:"--template qwen2-vl"})}),"\n"]}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{children:"ValueError: This model does not support image input. Please check whether the correct `template` is used.\n"})})]})}function d(n={}){let{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,l.jsx)(e,{...n,children:(0,l.jsx)(u,{...n})}):u(n)}},917776:function(n,e,t){t.d(e,{R:()=>r,x:()=>o});var a=t(7378);let l={},i=a.createContext(l);function r(n){let e=a.useContext(i);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(l):n.components||l:r(n.components),a.createElement(i.Provider,{value:e},n.children)}}}]);